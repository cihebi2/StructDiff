# StructDiff-7.0.0 ç¬¬äºŒé˜¶æ®µè®­ç»ƒé”™è¯¯ä¿®å¤æŒ‡å—

## ğŸ› é—®é¢˜æè¿°

åœ¨ç¬¬äºŒé˜¶æ®µè®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œè¯„ä¼°é˜¶æ®µå‡ºç°ä»¥ä¸‹é”™è¯¯ï¼š
```
ERROR - ç”Ÿæˆå•ä¸ªåºåˆ—å¤±è´¥: can't multiply sequence by non-int of type 'float'
```

## ğŸ” é—®é¢˜åˆ†æ

é”™è¯¯å‡ºç°åœ¨ `_generate_evaluation_samples` æ–¹æ³•ä¸­ï¼Œå…·ä½“æ˜¯åœ¨å»å™ªæ­¥éª¤ï¼š

```python
seq_embeddings = seq_embeddings - 0.1 * noise_pred
```

### æ ¹æœ¬åŸå› 
1. **ç±»å‹ä¸åŒ¹é…**: `noise_pred` å¯èƒ½æ˜¯tupleç±»å‹è€Œä¸æ˜¯tensor
2. **ç»´åº¦ä¸åŒ¹é…**: å¯èƒ½å­˜åœ¨å¹¿æ’­é—®é¢˜
3. **è®¾å¤‡ä¸ä¸€è‡´**: å¼ é‡å¯èƒ½åœ¨ä¸åŒè®¾å¤‡ä¸Š

## ğŸ› ï¸ ä¿®å¤æ–¹æ¡ˆ

### æ–¹æ¡ˆ1ï¼šä¿®å¤å»å™ªé€»è¾‘
ä¿®æ”¹ `_generate_evaluation_samples` æ–¹æ³•ä¸­çš„å»å™ªéƒ¨åˆ†ï¼š

```python
# åŸä»£ç ï¼ˆæœ‰é—®é¢˜çš„ï¼‰
for t in reversed(range(0, 1000, 100)):
    timesteps = torch.tensor([t], device=self.device)
    noise_pred = model.denoiser(
        seq_embeddings, timesteps, attention_mask
    )
    seq_embeddings = seq_embeddings - 0.1 * noise_pred

# ä¿®å¤åçš„ä»£ç 
for t in reversed(range(0, 1000, 100)):
    timesteps = torch.tensor([t], device=self.device)
    noise_pred_output = model.denoiser(
        seq_embeddings, timesteps, attention_mask
    )
    # å¤„ç†å¯èƒ½çš„tupleè¿”å›å€¼
    if isinstance(noise_pred_output, tuple):
        noise_pred = noise_pred_output[0]
    else:
        noise_pred = noise_pred_output
    
    # ç¡®ä¿noise_predæ˜¯tensorä¸”å½¢çŠ¶åŒ¹é…
    if isinstance(noise_pred, torch.Tensor):
        seq_embeddings = seq_embeddings - 0.1 * noise_pred
    else:
        logger.warning(f"noise_predç±»å‹å¼‚å¸¸: {type(noise_pred)}")
```

### æ–¹æ¡ˆ2ï¼šæ·»åŠ ç±»å‹æ£€æŸ¥å’Œé”™è¯¯å¤„ç†
åœ¨ `_decode_for_evaluation` æ–¹æ³•ä¸­æ·»åŠ æ›´å¥å£®çš„é”™è¯¯å¤„ç†ï¼š

```python
def _decode_for_evaluation(self, embeddings: torch.Tensor, attention_mask: torch.Tensor, target_length) -> str:
    """ä¸ºè¯„ä¼°è§£ç åºåˆ—"""
    try:
        # å¼ºåˆ¶è½¬æ¢target_lengthä¸ºæ•´æ•°
        if target_length is None:
            target_length = 10
        elif isinstance(target_length, torch.Tensor):
            target_length = int(target_length.item())
        elif isinstance(target_length, (float, int)):
            target_length = int(target_length)
        else:
            target_length = int(target_length)
    except (ValueError, TypeError):
        target_length = 10
    
    try:
        # ç¡®ä¿æ‰€æœ‰è¾“å…¥éƒ½æ˜¯tensor
        if not isinstance(embeddings, torch.Tensor):
            embeddings = torch.tensor(embeddings, device=self.device)
        if not isinstance(attention_mask, torch.Tensor):
            attention_mask = torch.tensor(attention_mask, device=self.device)
            
        # ç¡®ä¿åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
        embeddings = embeddings.to(self.device)
        attention_mask = attention_mask.to(self.device)
        
        # å…¶ä½™è§£ç é€»è¾‘...
```

### æ–¹æ¡ˆ3ï¼šç®€åŒ–è¯„ä¼°ç”Ÿæˆé€»è¾‘
ä½¿ç”¨æ›´ç®€å•çš„è¯„ä¼°ç”Ÿæˆæ–¹æ³•ï¼š

```python
def _generate_evaluation_samples(self, model, num_samples: int = 100) -> List[str]:
    """ç”Ÿæˆç”¨äºè¯„ä¼°çš„æ ·æœ¬åºåˆ—ï¼ˆä¿®å¤ç‰ˆï¼‰"""
    try:
        sequences = []
        model.eval()
        
        with torch.no_grad():
            for i in range(num_samples):
                try:
                    # éšæœºé•¿åº¦
                    length = torch.randint(
                        int(self.config.min_length),
                        int(self.config.max_length) + 1,
                        (1,)
                    ).item()
                    
                    # ç¡®ä¿lengthæ˜¯æ•´æ•°
                    length = int(length)
                    if length <= 0:
                        length = 10
                    
                    # ç”Ÿæˆéšæœºåºåˆ—åµŒå…¥
                    hidden_size = 320  # ä½¿ç”¨å®é™…æ¨¡å‹çš„hidden size
                    seq_embeddings = torch.randn(1, length, hidden_size, device=self.device)
                    
                    # ä½¿ç”¨è§£ç å™¨ç›´æ¥ç”Ÿæˆåºåˆ—
                    if hasattr(self.model, 'decode_projection'):
                        logits = self.model.decode_projection(seq_embeddings)
                        token_ids = torch.argmax(logits, dim=-1).squeeze(0)
                        
                        if self.tokenizer:
                            sequence = self.tokenizer.decode(token_ids, skip_special_tokens=True)
                            amino_acids = set('ACDEFGHIKLMNPQRSTVWY')
                            clean_sequence = ''.join([c for c in sequence.upper() if c in amino_acids])
                            
                            if clean_sequence and len(clean_sequence) >= self.config.min_length:
                                sequences.append(clean_sequence[:length])
                                
                except Exception as e:
                    logger.error(f"ç”Ÿæˆå•ä¸ªåºåˆ—å¤±è´¥: {e}")
                    # å›é€€åˆ°éšæœºåºåˆ—
                    import random
                    amino_acids = 'ACDEFGHIKLMNPQRSTVWY'
                    fallback_length = max(5, min(50, length if 'length' in locals() else 10))
                    fallback_seq = ''.join(random.choices(amino_acids, k=fallback_length))
                    sequences.append(fallback_seq)
        
        return sequences[:num_samples]
        
    except Exception as e:
        logger.error(f"æ ·æœ¬ç”Ÿæˆå¤±è´¥: {e}")
        # å®Œå…¨å›é€€æ–¹æ¡ˆ
        import random
        amino_acids = 'ACDEFGHIKLMNPQRSTVWY'
        return [''.join(random.choices(amino_acids, k=20)) for _ in range(min(10, num_samples))]
```

## ğŸš€ å®æ–½æ­¥éª¤

1. **åˆ‡æ¢åˆ°Codeæ¨¡å¼** - ä½¿ç”¨ `switch_mode` å·¥å…·
2. **åº”ç”¨ä¿®å¤** - æŒ‰ç…§ä¸Šè¿°æ–¹æ¡ˆä¿®æ”¹ä»£ç 
3. **é‡æ–°è¿è¡Œè®­ç»ƒ** - ç»§ç»­ç¬¬äºŒé˜¶æ®µè®­ç»ƒ
4. **éªŒè¯ä¿®å¤** - æ£€æŸ¥è¯„ä¼°é˜¶æ®µæ˜¯å¦æ­£å¸¸å·¥ä½œ

## ğŸ“‹ éªŒè¯æ¸…å•

- [ ] ä¿®å¤ `_generate_evaluation_samples` æ–¹æ³•
- [ ] ä¿®å¤ `_decode_for_evaluation` æ–¹æ³•
- [ ] æµ‹è¯•è¯„ä¼°ç”Ÿæˆé€»è¾‘
- [ ] é‡æ–°è¿è¡Œç¬¬äºŒé˜¶æ®µè®­ç»ƒ
- [ ] ç¡®è®¤è¯„ä¼°é˜¶æ®µæ— é”™è¯¯

## ğŸ¯ å»ºè®®

**æ¨èæ–¹æ¡ˆ**: ä½¿ç”¨æ–¹æ¡ˆ3ï¼ˆç®€åŒ–è¯„ä¼°ç”Ÿæˆé€»è¾‘ï¼‰ï¼Œå› ä¸ºå®ƒï¼š
- é¿å…äº†å¤æ‚çš„å»å™ªè¿‡ç¨‹
- æ›´ç›´æ¥åœ°ä½¿ç”¨è§£ç å™¨
- æœ‰æ›´å¥½çš„é”™è¯¯å¤„ç†
- æ›´å®¹æ˜“è°ƒè¯•å’Œç»´æŠ¤

**ä¸‹ä¸€æ­¥**: åˆ‡æ¢åˆ°Codeæ¨¡å¼å®æ–½ä¿®å¤