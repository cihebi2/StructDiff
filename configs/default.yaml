# Default training configuration
experiment:
  name: "structdiff_peptide_generation"
  project: "StructDiff"
  seed: 42
  output_dir: "./outputs"
  checkpoint_dir: "./checkpoints"
  log_dir: "./logs"

model:
  type: "StructDiff"
  config_path: "./configs/model/structdiff.yaml"

data:
  train_path: "./data/peptides/train.csv"
  val_path: "./data/peptides/val.csv"
  test_path: "./data/peptides/test.csv"
  structure_dir: "./data/structures"
  
  # Data processing
  max_length: 50
  min_length: 5
  augmentation:
    enabled: true
    noise_level: 0.1
    mask_prob: 0.15
  
  # Dataloader
  batch_size: 32
  num_workers: 4
  pin_memory: true
  prefetch_factor: 2

training:
  num_epochs: 100
  gradient_accumulation_steps: 1
  max_grad_norm: 1.0
  
  # Optimizer
  optimizer:
    type: "AdamW"
    lr: 1e-4
    betas: [0.9, 0.999]
    weight_decay: 0.01
    eps: 1e-8
  
  # Scheduler
  scheduler:
    type: "cosine"
    num_warmup_steps: 1000
    num_training_steps: null  # Computed from epochs
    min_lr: 1e-6
  
  # Mixed precision
  use_amp: true
  amp_dtype: "float16"
  
  # EMA
  use_ema: true
  ema_decay: 0.9999
  ema_update_every: 10
  
  # Checkpointing
  save_every: 1000
  validate_every: 500
  log_every: 100
  max_checkpoints: 5
  
  # Early stopping
  early_stopping:
    enabled: true
    patience: 10
    metric: "val_loss"
    mode: "min"

diffusion:
  num_timesteps: 1000
  noise_schedule: "sqrt"
  beta_start: 0.0001
  beta_end: 0.02
  
  # Sampling
  sampling_method: "ddpm"
  ddim_steps: 50
  
  # Loss
  loss_type: "mse"
  auxiliary_loss_weight: 0.1

evaluation:
  metrics:
    - perplexity
    - accuracy
    - structure_consistency
    - diversity
  
  generation:
    num_samples: 100
    guidance_scale: 1.0
    temperature: 1.0

wandb:
  enabled: true
  project: "StructDiff"
  entity: null  # Your wandb entity
  tags: ["peptide", "diffusion", "structure"]
  
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
# Updated: 05/30/2025 22:59:09
