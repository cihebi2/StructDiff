experiment:
  name: "structdiff_minimal_test"
  output_dir: "./outputs"
  seed: 42

model:
  sequence_encoder:
    path: "facebook/esm2_t6_8M_UR50D"  # 最小的ESM模型
    pretrained_model: "facebook/esm2_t6_8M_UR50D"
    freeze_encoder: true  # 冻结预训练编码器以节省内存
    use_lora: false
  
  structure_encoder:
    type: "multi_scale"
    hidden_dim: 64  # 进一步减小隐藏维度
    use_esmfold: true  # 重新启用ESMFold
  
  denoiser:
    hidden_dim: 128  # 减小去噪器维度
    num_layers: 2    # 减少层数
    num_heads: 2     # 减少注意力头数
    dropout: 0.1
    use_cross_attention: false

data:
  train_path: "./data/processed/train.csv"
  val_path: "./data/processed/val.csv"
  test_path: "./data/processed/test.csv"
  batch_size: 1    # 减少到1以避免批次问题
  max_length: 15   # 进一步减小序列长度
  min_length: 8
  use_predicted_structures: true  # 重新启用结构预测
  augmentation:
    enable: false   # 禁用数据增强以节省计算

training:
  num_epochs: 2    # 只训练2个epoch
  gradient_accumulation_steps: 4  # 增加梯度累积以补偿小批量大小
  
  optimizer:
    lr: 5e-5        # 稍微降低学习率
    weight_decay: 0.01
  
  scheduler:
    type: "cosine"
    num_warmup_steps: 10
  
  use_amp: true     # 使用混合精度训练节省内存
  
  save_every: 50
  validate_every: 25
  log_every: 5

diffusion:
  num_timesteps: 50   # 大幅减少时间步数
  noise_schedule: "linear"
  beta_start: 0.0001
  beta_end: 0.02

training_config:
  loss_weights:
    diffusion_loss: 1.0
    structure_consistency_loss: 0.1  # 重新启用结构损失
    auxiliary_loss: 0.0

wandb:
  enabled: false 