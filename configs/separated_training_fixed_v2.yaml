classifier_free_guidance:
  adaptive_guidance: true
  dropout_prob: 0.1
  enabled: true
  guidance_scale: 2.0
  guidance_schedule: cosine
data:
  data_dir: ./data/processed
  max_length: 50
  min_length: 5
  num_workers: 0
  pin_memory: false
  structure_cache_dir: ./cache
  train_file: train.csv
  use_predicted_structures: false
  val_file: val.csv
debug:
  detailed_logging: true
  enabled: false
diffusion:
  beta_end: 0.02
  beta_start: 0.0001
  ddim_steps: 50
  noise_schedule: sqrt
  num_timesteps: 1000
  sampling_method: ddpm
evaluation:
  enabled: false
experiment:
  description: 修复维度和内存问题的最终版本
  name: structdiff_separated_fixed_v2
  project: StructDiff-Production
  seed: 42
length_control:
  analyze_training_data: true
  enabled: true
  length_penalty_weight: 0.1
  max_length: 50
  min_length: 5
  save_distributions: true
model:
  denoiser:
    dropout: 0.1
    hidden_dim: 320
    num_heads: 8
    num_layers: 6
    use_cross_attention: false
  sequence_decoder:
    dropout: 0.1
    hidden_dim: 320
    num_layers: 3
    vocab_size: 33
  sequence_encoder:
    freeze_encoder: false
    pretrained_model: facebook/esm2_t6_8M_UR50D
    use_lora: false
  structure_encoder:
    cache_dir: ./cache
    fusion:
      hidden_dim: 320
      method: attention
    global:
      dropout: 0.1
      hidden_dim: 320
      num_attention_heads: 8
      num_layers: 2
    hidden_dim: 320
    local:
      dropout: 0.1
      hidden_dim: 320
      kernel_sizes:
      - 3
      - 5
      num_layers: 2
    type: multi_scale
    use_cache: true
    use_esmfold: false
  type: StructDiff
monitoring:
  tensorboard:
    enabled: false
  wandb:
    enabled: false
output:
  base_dir: ./outputs/separated_fixed_v2
  checkpoint_dir: ./outputs/separated_fixed_v2/checkpoints
  log_dir: ./outputs/separated_fixed_v2/logs
  results_dir: ./outputs/separated_fixed_v2/results
  save_generated_samples: true
  save_model_config: true
  save_training_stats: true
resources:
  allow_growth: true
  available_gpus:
  - 2
  - 3
  - 4
  - 5
  device: cuda:2
  gpu_memory_fraction: 0.7
  num_threads: 4
  stage1_gpus:
  - 2
  - 3
  stage2_gpus:
  - 4
  - 5
separated_training:
  stage1:
    batch_size: 1
    epochs: 50
    gradient_clip: 1.0
    learning_rate: 0.0001
    optimizer:
      betas:
      - 0.9
      - 0.999
      eps: 1.0e-08
      type: AdamW
      weight_decay: 0.01
    scheduler:
      eta_min: 1.0e-06
      type: cosine
    warmup_steps: 200
  stage2:
    batch_size: 2
    epochs: 30
    gradient_clip: 0.5
    learning_rate: 5.0e-05
    optimizer:
      betas:
      - 0.9
      - 0.999
      eps: 1.0e-08
      type: AdamW
      weight_decay: 0.01
    scheduler:
      eta_min: 1.0e-06
      type: cosine
    warmup_steps: 100
training_enhancements:
  gradient_accumulation_steps: 8
  log_every: 20
  max_checkpoints: 3
  save_every: 1000
  use_amp: false
  use_ema: false
  validate_every: 200
