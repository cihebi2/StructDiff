#!/usr/bin/env python3

import torch
import pandas as pd
import numpy as np
from pathlib import Path
import sys
import os

# Add project root to path
sys.path.append('/home/qlyu/sequence/StructDiff-7.0.0')

from structdiff.data.dataset import PeptideStructureDataset
from structdiff.utils.config import load_config
from torch.utils.data import DataLoader

def custom_collate_fn(batch):
    """è‡ªå®šä¹‰æ‰¹å¤„ç†å‡½æ•°ï¼Œå¤„ç†å¯èƒ½çš„ç»“æ„ç‰¹å¾ä¸åŒ¹é…"""
    # æ”¶é›†æ‰€æœ‰é”®
    keys = batch[0].keys()
    result = {}
    
    for key in keys:
        if key == 'structures':
            # è·³è¿‡ç»“æ„ç‰¹å¾ï¼Œé¿å…å½¢çŠ¶ä¸åŒ¹é…é—®é¢˜
            continue
        elif key == 'sequence':
            # å­—ç¬¦ä¸²åˆ—è¡¨
            result[key] = [item[key] for item in batch]
        else:
            # å¼ é‡å †å 
            result[key] = torch.stack([item[key] for item in batch])
    
    return result

def debug_simple_training():
    """è°ƒè¯•ç®€åŒ–çš„è®­ç»ƒæµç¨‹"""
    print("ğŸš€ å¼€å§‹ç®€åŒ–è®­ç»ƒè°ƒè¯•...")
    
    try:
        # Load config
        config_path = "/home/qlyu/sequence/StructDiff-7.0.0/configs/separated_training.yaml"
        config = load_config(config_path)
        
        # å¼ºåˆ¶ç¦ç”¨ç»“æ„é¢„æµ‹
        config.data.use_predicted_structures = False
        
        print("âœ… é…ç½®åŠ è½½æˆåŠŸï¼Œå·²ç¦ç”¨ç»“æ„é¢„æµ‹")
        
        # Create dataset
        dataset = PeptideStructureDataset(
            data_path="/home/qlyu/sequence/StructDiff-7.0.0/data/processed/train.csv",
            config=config,
            is_training=True
        )
        
        print(f"âœ… æ•°æ®é›†åˆ›å»ºæˆåŠŸï¼Œå¤§å°: {len(dataset)}")
        
        # Create dataloader with custom collate function
        dataloader = DataLoader(
            dataset, 
            batch_size=4, 
            shuffle=False,
            collate_fn=custom_collate_fn
        )
        
        print("âœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºæˆåŠŸ")
        
        # Test batch loading
        batch = next(iter(dataloader))
        print(f"âœ… æ‰¹æ¬¡åŠ è½½æˆåŠŸï¼Œé”®: {batch.keys()}")
        
        for key, value in batch.items():
            if isinstance(value, torch.Tensor):
                print(f"  {key}: shape={value.shape}, dtype={value.dtype}")
                if key == 'label':
                    print(f"    labelå€¼: {value}")
            elif isinstance(value, list):
                print(f"  {key}: list of {len(value)} items")
        
        # Import model
        from structdiff.models.structdiff import StructDiff
        
        print("æ­£åœ¨åˆ›å»ºæ¨¡å‹...")
        model = StructDiff(config.model)
        print(f"âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸï¼Œå‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters())}")
        
        # Move to GPU (when CUDA_VISIBLE_DEVICES=1, the visible device index is 0)
        device = torch.device('cuda:0')
        model = model.to(device)
        
        # Move batch to GPU
        for key in batch:
            if isinstance(batch[key], torch.Tensor):
                batch[key] = batch[key].to(device)
        
        print("âœ… æ•°æ®å·²ç§»åŠ¨åˆ°GPU")
        
        # Test forward pass
        print("å°è¯•å‰å‘ä¼ æ’­...")
        
        with torch.no_grad():
            # Get sequence embeddings
            seq_embeddings = model.sequence_encoder(
                batch['sequences'], 
                attention_mask=batch['attention_mask']
            ).last_hidden_state
            
            print(f"âœ… åºåˆ—ç¼–ç æˆåŠŸ: {seq_embeddings.shape}")
            
            # Create dummy conditions
            conditions = {'peptide_type': batch['label']}
            
            # Try denoiser forward (without structure features)
            timesteps = torch.randint(0, 1000, (batch['sequences'].shape[0],), device=device)
            
            print("å°è¯•å»å™ªå™¨å‰å‘ä¼ æ’­ï¼ˆæ— ç»“æ„ç‰¹å¾ï¼‰...")
            denoised, _ = model.denoiser(
                seq_embeddings,
                timesteps,
                batch['attention_mask'],
                structure_features=None,  # æ˜ç¡®è®¾ç½®ä¸ºNone
                conditions=conditions
            )
            
            print(f"âœ… å»å™ªå™¨å‰å‘ä¼ æ’­æˆåŠŸ: {denoised.shape}")
            
            # Test training step
            print("å°è¯•è®­ç»ƒæ­¥éª¤...")
            model.train()
            
            # Add noise to embeddings
            noise = torch.randn_like(seq_embeddings)
            noisy_embeddings = seq_embeddings + noise
            
            # Forward pass with noise
            predicted_noise, _ = model.denoiser(
                noisy_embeddings,
                timesteps,
                batch['attention_mask'],
                structure_features=None,
                conditions=conditions
            )
            
            # Compute loss
            loss = torch.nn.functional.mse_loss(predicted_noise, noise)
            print(f"âœ… è®­ç»ƒæ­¥éª¤æˆåŠŸï¼ŒæŸå¤±: {loss.item():.6f}")
        
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼è®­ç»ƒåº”è¯¥å¯ä»¥æ­£å¸¸è¿›è¡Œã€‚")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    debug_simple_training() 