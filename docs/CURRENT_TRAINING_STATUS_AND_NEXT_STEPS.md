# å½“å‰è®­ç»ƒçŠ¶æ€ä¸ä¸‹ä¸€æ­¥è®¡åˆ’

## ğŸ“Š å½“å‰è®­ç»ƒçŠ¶æ€

### 1. æ­£åœ¨è¿è¡Œçš„è®­ç»ƒä»»åŠ¡

**è®­ç»ƒè„šæœ¬**: `full_train_200_epochs_with_esmfold_fixed.py`

**å½“å‰é…ç½®**:
```python
# è®­ç»ƒå‚æ•°
batch_size = 8
gradient_accumulation_steps = 2
effective_batch_size = 16
num_epochs = 200
learning_rate = 1e-4
scheduler = CosineAnnealingLR(T_max=200, eta_min=1e-6)

# æ¨¡å‹çŠ¶æ€
structure_features_enabled = False  # å½“å‰ç¦ç”¨
esmfold_status = "å¤‡ç”¨çŠ¶æ€"  # å·²åˆå§‹åŒ–ä½†æœªä½¿ç”¨
```

### 2. è®­ç»ƒè¿›åº¦ç›‘æ§

#### 2.1 å…³é”®æ–‡ä»¶ä½ç½®
```bash
# è®­ç»ƒæ—¥å¿—
/home/qlyu/sequence/StructDiff-7.0.0/outputs/full_training_200_esmfold_fixed/training.log

# æ£€æŸ¥ç‚¹ç›®å½•
/home/qlyu/sequence/StructDiff-7.0.0/outputs/full_training_200_esmfold_fixed/checkpoints/

# è®­ç»ƒæŒ‡æ ‡
/home/qlyu/sequence/StructDiff-7.0.0/outputs/full_training_200_esmfold_fixed/training_metrics.json
```

#### 2.2 ç›‘æ§å‘½ä»¤
```bash
# å®æ—¶æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
tail -f /home/qlyu/sequence/StructDiff-7.0.0/outputs/full_training_200_esmfold_fixed/training.log

# æŸ¥çœ‹GPUä½¿ç”¨æƒ…å†µ
watch -n 1 nvidia-smi

# æŸ¥çœ‹è®­ç»ƒè¿›ç¨‹
ps aux | grep python | grep full_train

# æŸ¥çœ‹å½“å‰è®­ç»ƒæŒ‡æ ‡
cat /home/qlyu/sequence/StructDiff-7.0.0/outputs/full_training_200_esmfold_fixed/training_metrics.json | jq '.'
```

### 3. é¢„æœŸè®­ç»ƒè¡¨ç°

#### 3.1 æŸå¤±æ”¶æ•›æ¨¡å¼
```
Epoch 1-20:   è®­ç»ƒæŸå¤± 1.0 â†’ 0.6    (å¿«é€Ÿä¸‹é™é˜¶æ®µ)
Epoch 21-50:  è®­ç»ƒæŸå¤± 0.6 â†’ 0.3    (ç¨³å®šä¸‹é™é˜¶æ®µ)
Epoch 51-100: è®­ç»ƒæŸå¤± 0.3 â†’ 0.2    (ç¼“æ…¢æ”¶æ•›é˜¶æ®µ)
Epoch 101-200: è®­ç»ƒæŸå¤± 0.2 â†’ 0.15  (ç²¾ç»†è°ƒä¼˜é˜¶æ®µ)
```

#### 3.2 ç³»ç»Ÿèµ„æºä½¿ç”¨
```
GPUå†…å­˜ä½¿ç”¨: ~4GB (ä¸å«ESMFold)
è®­ç»ƒé€Ÿåº¦: ~2-3ç§’/æ‰¹æ¬¡
æ¯epochæ—¶é—´: ~10-15åˆ†é’Ÿ
é¢„è®¡æ€»è®­ç»ƒæ—¶é—´: ~40-50å°æ—¶
```

## ğŸ¯ ä¸‹ä¸€æ­¥è®¡åˆ’

### é˜¶æ®µ1: å½“å‰è®­ç»ƒå®Œæˆ (é¢„è®¡1-2å¤©)

#### 1.1 ç­‰å¾…å½“å‰è®­ç»ƒå®Œæˆ
```bash
# ç›‘æ§è®­ç»ƒæ˜¯å¦å®Œæˆ
ls -la /home/qlyu/sequence/StructDiff-7.0.0/outputs/full_training_200_esmfold_fixed/final_model_epoch_200.pt

# æ£€æŸ¥æœ€ç»ˆæŒ‡æ ‡
cat /home/qlyu/sequence/StructDiff-7.0.0/outputs/full_training_200_esmfold_fixed/final_metrics.json
```

#### 1.2 è¯„ä¼°è®­ç»ƒç»“æœ
```python
# è¯„ä¼°è„šæœ¬
def evaluate_current_training():
    """è¯„ä¼°å½“å‰è®­ç»ƒç»“æœ"""
    
    # åŠ è½½æœ€ç»ˆæŒ‡æ ‡
    with open('final_metrics.json', 'r') as f:
        metrics = json.load(f)
    
    # æ£€æŸ¥æ”¶æ•›æƒ…å†µ
    final_train_loss = metrics['final_train_loss']
    best_val_loss = metrics['best_val_loss']
    
    print(f"æœ€ç»ˆè®­ç»ƒæŸå¤±: {final_train_loss:.6f}")
    print(f"æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.6f}")
    
    # åˆ¤æ–­æ˜¯å¦éœ€è¦ç»§ç»­è®­ç»ƒ
    if final_train_loss > 0.25:
        print("å»ºè®®ç»§ç»­è®­ç»ƒä»¥è·å¾—æ›´å¥½çš„æ”¶æ•›")
    elif final_train_loss < 0.15:
        print("è®­ç»ƒæ”¶æ•›è‰¯å¥½ï¼Œå¯ä»¥è¿›å…¥ä¸‹ä¸€é˜¶æ®µ")
    else:
        print("è®­ç»ƒæ”¶æ•›æ­£å¸¸ï¼Œå¯ä»¥è€ƒè™‘è¿›å…¥ä¸‹ä¸€é˜¶æ®µ")
```

### é˜¶æ®µ2: ç»“æ„ç‰¹å¾é›†æˆ (é¢„è®¡2-3å¤©)

#### 2.1 åˆ›å»ºç»“æ„ç‰¹å¾è®­ç»ƒè„šæœ¬
```python
# æ–‡ä»¶å: full_train_with_structure_features.py

def create_structure_training_script():
    """åˆ›å»ºåŒ…å«ç»“æ„ç‰¹å¾çš„è®­ç»ƒè„šæœ¬"""
    
    # åŸºäºå½“å‰è„šæœ¬ä¿®æ”¹
    script_content = """
#!/usr/bin/env python3

# åœ¨åŸæœ‰è„šæœ¬åŸºç¡€ä¸Šçš„ä¿®æ”¹
def full_train_with_structure_features():
    # å¯ç”¨ç»“æ„ç‰¹å¾
    config.data.use_predicted_structures = True
    config.model.structure_encoder.use_esmfold = True
    
    # è°ƒæ•´è®­ç»ƒå‚æ•°ä»¥é€‚åº”ESMFold
    batch_size = 2  # é™ä½æ‰¹æ¬¡å¤§å°
    gradient_accumulation_steps = 8  # å¢åŠ æ¢¯åº¦ç´¯ç§¯
    effective_batch_size = 16  # ä¿æŒç›¸åŒçš„æœ‰æ•ˆæ‰¹æ¬¡å¤§å°
    
    # ä»ä¹‹å‰çš„æ£€æŸ¥ç‚¹å¼€å§‹
    checkpoint_path = "outputs/full_training_200_esmfold_fixed/best_model.pt"
    
    # å…¶ä½™é€»è¾‘ä¿æŒä¸å˜...
"""
    
    return script_content
```

#### 2.2 æ¸è¿›å¼ç»“æ„ç‰¹å¾é›†æˆ
```python
# é˜¶æ®µ2A: ç»“æ„ç‰¹å¾é¢„è®­ç»ƒ (50 epochs)
def stage_2a_structure_pretraining():
    """ç»“æ„ç‰¹å¾é¢„è®­ç»ƒé˜¶æ®µ"""
    
    # é…ç½®
    config = {
        'epochs': 50,
        'batch_size': 2,
        'gradient_accumulation_steps': 8,
        'learning_rate': 5e-5,  # é™ä½å­¦ä¹ ç‡
        'structure_weight': 0.1,  # è¾ƒå°çš„ç»“æ„æŸå¤±æƒé‡
        'freeze_sequence_encoder': True  # å†»ç»“åºåˆ—ç¼–ç å™¨
    }
    
    # ä»æœ€ä½³æ£€æŸ¥ç‚¹å¼€å§‹
    start_from_checkpoint = "best_model.pt"

# é˜¶æ®µ2B: ç«¯åˆ°ç«¯å¾®è°ƒ (50 epochs)
def stage_2b_end_to_end_finetuning():
    """ç«¯åˆ°ç«¯å¾®è°ƒé˜¶æ®µ"""
    
    # é…ç½®
    config = {
        'epochs': 50,
        'batch_size': 2,
        'gradient_accumulation_steps': 8,
        'learning_rate': 1e-5,  # æ›´ä½çš„å­¦ä¹ ç‡
        'structure_weight': 0.2,  # å¢åŠ ç»“æ„æŸå¤±æƒé‡
        'freeze_sequence_encoder': False  # è§£å†»åºåˆ—ç¼–ç å™¨
    }
```

### é˜¶æ®µ3: ç”Ÿæˆå’Œè¯„ä¼° (é¢„è®¡1å¤©)

#### 3.1 ç”Ÿæˆæµ‹è¯•è„šæœ¬
```python
# æ–‡ä»¶å: test_generation.py

def test_peptide_generation():
    """æµ‹è¯•è‚½æ®µç”ŸæˆåŠŸèƒ½"""
    
    # åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
    model = StructDiff.from_pretrained("outputs/final_model/")
    diffusion = GaussianDiffusion(...)
    
    # ç”Ÿæˆä¸åŒç±»å‹çš„è‚½æ®µ
    test_conditions = [
        {'peptide_type': 0, 'length': 20},  # æŠ—èŒè‚½
        {'peptide_type': 1, 'length': 25},  # æŠ—çœŸèŒè‚½
        {'peptide_type': 2, 'length': 30},  # æŠ—ç—…æ¯’è‚½
    ]
    
    for condition in test_conditions:
        sequences = generate_peptides(
            model=model,
            diffusion=diffusion,
            num_samples=100,
            condition=condition
        )
        
        # è¯„ä¼°ç”Ÿæˆè´¨é‡
        evaluate_generated_sequences(sequences, condition)
```

#### 3.2 è¯„ä¼°æŒ‡æ ‡
```python
def evaluate_generated_sequences(sequences, condition):
    """è¯„ä¼°ç”Ÿæˆçš„åºåˆ—è´¨é‡"""
    
    metrics = {}
    
    # 1. åŸºæœ¬ç»Ÿè®¡
    metrics['num_sequences'] = len(sequences)
    metrics['avg_length'] = np.mean([len(seq) for seq in sequences])
    metrics['length_std'] = np.std([len(seq) for seq in sequences])
    
    # 2. åºåˆ—å¤šæ ·æ€§
    metrics['unique_sequences'] = len(set(sequences))
    metrics['diversity_ratio'] = metrics['unique_sequences'] / metrics['num_sequences']
    
    # 3. æ°¨åŸºé…¸ç»„æˆ
    all_aas = ''.join(sequences)
    aa_counts = Counter(all_aas)
    metrics['aa_distribution'] = dict(aa_counts)
    
    # 4. ç”Ÿç‰©å­¦è¯„ä¼° (å¦‚æœæœ‰å·¥å…·)
    # metrics['antimicrobial_score'] = predict_antimicrobial_activity(sequences)
    # metrics['toxicity_score'] = predict_toxicity(sequences)
    
    return metrics
```

## ğŸ› ï¸ å…·ä½“æ“ä½œæ­¥éª¤

### æ­¥éª¤1: ç›‘æ§å½“å‰è®­ç»ƒ

```bash
# 1. æ£€æŸ¥è®­ç»ƒæ˜¯å¦è¿˜åœ¨è¿è¡Œ
ps aux | grep full_train_200_epochs_with_esmfold_fixed

# 2. æŸ¥çœ‹æœ€æ–°æ—¥å¿—
tail -n 50 /home/qlyu/sequence/StructDiff-7.0.0/outputs/full_training_200_esmfold_fixed/training.log

# 3. æ£€æŸ¥GPUä½¿ç”¨æƒ…å†µ
nvidia-smi

# 4. æŸ¥çœ‹å½“å‰epochè¿›åº¦
grep "Epoch.*å®Œæˆ" /home/qlyu/sequence/StructDiff-7.0.0/outputs/full_training_200_esmfold_fixed/training.log | tail -5
```

### æ­¥éª¤2: å‡†å¤‡ä¸‹ä¸€é˜¶æ®µè®­ç»ƒ

```bash
# 1. åˆ›å»ºæ–°çš„è®­ç»ƒè„šæœ¬
cp full_train_200_epochs_with_esmfold_fixed.py full_train_with_structure_features.py

# 2. ä¿®æ”¹é…ç½®ä»¥å¯ç”¨ç»“æ„ç‰¹å¾
# (éœ€è¦æ‰‹åŠ¨ç¼–è¾‘è„šæœ¬)

# 3. åˆ›å»ºæ–°çš„è¾“å‡ºç›®å½•
mkdir -p outputs/structure_feature_training

# 4. å‡†å¤‡ä»æ£€æŸ¥ç‚¹æ¢å¤çš„è„šæœ¬
```

### æ­¥éª¤3: åˆ›å»ºç›‘æ§è„šæœ¬

```python
# æ–‡ä»¶å: monitor_training.py

import json
import time
import os
from datetime import datetime

def monitor_training_progress():
    """ç›‘æ§è®­ç»ƒè¿›åº¦"""
    
    log_file = "outputs/full_training_200_esmfold_fixed/training.log"
    metrics_file = "outputs/full_training_200_esmfold_fixed/training_metrics.json"
    
    while True:
        try:
            # æ£€æŸ¥æ—¥å¿—æ–‡ä»¶
            if os.path.exists(log_file):
                with open(log_file, 'r') as f:
                    lines = f.readlines()
                    if lines:
                        last_line = lines[-1]
                        print(f"[{datetime.now()}] æœ€æ–°æ—¥å¿—: {last_line.strip()}")
            
            # æ£€æŸ¥æŒ‡æ ‡æ–‡ä»¶
            if os.path.exists(metrics_file):
                with open(metrics_file, 'r') as f:
                    metrics = json.load(f)
                    current_epoch = metrics.get('epoch', 0)
                    current_loss = metrics.get('train_losses', [])
                    if current_loss:
                        print(f"[{datetime.now()}] å½“å‰epoch: {current_epoch}, æœ€æ–°æŸå¤±: {current_loss[-1]:.6f}")
            
            time.sleep(300)  # æ¯5åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
            
        except Exception as e:
            print(f"ç›‘æ§é”™è¯¯: {e}")
            time.sleep(60)

if __name__ == "__main__":
    monitor_training_progress()
```

### æ­¥éª¤4: åˆ›å»ºè‡ªåŠ¨åŒ–è„šæœ¬

```bash
# æ–‡ä»¶å: auto_training_pipeline.sh

#!/bin/bash

# è‡ªåŠ¨åŒ–è®­ç»ƒæµæ°´çº¿
echo "å¼€å§‹è‡ªåŠ¨åŒ–è®­ç»ƒæµæ°´çº¿..."

# 1. ç­‰å¾…å½“å‰è®­ç»ƒå®Œæˆ
echo "ç­‰å¾…å½“å‰è®­ç»ƒå®Œæˆ..."
while [ ! -f "outputs/full_training_200_esmfold_fixed/final_model_epoch_200.pt" ]; do
    echo "è®­ç»ƒä»åœ¨è¿›è¡Œä¸­ï¼Œç­‰å¾…ä¸­..."
    sleep 1800  # ç­‰å¾…30åˆ†é’Ÿ
done

echo "å½“å‰è®­ç»ƒå·²å®Œæˆï¼"

# 2. è¯„ä¼°è®­ç»ƒç»“æœ
echo "è¯„ä¼°è®­ç»ƒç»“æœ..."
python evaluate_training_results.py

# 3. å¼€å§‹ç»“æ„ç‰¹å¾è®­ç»ƒ
echo "å¼€å§‹ç»“æ„ç‰¹å¾è®­ç»ƒ..."
python full_train_with_structure_features.py

# 4. å®Œæˆåè¿›è¡Œç”Ÿæˆæµ‹è¯•
echo "è¿›è¡Œç”Ÿæˆæµ‹è¯•..."
python test_generation.py

echo "è‡ªåŠ¨åŒ–æµæ°´çº¿å®Œæˆï¼"
```

## ğŸ“‹ æ£€æŸ¥æ¸…å•

### å½“å‰é˜¶æ®µå®Œæˆæ ‡å‡†
- [ ] è®­ç»ƒæŸå¤±æ”¶æ•›åˆ° < 0.20
- [ ] éªŒè¯æŸå¤±ç¨³å®šä¸”æ— æ˜æ˜¾è¿‡æ‹Ÿåˆ
- [ ] ç”Ÿæˆ `final_model_epoch_200.pt` æ–‡ä»¶
- [ ] ç”Ÿæˆå®Œæ•´çš„è®­ç»ƒæŒ‡æ ‡æ–‡ä»¶

### ä¸‹ä¸€é˜¶æ®µå‡†å¤‡æ¸…å•
- [ ] åˆ›å»ºç»“æ„ç‰¹å¾è®­ç»ƒè„šæœ¬
- [ ] è®¾ç½®æ­£ç¡®çš„æ£€æŸ¥ç‚¹æ¢å¤è·¯å¾„
- [ ] è°ƒæ•´æ‰¹æ¬¡å¤§å°å’Œæ¢¯åº¦ç´¯ç§¯å‚æ•°
- [ ] å‡†å¤‡ç»“æ„ç‰¹å¾æå–å‡½æ•°
- [ ] è®¾ç½®å†…å­˜ä¼˜åŒ–ç­–ç•¥

### æœ€ç»ˆè¯„ä¼°æ¸…å•
- [ ] ç”Ÿæˆè´¨é‡è¯„ä¼°
- [ ] åºåˆ—å¤šæ ·æ€§åˆ†æ
- [ ] æ¡ä»¶æ§åˆ¶æ•ˆæœéªŒè¯
- [ ] ä¸åŸºçº¿æ¨¡å‹æ¯”è¾ƒ
- [ ] ç”Ÿç‰©å­¦æ´»æ€§é¢„æµ‹ï¼ˆå¦‚æœå¯èƒ½ï¼‰

## ğŸš¨ æ³¨æ„äº‹é¡¹

### 1. èµ„æºç®¡ç†
- å½“å‰è®­ç»ƒé¢„è®¡éœ€è¦40-50å°æ—¶
- ç»“æ„ç‰¹å¾è®­ç»ƒéœ€è¦æ›´å¤šGPUå†…å­˜
- å»ºè®®åœ¨è®­ç»ƒé—´éš™è¿›è¡Œç³»ç»Ÿç»´æŠ¤

### 2. å¤‡ä»½ç­–ç•¥
```bash
# å®šæœŸå¤‡ä»½é‡è¦æ–‡ä»¶
rsync -av outputs/ backup/outputs_$(date +%Y%m%d_%H%M%S)/
```

### 3. æ•…éšœæ¢å¤
```bash
# å¦‚æœè®­ç»ƒæ„å¤–ä¸­æ–­
python full_train_200_epochs_with_esmfold_fixed.py --resume_from_checkpoint outputs/full_training_200_esmfold_fixed/checkpoint_epoch_XXX.pt
```

### 4. ç›‘æ§å‘Šè­¦
```python
# ç®€å•çš„å‘Šè­¦è„šæœ¬
def check_training_health():
    """æ£€æŸ¥è®­ç»ƒå¥åº·çŠ¶æ€"""
    
    # æ£€æŸ¥GPUå†…å­˜
    gpu_mem = torch.cuda.memory_allocated() // 1024**3
    if gpu_mem > 20:  # è¶…è¿‡20GB
        send_alert("GPUå†…å­˜ä½¿ç”¨è¿‡é«˜")
    
    # æ£€æŸ¥æŸå¤±æ˜¯å¦å¼‚å¸¸
    if os.path.exists("training_metrics.json"):
        with open("training_metrics.json", "r") as f:
            metrics = json.load(f)
            recent_losses = metrics.get("train_losses", [])[-10:]
            if recent_losses and np.mean(recent_losses) > 1.0:
                send_alert("è®­ç»ƒæŸå¤±å¼‚å¸¸é«˜")
```

é€šè¿‡è¿™ä¸ªè¯¦ç»†çš„è®¡åˆ’ï¼Œæ‚¨å¯ä»¥ç³»ç»Ÿåœ°ç®¡ç†å½“å‰çš„è®­ç»ƒè¿‡ç¨‹ï¼Œå¹¶ä¸ºä¸‹ä¸€é˜¶æ®µçš„ç»“æ„ç‰¹å¾é›†æˆåšå¥½å‡†å¤‡ã€‚ 

graph TB
    A[å¼€å§‹è®­ç»ƒ] --> B[ç¯å¢ƒåˆå§‹åŒ–]
    B --> C[åŠ è½½é…ç½®æ–‡ä»¶]
    C --> D[åˆå§‹åŒ–ESMFold<br/>å¤‡ç”¨çŠ¶æ€]
    D --> E[åˆ›å»ºæ•°æ®é›†]
    E --> F[åˆ›å»ºæ•°æ®åŠ è½½å™¨]
    F --> G[åˆ›å»ºStructDiffæ¨¡å‹]
    G --> H[åˆ›å»ºæ‰©æ•£è¿‡ç¨‹]
    H --> I[è®¾ç½®ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨]
    I --> J[å¼€å§‹è®­ç»ƒå¾ªç¯]
    
    J --> K[éå†è®­ç»ƒæ‰¹æ¬¡]
    K --> L[è·å–åºåˆ—åµŒå…¥]
    L --> M[é‡‡æ ·æ—¶é—´æ­¥]
    M --> N[æ·»åŠ å™ªå£°]
    N --> O[å»å™ªé¢„æµ‹]
    O --> P[è®¡ç®—MSEæŸå¤±]
    P --> Q[åå‘ä¼ æ’­]
    Q --> R[æ¢¯åº¦ç´¯ç§¯]
    R --> S{æ˜¯å¦è¾¾åˆ°ç´¯ç§¯æ­¥æ•°?}
    S -->|æ˜¯| T[æ›´æ–°å‚æ•°]
    S -->|å¦| K
    T --> U[æ›´æ–°å­¦ä¹ ç‡]
    U --> V{æ˜¯å¦å®Œæˆepoch?}
    V -->|å¦| K
    V -->|æ˜¯| W[è®¡ç®—epochæŸå¤±]
    W --> X{æ˜¯å¦éœ€è¦éªŒè¯?}
    X -->|æ˜¯| Y[éªŒè¯æ­¥éª¤]
    X -->|å¦| Z
    Y --> Z{æ˜¯å¦éœ€è¦ä¿å­˜?}
    Z -->|æ˜¯| AA[ä¿å­˜æ£€æŸ¥ç‚¹]
    Z -->|å¦| BB
    AA --> BB{æ˜¯å¦å®Œæˆè®­ç»ƒ?}
    BB -->|å¦| J
    BB -->|æ˜¯| CC[ä¿å­˜æœ€ç»ˆæ¨¡å‹]
    CC --> DD[è®­ç»ƒå®Œæˆ]
    
    style A fill:#e1f5fe
    style DD fill:#c8e6c9
    style G fill:#fff3e0
    style H fill:#fff3e0
    style P fill:#ffebee