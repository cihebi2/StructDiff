# GPUåˆ©ç”¨ç‡ä¼˜åŒ–è®¡åˆ’

## ğŸš¨ å½“å‰é—®é¢˜åˆ†æ

### ç°çŠ¶
- **GPUåˆ©ç”¨ç‡**: ä»…14% (è¿œä½äºç†æƒ³çš„80-95%)
- **åŠŸç‡ä½¿ç”¨**: 88W / 450W (ä»…19%)
- **å†…å­˜ä½¿ç”¨**: 18GB / 24GB (75% - åˆç†)
- **è®­ç»ƒé€Ÿåº¦**: ~2ç§’/æ‰¹æ¬¡ (è¿‡æ…¢)

### æ ¹æœ¬åŸå› 
1. **æ•°æ®åŠ è½½ç“¶é¢ˆ** - å•çº¿ç¨‹åŠ è½½ï¼Œæ‰¹æ¬¡è¿‡å°
2. **ESMFoldè®¡ç®—ç“¶é¢ˆ** - CPUå¯†é›†å‹ç»“æ„é¢„æµ‹
3. **è®¡ç®—-å†…å­˜ä¸å¹³è¡¡** - é«˜å†…å­˜å ç”¨ä½†ä½è®¡ç®—å¼ºåº¦
4. **æœªå……åˆ†åˆ©ç”¨å¹¶è¡Œæ€§** - ä¿å®ˆçš„å¹¶å‘è®¾ç½®

## ğŸ“ˆ ä¼˜åŒ–ç­–ç•¥ä¸å®æ–½è®¡åˆ’

### ğŸ¯ ç›®æ ‡
- GPUåˆ©ç”¨ç‡: 14% â†’ 80%+
- åŠŸç‡ä½¿ç”¨: 88W â†’ 300W+
- è®­ç»ƒé€Ÿåº¦: 2ç§’/æ‰¹æ¬¡ â†’ 0.5ç§’/æ‰¹æ¬¡
- ä¿æŒå†…å­˜ä½¿ç”¨åœ¨å®‰å…¨èŒƒå›´å†…

---

## ğŸš€ ä¼˜åŒ–æ–¹æ¡ˆ

### 1. **æ•°æ®åŠ è½½ä¼˜åŒ–** (é¢„æœŸæå‡: 30-50%)

#### 1.1 å¤šè¿›ç¨‹æ•°æ®åŠ è½½
```python
# å½“å‰è®¾ç½®
train_loader = DataLoader(
    train_dataset,
    batch_size=2,
    num_workers=0,  # âŒ å•çº¿ç¨‹
    pin_memory=False  # âŒ æœªå¯ç”¨å†…å­˜å›ºå®š
)

# ä¼˜åŒ–åè®¾ç½®
train_loader = DataLoader(
    train_dataset,
    batch_size=4,  # å¢åŠ æ‰¹æ¬¡å¤§å°
    num_workers=4,  # âœ… å¤šè¿›ç¨‹åŠ è½½
    pin_memory=True,  # âœ… å¯ç”¨å†…å­˜å›ºå®š
    prefetch_factor=2,  # âœ… é¢„å–ç¼“å†²
    persistent_workers=True  # âœ… æŒä¹…åŒ–å·¥ä½œè¿›ç¨‹
)
```

#### 1.2 ç»“æ„ç‰¹å¾ç¼“å­˜ç­–ç•¥
```python
# å®ç°æ™ºèƒ½ç¼“å­˜ç³»ç»Ÿ
class StructureCacheManager:
    def __init__(self, cache_dir, max_cache_size=1000):
        self.cache_dir = cache_dir
        self.cache = {}
        self.max_size = max_cache_size
    
    def get_or_predict(self, sequence, esmfold_wrapper):
        seq_hash = hashlib.md5(sequence.encode()).hexdigest()
        cache_file = f"{self.cache_dir}/{seq_hash}.pkl"
        
        if os.path.exists(cache_file):
            # ä»ç¼“å­˜åŠ è½½
            with open(cache_file, 'rb') as f:
                return pickle.load(f)
        else:
            # é¢„æµ‹å¹¶ç¼“å­˜
            structure = esmfold_wrapper.predict_structure(sequence)
            with open(cache_file, 'wb') as f:
                pickle.dump(structure, f)
            return structure
```

### 2. **æ‰¹æ¬¡å¤§å°ä¼˜åŒ–** (é¢„æœŸæå‡: 40-60%)

#### 2.1 åŠ¨æ€æ‰¹æ¬¡å¤§å°è°ƒæ•´
```python
def optimize_batch_size():
    """åŠ¨æ€å¯»æ‰¾æœ€ä¼˜æ‰¹æ¬¡å¤§å°"""
    base_batch_size = 2
    max_batch_size = 16
    
    for batch_size in [2, 4, 6, 8, 12, 16]:
        try:
            # æµ‹è¯•æ‰¹æ¬¡å¤§å°
            test_batch = create_test_batch(batch_size)
            start_time = time.time()
            
            with torch.cuda.amp.autocast():
                outputs = model(test_batch)
                loss = outputs['total_loss']
                loss.backward()
            
            batch_time = time.time() - start_time
            memory_used = torch.cuda.memory_allocated() / 1e9
            
            if memory_used < 22:  # ä¿æŒ2GBå®‰å…¨è¾¹ç•Œ
                optimal_batch_size = batch_size
                logger.info(f"æ‰¹æ¬¡å¤§å° {batch_size}: æ—¶é—´={batch_time:.2f}s, å†…å­˜={memory_used:.1f}GB")
            else:
                break
                
        except RuntimeError as e:
            if "out of memory" in str(e):
                break
    
    return optimal_batch_size
```

#### 2.2 æ¢¯åº¦ç´¯ç§¯ä¼˜åŒ–
```python
# å½“å‰è®¾ç½®
batch_size = 2
gradient_accumulation_steps = 8
effective_batch_size = 16

# ä¼˜åŒ–è®¾ç½®
batch_size = 8  # å¢åŠ åˆ°8
gradient_accumulation_steps = 2  # å‡å°‘åˆ°2
effective_batch_size = 16  # ä¿æŒä¸å˜

# é¢„æœŸæ•ˆæœ: å‡å°‘æ¢¯åº¦ç´¯ç§¯æ¬¡æ•°ï¼Œå¢åŠ GPUè®¡ç®—å¯†åº¦
```

### 3. **æ··åˆç²¾åº¦è®­ç»ƒ** (é¢„æœŸæå‡: 20-30%)

#### 3.1 å¯ç”¨AMP (Automatic Mixed Precision)
```python
# æ·»åŠ åˆ°è®­ç»ƒå¾ªç¯
from torch.cuda.amp import autocast, GradScaler

scaler = GradScaler()

def optimized_training_step(model, batch, optimizer):
    with autocast():  # âœ… è‡ªåŠ¨æ··åˆç²¾åº¦
        outputs = model(
            sequences=batch['sequences'],
            attention_mask=batch['attention_mask'],
            timesteps=timesteps,
            structures=batch.get('structures'),
            conditions=batch.get('conditions'),
            return_loss=True
        )
        loss = outputs['total_loss'] / gradient_accumulation_steps
    
    # ç¼©æ”¾æŸå¤±å¹¶åå‘ä¼ æ’­
    scaler.scale(loss).backward()
    
    return outputs, loss.item() * gradient_accumulation_steps
```

#### 3.2 æ¨¡å‹ä¼˜åŒ–
```python
# å¯ç”¨ä¼˜åŒ–ç¼–è¯‘ (PyTorch 2.0+)
model = torch.compile(model, mode="reduce-overhead")

# æˆ–è€…ä½¿ç”¨æ›´æ¿€è¿›çš„ä¼˜åŒ–
model = torch.compile(model, mode="max-autotune")
```

### 4. **å¹¶è¡Œè®¡ç®—ä¼˜åŒ–** (é¢„æœŸæå‡: 25-40%)

#### 4.1 ESMFoldå¹¶è¡Œé¢„æµ‹
```python
class ParallelESMFoldWrapper:
    def __init__(self, device, num_parallel=2):
        self.device = device
        self.num_parallel = num_parallel
        self.esmfold_pool = []
        
        # åˆ›å»ºå¤šä¸ªESMFoldå®ä¾‹
        for i in range(num_parallel):
            esmfold = ESMFoldWrapper(device=f"cuda:{device}")
            self.esmfold_pool.append(esmfold)
    
    def predict_batch_parallel(self, sequences):
        """å¹¶è¡Œé¢„æµ‹å¤šä¸ªåºåˆ—çš„ç»“æ„"""
        from concurrent.futures import ThreadPoolExecutor
        
        def predict_single(seq_and_model):
            seq, model_idx = seq_and_model
            return self.esmfold_pool[model_idx].predict_structure(seq)
        
        # åˆ†é…åºåˆ—åˆ°ä¸åŒçš„ESMFoldå®ä¾‹
        seq_model_pairs = [
            (seq, i % self.num_parallel) 
            for i, seq in enumerate(sequences)
        ]
        
        with ThreadPoolExecutor(max_workers=self.num_parallel) as executor:
            results = list(executor.map(predict_single, seq_model_pairs))
        
        return results
```

#### 4.2 å¼‚æ­¥æ•°æ®é¢„å¤„ç†
```python
import asyncio
from concurrent.futures import ThreadPoolExecutor

class AsyncDataProcessor:
    def __init__(self, esmfold_wrapper, max_workers=4):
        self.esmfold_wrapper = esmfold_wrapper
        self.executor = ThreadPoolExecutor(max_workers=max_workers)
        self.cache = {}
    
    async def preprocess_batch_async(self, sequences):
        """å¼‚æ­¥é¢„å¤„ç†æ‰¹æ¬¡æ•°æ®"""
        loop = asyncio.get_event_loop()
        
        # å¹¶è¡Œå¤„ç†æ‰€æœ‰åºåˆ—
        tasks = [
            loop.run_in_executor(
                self.executor,
                self.process_single_sequence,
                seq
            ) for seq in sequences
        ]
        
        results = await asyncio.gather(*tasks)
        return results
    
    def process_single_sequence(self, sequence):
        """å¤„ç†å•ä¸ªåºåˆ—"""
        if sequence in self.cache:
            return self.cache[sequence]
        
        structure = self.esmfold_wrapper.predict_structure(sequence)
        self.cache[sequence] = structure
        return structure
```

### 5. **å†…å­˜-è®¡ç®—å¹³è¡¡ä¼˜åŒ–** (é¢„æœŸæå‡: 15-25%)

#### 5.1 æ¢¯åº¦æ£€æŸ¥ç‚¹ (Gradient Checkpointing)
```python
# åœ¨æ¨¡å‹åˆå§‹åŒ–æ—¶å¯ç”¨
from torch.utils.checkpoint import checkpoint

class OptimizedStructDiff(StructDiff):
    def forward(self, *args, **kwargs):
        # ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹å‡å°‘å†…å­˜ä½¿ç”¨
        if self.training:
            return checkpoint(super().forward, *args, **kwargs)
        else:
            return super().forward(*args, **kwargs)
```

#### 5.2 åŠ¨æ€å†…å­˜ç®¡ç†
```python
def dynamic_memory_management():
    """åŠ¨æ€å†…å­˜ç®¡ç†ç­–ç•¥"""
    allocated = torch.cuda.memory_allocated()
    reserved = torch.cuda.memory_reserved()
    
    # å¦‚æœå†…å­˜ä½¿ç”¨ç‡ä½äº70%ï¼Œå¯ä»¥å¢åŠ æ‰¹æ¬¡å¤§å°
    if allocated / (24 * 1024**3) < 0.7:
        return "increase_batch_size"
    
    # å¦‚æœå†…å­˜ä½¿ç”¨ç‡é«˜äº90%ï¼Œéœ€è¦æ¸…ç†
    elif allocated / (24 * 1024**3) > 0.9:
        torch.cuda.empty_cache()
        return "decrease_batch_size"
    
    return "maintain"
```

## ğŸ› ï¸ å®æ–½è®¡åˆ’

### é˜¶æ®µ1: å¿«é€Ÿä¼˜åŒ– (1-2å°æ—¶å®æ–½)

#### 1.1 åˆ›å»ºä¼˜åŒ–ç‰ˆæœ¬è®­ç»ƒè„šæœ¬
```python
# æ–‡ä»¶å: full_train_optimized_gpu_utilization.py

def create_optimized_training_script():
    """åˆ›å»ºGPUåˆ©ç”¨ç‡ä¼˜åŒ–ç‰ˆæœ¬"""
    
    # 1. å¢åŠ æ‰¹æ¬¡å¤§å°
    batch_size = 6  # ä»2å¢åŠ åˆ°6
    gradient_accumulation_steps = 3  # ç›¸åº”è°ƒæ•´
    
    # 2. å¯ç”¨å¤šè¿›ç¨‹æ•°æ®åŠ è½½
    num_workers = 4
    pin_memory = True
    prefetch_factor = 2
    
    # 3. å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
    use_amp = True
    
    # 4. ä¼˜åŒ–æ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=pin_memory,
        prefetch_factor=prefetch_factor,
        persistent_workers=True,
        collate_fn=collator,
        drop_last=True
    )
    
    return train_loader
```

#### 1.2 æ‰¹æ¬¡å¤§å°æµ‹è¯•è„šæœ¬
```python
# æ–‡ä»¶å: test_optimal_batch_size.py

def test_batch_sizes():
    """æµ‹è¯•ä¸åŒæ‰¹æ¬¡å¤§å°çš„æ€§èƒ½"""
    
    batch_sizes = [2, 4, 6, 8, 10, 12]
    results = {}
    
    for bs in batch_sizes:
        try:
            start_time = time.time()
            
            # åˆ›å»ºæµ‹è¯•æ‰¹æ¬¡
            test_batch = create_test_batch(bs)
            
            # æµ‹è¯•å‰å‘ä¼ æ’­
            with torch.cuda.amp.autocast():
                outputs = model(test_batch)
                loss = outputs['total_loss']
            
            # æµ‹è¯•åå‘ä¼ æ’­
            loss.backward()
            
            end_time = time.time()
            memory_used = torch.cuda.memory_allocated() / 1e9
            
            results[bs] = {
                'time': end_time - start_time,
                'memory': memory_used,
                'throughput': bs / (end_time - start_time)
            }
            
            print(f"æ‰¹æ¬¡å¤§å° {bs}: æ—¶é—´={end_time - start_time:.2f}s, "
                  f"å†…å­˜={memory_used:.1f}GB, "
                  f"ååé‡={bs / (end_time - start_time):.2f} samples/s")
            
            # æ¸…ç†æ¢¯åº¦å’Œå†…å­˜
            optimizer.zero_grad()
            torch.cuda.empty_cache()
            
        except RuntimeError as e:
            if "out of memory" in str(e):
                print(f"æ‰¹æ¬¡å¤§å° {bs}: å†…å­˜ä¸è¶³")
                break
            else:
                raise e
    
    return results
```

### é˜¶æ®µ2: ä¸­çº§ä¼˜åŒ– (åŠå¤©å®æ–½)

#### 2.1 ç»“æ„ç‰¹å¾ç¼“å­˜ç³»ç»Ÿ
- å®ç°æ™ºèƒ½ç¼“å­˜ç®¡ç†
- é¢„è®¡ç®—å¸¸è§åºåˆ—çš„ç»“æ„ç‰¹å¾
- å‡å°‘ESMFoldé‡å¤è®¡ç®—

#### 2.2 å¼‚æ­¥æ•°æ®å¤„ç†
- å®ç°å¼‚æ­¥æ•°æ®é¢„å¤„ç†
- å¹¶è¡Œç»“æ„é¢„æµ‹
- é‡å è®¡ç®—å’Œæ•°æ®åŠ è½½

### é˜¶æ®µ3: é«˜çº§ä¼˜åŒ– (1å¤©å®æ–½)

#### 3.1 æ¨¡å‹ç¼–è¯‘ä¼˜åŒ–
- ä½¿ç”¨PyTorch 2.0ç¼–è¯‘ä¼˜åŒ–
- è‡ªå®šä¹‰CUDAæ ¸å¿ƒï¼ˆå¦‚éœ€è¦ï¼‰
- ç®—å­èåˆä¼˜åŒ–

#### 3.2 å¤šGPUå¹¶è¡Œ (å¦‚æœéœ€è¦)
- æ•°æ®å¹¶è¡Œè®­ç»ƒ
- æ¨¡å‹å¹¶è¡Œï¼ˆé’ˆå¯¹å¤§æ¨¡å‹ï¼‰
- æµæ°´çº¿å¹¶è¡Œ

## ğŸ“Š é¢„æœŸæ•ˆæœ

### æ€§èƒ½æå‡é¢„æµ‹
| ä¼˜åŒ–é¡¹ç›® | å½“å‰çŠ¶æ€ | ä¼˜åŒ–å | æå‡å¹…åº¦ |
|---------|---------|--------|----------|
| GPUåˆ©ç”¨ç‡ | 14% | 75-85% | 5-6å€ |
| åŠŸç‡ä½¿ç”¨ | 88W | 280-320W | 3-4å€ |
| è®­ç»ƒé€Ÿåº¦ | 2.0s/æ‰¹æ¬¡ | 0.4-0.6s/æ‰¹æ¬¡ | 3-5å€ |
| å†…å­˜æ•ˆç‡ | ä¸­ç­‰ | é«˜ | 20-30% |
| æ€»è®­ç»ƒæ—¶é—´ | ~300å°æ—¶ | ~60-80å°æ—¶ | 4-5å€ |

### èµ„æºåˆ©ç”¨ç‡ç›®æ ‡
```
GPUåˆ©ç”¨ç‡: 75-85% (ç†æƒ³èŒƒå›´)
å†…å­˜ä½¿ç”¨: 20-22GB (ç•™2GBå®‰å…¨è¾¹ç•Œ)
åŠŸç‡ä½¿ç”¨: 280-320W (60-70%æœ€å¤§åŠŸç‡)
æ¸©åº¦: <75Â°C (å®‰å…¨èŒƒå›´)
```

## ğŸš€ ç«‹å³å¯æ‰§è¡Œçš„å¿«é€Ÿä¼˜åŒ–

### 1. æµ‹è¯•æœ€ä¼˜æ‰¹æ¬¡å¤§å°
```bash
cd /home/qlyu/sequence/StructDiff-7.0.0
python test_optimal_batch_size.py
```

### 2. åˆ›å»ºä¼˜åŒ–ç‰ˆæœ¬è®­ç»ƒè„šæœ¬
```bash
# åŸºäºå½“å‰è„šæœ¬åˆ›å»ºä¼˜åŒ–ç‰ˆæœ¬
cp full_train_with_structure_features_fixed_v2.py full_train_optimized_v1.py
# ç„¶åæ‰‹åŠ¨ç¼–è¾‘ä¼˜åŒ–å‚æ•°
```

### 3. ç›‘æ§ä¼˜åŒ–æ•ˆæœ
```bash
# å®æ—¶ç›‘æ§GPUåˆ©ç”¨ç‡
watch -n 1 nvidia-smi

# ç›‘æ§è®­ç»ƒé€Ÿåº¦
tail -f outputs/structure_feature_training_optimized/training.log
```

é€šè¿‡è¿™äº›ä¼˜åŒ–ï¼Œé¢„è®¡å¯ä»¥å°†GPUåˆ©ç”¨ç‡ä»14%æå‡åˆ°75%ä»¥ä¸Šï¼Œè®­ç»ƒé€Ÿåº¦æå‡3-5å€ï¼Œå¤§å¤§ç¼©çŸ­è®­ç»ƒæ—¶é—´ï¼ 