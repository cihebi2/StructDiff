# StructDiff å®Œæ•´æµæ°´çº¿ç³»ç»Ÿè¯¦è§£

## æ¦‚è¿°

`run_complete_pipeline.py` æ˜¯ StructDiff é¡¹ç›®çš„æ ¸å¿ƒé›†æˆè„šæœ¬ï¼Œå®ƒå°†è®­ç»ƒã€ç”Ÿæˆã€è¯„ä¼°ä¸‰ä¸ªé˜¶æ®µæ— ç¼è¿æ¥ï¼Œå½¢æˆä¸€ä¸ªç«¯åˆ°ç«¯çš„è‚½æ®µç”Ÿæˆå’Œè¯„ä¼°æµæ°´çº¿ã€‚è¯¥ç³»ç»ŸåŸºäº CPL-Diff å¯å‘çš„åˆ†ç¦»å¼è®­ç»ƒç­–ç•¥ï¼Œé›†æˆäº†æœ€æ–°çš„æ‰©æ•£æ¨¡å‹æŠ€æœ¯å’Œæ ‡å‡†åŒ–è¯„ä¼°ä½“ç³»ã€‚

---

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„æ€»è§ˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   å®Œæ•´æµæ°´çº¿ç³»ç»Ÿ                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   è®­ç»ƒé˜¶æ®µ       â”‚   ç”Ÿæˆé˜¶æ®µ       â”‚   è¯„ä¼°é˜¶æ®µ               â”‚
â”‚   Training      â”‚   Generation    â”‚   Evaluation            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ åˆ†ç¦»å¼è®­ç»ƒ     â”‚ â€¢ åºåˆ—ç”Ÿæˆ       â”‚ â€¢ CPL-Diffæ ‡å‡†è¯„ä¼°      â”‚
â”‚ â€¢ æ¨¡å‹æ£€æŸ¥ç‚¹     â”‚ â€¢ å¤šç±»å‹è‚½æ®µ     â”‚ â€¢ æ€§èƒ½æŒ‡æ ‡è®¡ç®—          â”‚
â”‚ â€¢ è®­ç»ƒç›‘æ§       â”‚ â€¢ é•¿åº¦æ§åˆ¶       â”‚ â€¢ æŠ¥å‘Šç”Ÿæˆ              â”‚
â”‚ â€¢ å®šæœŸè¯„ä¼°       â”‚ â€¢ å¼•å¯¼é‡‡æ ·       â”‚ â€¢ ç»“æœå¯è§†åŒ–            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“š æ ¸å¿ƒæ¨¡å—è¯¦è§£

### ğŸš€ 1. ä¸»æ§åˆ¶æ¨¡å—

#### `main()` - æµæ°´çº¿ä¸»å…¥å£

**åŠŸèƒ½**ï¼šåè°ƒæ•´ä¸ªæµæ°´çº¿çš„æ‰§è¡Œæµç¨‹

**æ‰§è¡Œæµç¨‹**ï¼š
```python
def main():
    args = parse_args()                    # 1. è§£æå‘½ä»¤è¡Œå‚æ•°
    experiment_info = setup_experiment()   # 2. è®¾ç½®å®éªŒç¯å¢ƒ
    config = load_config()                 # 3. åŠ è½½é…ç½®æ–‡ä»¶
    
    # 4. æ‰§è¡Œä¸‰é˜¶æ®µæµæ°´çº¿
    training_result = run_training_stage()
    generation_result = run_generation_stage()
    evaluation_result = run_evaluation_stage()
    
    # 5. ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
    generate_final_report()
```

**è¾“å…¥**ï¼š
- å‘½ä»¤è¡Œå‚æ•°
- é…ç½®æ–‡ä»¶è·¯å¾„
- æ•°æ®ç›®å½•è·¯å¾„

**è¾“å‡º**ï¼š
- å®Œæ•´çš„å®éªŒæŠ¥å‘Š
- ç»“æ„åŒ–çš„ç»“æœæ–‡ä»¶
- æ—¥å¿—å’Œç›‘æ§æ•°æ®

---

### ğŸ”§ 2. å®éªŒè®¾ç½®æ¨¡å—

#### `setup_experiment(args)` - å®éªŒç¯å¢ƒåˆå§‹åŒ–

**åŠŸèƒ½**ï¼šä¸ºæ•´ä¸ªæµæ°´çº¿åˆ›å»ºç»Ÿä¸€çš„å®éªŒç¯å¢ƒ

```python
def setup_experiment(args):
    """
    è®¾ç½®å®éªŒç¯å¢ƒï¼ŒåŒ…æ‹¬ï¼š
    - åˆ›å»ºå®éªŒç›®å½•ç»“æ„
    - é…ç½®æ—¥å¿—ç³»ç»Ÿ
    - è®¾ç½®éšæœºç§å­
    - æ£€æµ‹å’Œé…ç½®ç¡¬ä»¶è®¾å¤‡
    """
```

**è¾“å…¥å‚æ•°**ï¼š
```python
args = {
    'experiment_name': str,    # å®éªŒåç§°
    'output_dir': str,         # è¾“å‡ºæ ¹ç›®å½•
    'device': str,             # è®¾å¤‡ç±»å‹ (cuda/cpu/auto)
    'seed': int                # éšæœºç§å­
}
```

**æ‰§è¡Œé€»è¾‘**ï¼š
1. **ç›®å½•åˆ›å»º**ï¼š
   ```
   outputs/experiment_name/
   â”œâ”€â”€ training/          # è®­ç»ƒç›¸å…³æ–‡ä»¶
   â”œâ”€â”€ generation/        # ç”Ÿæˆçš„åºåˆ—
   â”œâ”€â”€ evaluation/        # è¯„ä¼°ç»“æœ
   â”œâ”€â”€ logs/             # æ—¥å¿—æ–‡ä»¶
   â””â”€â”€ reports/          # æœ€ç»ˆæŠ¥å‘Š
   ```

2. **æ—¥å¿—é…ç½®**ï¼š
   - è®¾ç½®ç»Ÿä¸€çš„æ—¥å¿—æ ¼å¼
   - é…ç½®æ–‡ä»¶å’Œæ§åˆ¶å°è¾“å‡º
   - è®°å½•å®éªŒå…ƒä¿¡æ¯

3. **è®¾å¤‡æ£€æµ‹**ï¼š
   ```python
   if args.device == "auto":
       device = "cuda" if torch.cuda.is_available() else "cpu"
   ```

**è¾“å‡º**ï¼š
```python
{
    "experiment_dir": Path,    # å®éªŒæ ¹ç›®å½•
    "device": str,             # æœ€ç»ˆä½¿ç”¨çš„è®¾å¤‡
    "experiment_name": str     # å®éªŒåç§°
}
```

---

### ğŸ“ 3. è®­ç»ƒé˜¶æ®µæ¨¡å—

#### `run_training_stage(args, config, experiment_info)` - åˆ†ç¦»å¼è®­ç»ƒæ‰§è¡Œ

**åŠŸèƒ½**ï¼šæ‰§è¡ŒåŸºäº CPL-Diff çš„ä¸¤é˜¶æ®µåˆ†ç¦»å¼è®­ç»ƒ

```python
def run_training_stage(args, config, experiment_info):
    """
    æ‰§è¡Œå®Œæ•´çš„åˆ†ç¦»å¼è®­ç»ƒæµç¨‹ï¼š
    1. æ¨¡å‹å’Œç»„ä»¶åˆå§‹åŒ–
    2. æ•°æ®åŠ è½½å™¨åˆ›å»º
    3. ä¸¤é˜¶æ®µè®­ç»ƒæ‰§è¡Œ
    4. æ£€æŸ¥ç‚¹ç®¡ç†
    5. è®­ç»ƒç›‘æ§å’Œè¯„ä¼°
    """
```

#### 3.1 æ¨¡å‹åˆå§‹åŒ–æµç¨‹

```python
# 1. åˆ†è¯å™¨åŠ è½½
tokenizer_name = config.model.sequence_encoder.pretrained_model
tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)

# 2. æ¨¡å‹åˆ›å»º
model = StructDiff(config.model).to(device)
diffusion = GaussianDiffusion(config.diffusion)

# 3. è®­ç»ƒç®¡ç†å™¨
trainer = SeparatedTrainingManager(
    config=training_config,
    model=model,
    diffusion=diffusion,
    device=device,
    tokenizer=tokenizer
)
```

#### 3.2 è®­ç»ƒé…ç½®æ˜ å°„

**ä»YAMLé…ç½®åˆ°è®­ç»ƒé…ç½®**ï¼š
```python
training_config = SeparatedTrainingConfig(
    # åŸºç¡€é…ç½®
    data_dir=args.data_dir,
    output_dir=experiment_dir / "training",
    checkpoint_dir=experiment_dir / "checkpoints",
    
    # è¯„ä¼°é…ç½®ï¼ˆæ–°å¢ï¼‰
    enable_evaluation=True,
    evaluate_every=5,
    auto_generate_after_training=True
)
```

#### 3.3 æ•°æ®åŠ è½½æµç¨‹

```python
# è®­ç»ƒæ•°æ®é›†
train_dataset = PeptideStructureDataset(
    data_path=data_dir / "train.csv",
    config=config,
    is_training=True
)

# éªŒè¯æ•°æ®é›†ï¼ˆå¯é€‰ï¼‰
if val_path.exists():
    val_dataset = PeptideStructureDataset(
        data_path=data_dir / "val.csv",
        config=config,
        is_training=False
    )
```

#### 3.4 ä¸¤é˜¶æ®µè®­ç»ƒæ‰§è¡Œ

**é˜¶æ®µ1ï¼šå»å™ªå™¨è®­ç»ƒ**
```python
# ç‰¹ç‚¹ï¼š
- å†»ç»“åºåˆ—ç¼–ç å™¨æƒé‡
- ä¸“æ³¨è®­ç»ƒå»å™ªèƒ½åŠ›
- ä½¿ç”¨è¾ƒé«˜å­¦ä¹ ç‡
- å®šæœŸè¿›è¡ŒCPL-Diffè¯„ä¼°

# è®­ç»ƒç›®æ ‡ï¼š
å­¦ä¹ ä»å™ªå£°ä¸­æ¢å¤æœ‰æ„ä¹‰çš„ç‰¹å¾è¡¨ç¤º
```

**é˜¶æ®µ2ï¼šè§£ç å™¨è®­ç»ƒ**
```python
# ç‰¹ç‚¹ï¼š
- å†»ç»“å»å™ªå™¨æƒé‡
- ä¸“æ³¨åºåˆ—é‡å»ºèƒ½åŠ›
- ä½¿ç”¨è¾ƒä½å­¦ä¹ ç‡
- æ›´å¤§çš„æ‰¹æ¬¡å¤§å°

# è®­ç»ƒç›®æ ‡ï¼š
å­¦ä¹ å°†ç‰¹å¾è¡¨ç¤ºè½¬æ¢ä¸ºæ°¨åŸºé…¸åºåˆ—
```

**è®­ç»ƒè¾“å…¥**ï¼š
- `train_loader`: è®­ç»ƒæ•°æ®åŠ è½½å™¨
- `val_loader`: éªŒè¯æ•°æ®åŠ è½½å™¨ï¼ˆå¯é€‰ï¼‰
- `config`: æ¨¡å‹å’Œè®­ç»ƒé…ç½®

**è®­ç»ƒè¾“å‡º**ï¼š
```python
{
    "training_stats": {
        "stage1": {
            "losses": [float],           # æ¯ä¸ªepochçš„æŸå¤±
            "val_losses": [float],       # éªŒè¯æŸå¤±
            "evaluations": [dict],       # å®šæœŸè¯„ä¼°ç»“æœ
            "final_evaluation": dict     # é˜¶æ®µç»“æŸè¯„ä¼°
        },
        "stage2": {
            # åŒstage1ç»“æ„
        }
    },
    "checkpoint_path": str,              # æœ€ä½³æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„
    "training_config": SeparatedTrainingConfig
}
```

---

### ğŸ¯ 4. ç”Ÿæˆé˜¶æ®µæ¨¡å—

#### `run_generation_stage(args, config, experiment_info, training_result)` - åºåˆ—ç”Ÿæˆæ‰§è¡Œ

**åŠŸèƒ½**ï¼šåŸºäºè®­ç»ƒå¥½çš„æ¨¡å‹ç”Ÿæˆå¤šç§ç±»å‹çš„è‚½æ®µåºåˆ—

```python
def run_generation_stage(args, config, experiment_info, training_result):
    """
    æ‰§è¡Œåºåˆ—ç”Ÿæˆæµç¨‹ï¼š
    1. åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
    2. é…ç½®ç”Ÿæˆå‚æ•°
    3. æ‰¹é‡ç”Ÿæˆä¸åŒç±»å‹è‚½æ®µ
    4. åºåˆ—åå¤„ç†å’Œä¿å­˜
    """
```

#### 4.1 æ¨¡å‹åŠ è½½æµç¨‹

```python
# 1. æ£€æŸ¥ç‚¹éªŒè¯
checkpoint_path = training_result.get("checkpoint_path")
if not checkpoint_path or not Path(checkpoint_path).exists():
    logger.error("æ— æ³•æ‰¾åˆ°æœ‰æ•ˆçš„æ£€æŸ¥ç‚¹æ–‡ä»¶")
    return None

# 2. æ¨¡å‹é‡å»ºå’Œæƒé‡åŠ è½½
checkpoint = torch.load(checkpoint_path, map_location=device)
model = StructDiff(config.model).to(device)
model.load_state_dict(checkpoint['model_state_dict'])
model.eval()

# 3. ç»„ä»¶åˆå§‹åŒ–
diffusion = GaussianDiffusion(config.diffusion)
tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)
```

#### 4.2 ç”Ÿæˆæµç¨‹è¯¦è§£

**å¤šç±»å‹ç”Ÿæˆå¾ªç¯**ï¼š
```python
for peptide_type in args.peptide_types:  # ['antimicrobial', 'antifungal', 'antiviral']
    logger.info(f"ç”Ÿæˆ {peptide_type} è‚½æ®µ...")
    
    sequences = []
    with torch.no_grad():
        for i in range(0, args.num_samples, 10):  # æ‰¹æ¬¡ç”Ÿæˆ
            # 1. é•¿åº¦é‡‡æ ·
            length = torch.randint(10, 30, (1,)).item()
            
            # 2. å™ªå£°åˆå§‹åŒ–
            seq_embeddings = torch.randn(1, length, hidden_size, device=device)
            attention_mask = torch.ones(1, length, device=device)
            
            # 3. æ‰©æ•£å»å™ªè¿‡ç¨‹
            for t in reversed(range(0, 1000, 50)):  # DDIMé‡‡æ ·
                timesteps = torch.tensor([t], device=device)
                noise_pred = model.denoiser(seq_embeddings, timesteps, attention_mask)
                seq_embeddings = seq_embeddings - 0.01 * noise_pred
            
            # 4. åºåˆ—è§£ç 
            sequence = decode_sequence(seq_embeddings, attention_mask, model, tokenizer)
            
            if sequence and len(sequence) >= 5:
                sequences.append(sequence)
```

**åºåˆ—è§£ç æœºåˆ¶**ï¼š
```python
def decode_sequence(embeddings, attention_mask, model, tokenizer):
    """
    å¤šå±‚è§£ç ç­–ç•¥ï¼š
    1. ä¼˜å…ˆä½¿ç”¨è®­ç»ƒçš„åºåˆ—è§£ç å™¨
    2. å›é€€åˆ°ç›¸ä¼¼æ€§åŒ¹é…è§£ç 
    3. æœ€åä½¿ç”¨éšæœºå›é€€æ–¹æ¡ˆ
    """
    
    # æ–¹æ³•1ï¼šå­¦ä¹ åŒ–è§£ç 
    if hasattr(model, 'sequence_decoder') and model.sequence_decoder:
        logits = model.sequence_decoder(embeddings, attention_mask)
        token_ids = torch.argmax(logits, dim=-1)
        sequence = tokenizer.decode(token_ids, skip_special_tokens=True)
        
    # æ–¹æ³•2ï¼šç›¸ä¼¼æ€§è§£ç ï¼ˆå›é€€ï¼‰
    else:
        # åŸºäºåµŒå…¥ç›¸ä¼¼æ€§çš„è§£ç é€»è¾‘
        
    # æ–¹æ³•3ï¼šéšæœºå›é€€
    # ...
    
    # åºåˆ—æ¸…ç†
    amino_acids = set('ACDEFGHIKLMNPQRSTVWY')
    clean_sequence = ''.join([c for c in sequence.upper() if c in amino_acids])
    return clean_sequence
```

#### 4.3 åºåˆ—ä¿å­˜å’Œç»„ç»‡

```python
# ä¸ºæ¯ç§è‚½æ®µç±»å‹ä¿å­˜åºåˆ—
output_file = generation_dir / f"{peptide_type}_sequences.fasta"
with open(output_file, 'w') as f:
    for i, seq in enumerate(sequences):
        f.write(f">{peptide_type}_{i}\n{seq}\n")

all_generated[peptide_type] = {
    "sequences": sequences,      # åºåˆ—åˆ—è¡¨
    "count": len(sequences),     # åºåˆ—æ•°é‡
    "file": str(output_file)     # æ–‡ä»¶è·¯å¾„
}
```

**ç”Ÿæˆè¾“å…¥**ï¼š
- `checkpoint_path`: è®­ç»ƒå¥½çš„æ¨¡å‹æ£€æŸ¥ç‚¹
- `args.peptide_types`: è¦ç”Ÿæˆçš„è‚½æ®µç±»å‹åˆ—è¡¨
- `args.num_samples`: æ¯ç§ç±»å‹çš„ç”Ÿæˆæ•°é‡
- `config`: æ¨¡å‹å’Œç”Ÿæˆé…ç½®

**ç”Ÿæˆè¾“å‡º**ï¼š
```python
{
    "antimicrobial": {
        "sequences": [str],      # ç”Ÿæˆçš„åºåˆ—åˆ—è¡¨
        "count": int,            # åºåˆ—æ•°é‡
        "file": str              # FASTAæ–‡ä»¶è·¯å¾„
    },
    "antifungal": { ... },
    "antiviral": { ... }
}
```

---

### ğŸ”¬ 5. è¯„ä¼°é˜¶æ®µæ¨¡å—

#### `run_evaluation_stage(args, experiment_info, generation_result)` - CPL-Diffæ ‡å‡†è¯„ä¼°

**åŠŸèƒ½**ï¼šå¯¹ç”Ÿæˆçš„åºåˆ—è¿›è¡Œå…¨é¢çš„è´¨é‡è¯„ä¼°

```python
def run_evaluation_stage(args, experiment_info, generation_result):
    """
    æ‰§è¡ŒCPL-Diffæ ‡å‡†è¯„ä¼°æµç¨‹ï¼š
    1. åˆå§‹åŒ–è¯„ä¼°å™¨
    2. åŠ è½½ç”Ÿæˆçš„åºåˆ—
    3. è¿è¡Œäº”å¤§æ ¸å¿ƒæŒ‡æ ‡è¯„ä¼°
    4. ç”Ÿæˆè¯¦ç»†è¯„ä¼°æŠ¥å‘Š
    """
```

#### 5.1 è¯„ä¼°å™¨åˆå§‹åŒ–

```python
evaluation_dir = experiment_info["experiment_dir"] / "evaluation"
evaluator = CPLDiffStandardEvaluator(output_dir=str(evaluation_dir))
```

#### 5.2 è¯„ä¼°å¾ªç¯æ‰§è¡Œ

```python
all_evaluations = {}

for peptide_type, gen_data in generation_result.items():
    sequences = gen_data["sequences"]
    
    # CPL-Diffæ ‡å‡†è¯„ä¼°
    eval_results = evaluator.comprehensive_cpldiff_evaluation(
        generated_sequences=sequences,
        reference_sequences=[],          # ä½¿ç”¨å†…ç½®å‚è€ƒåºåˆ—
        peptide_type=peptide_type
    )
    
    # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
    report_name = f"{experiment_name}_{peptide_type}"
    evaluator.generate_cpldiff_report(eval_results, report_name)
    
    all_evaluations[peptide_type] = eval_results
```

#### 5.3 CPL-Diff äº”å¤§æ ¸å¿ƒæŒ‡æ ‡

**1. Pseudo Perplexity (ä¼ªå›°æƒ‘åº¦)**
```python
æŒ‡æ ‡å«ä¹‰: ä½¿ç”¨ESM-2è®¡ç®—çš„åºåˆ—è‡ªç„¶åº¦
æœŸæœ›å€¼: è¶Šä½è¶Šå¥½ (â†“)
è®¡ç®—æ–¹æ³•: åŸºäºESM-2çš„æ¡ä»¶æ¦‚ç‡
è´¨é‡æŒ‡ç¤º: åºåˆ—çš„ç”Ÿç‰©å­¦åˆç†æ€§
```

**2. pLDDT Score (ç»“æ„ç½®ä¿¡åº¦)**
```python
æŒ‡æ ‡å«ä¹‰: ESMFoldé¢„æµ‹çš„ç»“æ„ç½®ä¿¡åº¦
æœŸæœ›å€¼: è¶Šé«˜è¶Šå¥½ (â†‘)
è®¡ç®—æ–¹æ³•: ESMFoldé¢„æµ‹ç½®ä¿¡åº¦çš„å¹³å‡å€¼
è´¨é‡æŒ‡ç¤º: åºåˆ—å¯æŠ˜å æ€§å’Œç»“æ„ç¨³å®šæ€§
```

**3. Instability Index (ä¸ç¨³å®šæ€§æŒ‡æ•°)**
```python
æŒ‡æ ‡å«ä¹‰: modlAMPè®¡ç®—çš„è›‹ç™½è´¨ç¨³å®šæ€§
æœŸæœ›å€¼: è¶Šä½è¶Šå¥½ (â†“)
è®¡ç®—æ–¹æ³•: åŸºäºæ°¨åŸºé…¸ç»„æˆçš„ç¨³å®šæ€§é¢„æµ‹
è´¨é‡æŒ‡ç¤º: è›‹ç™½è´¨åœ¨ä½“å†…çš„ç¨³å®šæ€§
```

**4. Similarity Score (ç›¸ä¼¼æ€§è¯„åˆ†)**
```python
æŒ‡æ ‡å«ä¹‰: ä¸å·²çŸ¥åºåˆ—çš„BLOSUM62ç›¸ä¼¼æ€§
æœŸæœ›å€¼: è¶Šä½è¶Šå¥½ (â†“) - è¡¨ç¤ºæ›´é«˜çš„æ–°é¢–æ€§
è®¡ç®—æ–¹æ³•: BLOSUM62çŸ©é˜µè®¡ç®—åºåˆ—ç›¸ä¼¼æ€§
è´¨é‡æŒ‡ç¤º: ç”Ÿæˆåºåˆ—çš„æ–°é¢–æ€§å’Œå¤šæ ·æ€§
```

**5. Activity Prediction (æ´»æ€§é¢„æµ‹)**
```python
æŒ‡æ ‡å«ä¹‰: å¤–éƒ¨åˆ†ç±»å™¨é¢„æµ‹çš„ç”Ÿç‰©æ´»æ€§
æœŸæœ›å€¼: è¶Šé«˜è¶Šå¥½ (â†‘)
è®¡ç®—æ–¹æ³•: ä½¿ç”¨é¢„è®­ç»ƒçš„æ´»æ€§é¢„æµ‹æ¨¡å‹
è´¨é‡æŒ‡ç¤º: åºåˆ—çš„åŠŸèƒ½æ´»æ€§æ½œåŠ›
```

#### 5.4 è¯„ä¼°æŠ¥å‘Šç”Ÿæˆ

**HTMLæŠ¥å‘Šç»“æ„**ï¼š
```html
è¯„ä¼°æŠ¥å‘ŠåŒ…å«ï¼š
â”œâ”€â”€ æ‰§è¡Œæ‘˜è¦ (Executive Summary)
â”œâ”€â”€ æ ¸å¿ƒæŒ‡æ ‡æ€»è§ˆ (Core Metrics Overview)
â”œâ”€â”€ è¯¦ç»†æŒ‡æ ‡åˆ†æ (Detailed Analysis)
â”‚   â”œâ”€â”€ ä¼ªå›°æƒ‘åº¦åˆ†å¸ƒå›¾
â”‚   â”œâ”€â”€ pLDDTåˆ†æ•°åˆ†å¸ƒ
â”‚   â”œâ”€â”€ ç¨³å®šæ€§åˆ†æ
â”‚   â”œâ”€â”€ ç›¸ä¼¼æ€§çƒ­å›¾
â”‚   â””â”€â”€ æ´»æ€§é¢„æµ‹ç»“æœ
â”œâ”€â”€ åºåˆ—è´¨é‡åˆ†æ (Sequence Quality Analysis)
â”œâ”€â”€ å¯¹æ¯”åˆ†æ (Comparative Analysis)
â””â”€â”€ ç»“è®ºå’Œå»ºè®® (Conclusions & Recommendations)
```

**è¯„ä¼°è¾“å…¥**ï¼š
- `generation_result`: ç”Ÿæˆçš„åºåˆ—æ•°æ®
- `peptide_type`: è‚½æ®µç±»å‹
- `evaluation_dir`: è¯„ä¼°ç»“æœè¾“å‡ºç›®å½•

**è¯„ä¼°è¾“å‡º**ï¼š
```python
{
    "antimicrobial": {
        "cpldiff_core_metrics": {
            "pseudo_perplexity": {
                "mean_pseudo_perplexity": float,
                "std_pseudo_perplexity": float,
                "distribution": [float]
            },
            "plddt": {
                "mean_plddt": float,
                "std_plddt": float,
                "high_confidence_ratio": float  # pLDDT > 70çš„æ¯”ä¾‹
            },
            "instability": {
                "mean_instability": float,
                "stable_ratio": float           # ç¨³å®šåºåˆ—æ¯”ä¾‹
            },
            "similarity": {
                "mean_similarity": float,
                "novelty_ratio": float          # ä½ç›¸ä¼¼æ€§åºåˆ—æ¯”ä¾‹
            },
            "activity": {
                "mean_activity_score": float,
                "active_ratio": float           # é«˜æ´»æ€§åºåˆ—æ¯”ä¾‹
            }
        },
        "additional_metrics": {
            "information_entropy": float,
            "amino_acid_diversity": float,
            "length_distribution": dict
        },
        "quality_summary": {
            "overall_score": float,             # ç»¼åˆè´¨é‡è¯„åˆ†
            "grade": str,                       # è´¨é‡ç­‰çº§ (A/B/C/D)
            "recommendations": [str]            # æ”¹è¿›å»ºè®®
        }
    }
}
```

---

### ğŸ“Š 6. æŠ¥å‘Šç”Ÿæˆæ¨¡å—

#### `generate_final_report(args, experiment_info, results)` - ç»¼åˆæŠ¥å‘Šç”Ÿæˆ

**åŠŸèƒ½**ï¼šæ•´åˆæ‰€æœ‰é˜¶æ®µçš„ç»“æœï¼Œç”Ÿæˆå…¨é¢çš„å®éªŒæŠ¥å‘Š

```python
def generate_final_report(args, experiment_info, results):
    """
    ç”Ÿæˆæœ€ç»ˆå®éªŒæŠ¥å‘Šï¼š
    1. æ•´åˆä¸‰é˜¶æ®µç»“æœæ•°æ®
    2. ç”ŸæˆJSONè¯¦ç»†æŠ¥å‘Š
    3. ç”Ÿæˆæ–‡æœ¬æ‘˜è¦æŠ¥å‘Š
    4. åˆ›å»ºå¯è§†åŒ–å›¾è¡¨
    """
```

#### 6.1 æŠ¥å‘Šæ•°æ®ç»“æ„

```python
report_data = {
    "experiment_info": {
        "name": str,                    # å®éªŒåç§°
        "timestamp": str,               # æ‰§è¡Œæ—¶é—´
        "config": dict,                 # å®Œæ•´é…ç½®
        "device": str,                  # ä½¿ç”¨è®¾å¤‡
        "duration": float               # æ‰§è¡Œæ—¶é•¿
    },
    "pipeline_results": {
        "training": {
            "stage1_stats": dict,       # é˜¶æ®µ1è®­ç»ƒç»Ÿè®¡
            "stage2_stats": dict,       # é˜¶æ®µ2è®­ç»ƒç»Ÿè®¡
            "checkpoint_path": str,     # æœ€ä½³æ£€æŸ¥ç‚¹
            "training_duration": float  # è®­ç»ƒæ—¶é•¿
        },
        "generation": {
            "antimicrobial": dict,      # æŠ—èŒè‚½ç”Ÿæˆç»“æœ
            "antifungal": dict,         # æŠ—çœŸèŒè‚½ç”Ÿæˆç»“æœ
            "antiviral": dict,          # æŠ—ç—…æ¯’è‚½ç”Ÿæˆç»“æœ
            "generation_duration": float
        },
        "evaluation": {
            "antimicrobial": dict,      # æŠ—èŒè‚½è¯„ä¼°ç»“æœ
            "antifungal": dict,         # æŠ—çœŸèŒè‚½è¯„ä¼°ç»“æœ
            "antiviral": dict,          # æŠ—ç—…æ¯’è‚½è¯„ä¼°ç»“æœ
            "evaluation_duration": float
        }
    }
}
```

#### 6.2 JSONè¯¦ç»†æŠ¥å‘Š

**æ–‡ä»¶**ï¼š`final_report.json`

**å†…å®¹**ï¼šåŒ…å«æ‰€æœ‰åŸå§‹æ•°æ®ã€ç»Ÿè®¡ä¿¡æ¯ã€é…ç½®å‚æ•°çš„å®Œæ•´è®°å½•

**ç”¨é€”**ï¼šç¨‹åºåŒ–åˆ†æã€æ•°æ®æŒ–æ˜ã€ç»“æœæ¯”è¾ƒ

#### 6.3 æ–‡æœ¬æ‘˜è¦æŠ¥å‘Š

**æ–‡ä»¶**ï¼š`final_report.txt`

**å†…å®¹ç¤ºä¾‹**ï¼š
```text
StructDiffå®Œæ•´æµæ°´çº¿å®éªŒæŠ¥å‘Š
==================================================

å®éªŒåç§°: peptide_generation_20231201
æ‰§è¡Œæ—¶é—´: 2023-12-01 14:30:25
è®¾å¤‡: NVIDIA RTX 4090
æ€»è€—æ—¶: 4.5å°æ—¶

è®­ç»ƒé˜¶æ®µç»“æœ:
--------------------
é˜¶æ®µ1 - å»å™ªå™¨è®­ç»ƒ:
  æœ€ç»ˆæŸå¤±: 0.0245
  éªŒè¯æŸå¤±: 0.0312
  è®­ç»ƒè½®æ•°: 200
  è¯„ä¼°æ¬¡æ•°: 40

é˜¶æ®µ2 - è§£ç å™¨è®­ç»ƒ:
  æœ€ç»ˆæŸå¤±: 0.0156
  éªŒè¯æŸå¤±: 0.0203
  è®­ç»ƒè½®æ•°: 100
  è¯„ä¼°æ¬¡æ•°: 20

ç”Ÿæˆé˜¶æ®µç»“æœ:
--------------------
æŠ—èŒè‚½: 1000 ä¸ªåºåˆ—
æŠ—çœŸèŒè‚½: 1000 ä¸ªåºåˆ—
æŠ—ç—…æ¯’è‚½: 1000 ä¸ªåºåˆ—
æ€»ç”Ÿæˆæ—¶é—´: 15åˆ†é’Ÿ

è¯„ä¼°é˜¶æ®µç»“æœ:
--------------------
æŠ—èŒè‚½è´¨é‡è¯„ä¼°:
  ä¼ªå›°æƒ‘åº¦: 8.45 (â†“è¶Šä½è¶Šå¥½)
  pLDDTåˆ†æ•°: 72.8 (â†‘è¶Šé«˜è¶Šå¥½)
  ä¸ç¨³å®šæ€§: 32.1 (â†“è¶Šä½è¶Šå¥½)
  ç›¸ä¼¼æ€§: 0.23 (â†“è¶Šä½è¶Šå¥½ï¼Œè¡¨ç¤ºæ–°é¢–æ€§)
  æ´»æ€§é¢„æµ‹: 0.78 (â†‘è¶Šé«˜è¶Šå¥½)
  
  ç»¼åˆè¯„åˆ†: B+ (85/100)
  æ¨èåº¦: é«˜è´¨é‡ï¼Œå»ºè®®è¿›ä¸€æ­¥å®éªŒéªŒè¯

æŠ—çœŸèŒè‚½è´¨é‡è¯„ä¼°:
  ...

æŠ—ç—…æ¯’è‚½è´¨é‡è¯„ä¼°:
  ...

ç»“è®ºä¸å»ºè®®:
--------------------
1. æ¨¡å‹åœ¨æŠ—èŒè‚½ç”Ÿæˆæ–¹é¢è¡¨ç°æœ€ä½³
2. å»ºè®®è°ƒæ•´æŠ—çœŸèŒè‚½çš„è®­ç»ƒå‚æ•°
3. åºåˆ—å¤šæ ·æ€§è‰¯å¥½ï¼Œæ–°é¢–æ€§è¾ƒé«˜
4. æ¨èè¿›è¡Œæ¹¿å®éªŒéªŒè¯å‰10%çš„é«˜è´¨é‡åºåˆ—

è¯¦ç»†ç»“æœè¯·æŸ¥çœ‹ç›¸åº”ç›®å½•ä¸­çš„å…·ä½“æ–‡ä»¶ã€‚
```

---

## ğŸ”„ æ¨¡å—é—´çš„æ•°æ®æµ

### æ•°æ®æµå‘å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ é…ç½®æ–‡ä»¶     â”‚â”€â”€â”€â†’â”‚ å®éªŒç¯å¢ƒè®¾ç½®  â”‚â”€â”€â”€â†’â”‚ å…¨å±€é…ç½®     â”‚
â”‚ YAML        â”‚    â”‚ setup_exp    â”‚    â”‚ experiment  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ è®­ç»ƒæ•°æ®     â”‚â”€â”€â”€â†’â”‚ è®­ç»ƒé˜¶æ®µ     â”‚â”€â”€â”€â†’â”‚ æ¨¡å‹æ£€æŸ¥ç‚¹   â”‚
â”‚ CSV Files   â”‚    â”‚ training     â”‚    â”‚ checkpoint  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æ¨¡å‹æ£€æŸ¥ç‚¹   â”‚â”€â”€â”€â†’â”‚ ç”Ÿæˆé˜¶æ®µ     â”‚â”€â”€â”€â†’â”‚ è‚½æ®µåºåˆ—     â”‚
â”‚ checkpoint  â”‚    â”‚ generation   â”‚    â”‚ sequences   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ è‚½æ®µåºåˆ—     â”‚â”€â”€â”€â†’â”‚ è¯„ä¼°é˜¶æ®µ     â”‚â”€â”€â”€â†’â”‚ è´¨é‡æŠ¥å‘Š     â”‚
â”‚ sequences   â”‚    â”‚ evaluation   â”‚    â”‚ reports     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### å…³é”®æ•°æ®ä¼ é€’

#### 1. é…ç½®ä¼ é€’é“¾

```python
YAMLé…ç½® â†’ OmegaConfå¯¹è±¡ â†’ å„æ¨¡å—é…ç½®ç±» â†’ å…·ä½“ç»„ä»¶å‚æ•°
```

#### 2. æ¨¡å‹ä¼ é€’é“¾

```python
è®­ç»ƒé…ç½® â†’ StructDiffæ¨¡å‹ â†’ æ£€æŸ¥ç‚¹æ–‡ä»¶ â†’ åŠ è½½çš„æ¨¡å‹ â†’ ç”Ÿæˆåºåˆ—
```

#### 3. è¯„ä¼°ä¼ é€’é“¾

```python
ç”Ÿæˆåºåˆ— â†’ CPLDiffè¯„ä¼°å™¨ â†’ æŒ‡æ ‡è®¡ç®— â†’ è¯„ä¼°ç»“æœ â†’ æœ€ç»ˆæŠ¥å‘Š
```

---

## ğŸš€ ä½¿ç”¨æŒ‡å—

### åŸºç¡€ä½¿ç”¨

#### 1. å®Œæ•´æµæ°´çº¿æ‰§è¡Œ

```bash
# æ ‡å‡†æ‰§è¡Œ
python scripts/run_complete_pipeline.py \
    --config configs/separated_training.yaml \
    --data-dir ./data/processed \
    --output-dir ./outputs/my_experiment

# è‡ªå®šä¹‰å®éªŒåç§°
python scripts/run_complete_pipeline.py \
    --config configs/separated_training.yaml \
    --experiment-name antimicrobial_peptides_v2 \
    --num-samples 2000
```

#### 2. éƒ¨åˆ†æµæ°´çº¿æ‰§è¡Œ

```bash
# ä»…ç”Ÿæˆå’Œè¯„ä¼°ï¼ˆè·³è¿‡è®­ç»ƒï¼‰
python scripts/run_complete_pipeline.py \
    --skip-training \
    --checkpoint-path ./checkpoints/best_model.pth \
    --num-samples 1000

# ä»…è®­ç»ƒï¼ˆè·³è¿‡ç”Ÿæˆå’Œè¯„ä¼°ï¼‰
python scripts/run_complete_pipeline.py \
    --skip-generation \
    --skip-evaluation

# è‡ªå®šä¹‰è‚½æ®µç±»å‹
python scripts/run_complete_pipeline.py \
    --peptide-types antimicrobial antifungal \
    --num-samples 1500
```

### é«˜çº§ä½¿ç”¨

#### 1. å¤šå®éªŒæ‰¹é‡æ‰§è¡Œ

```bash
#!/bin/bash
# æ‰¹é‡å®éªŒè„šæœ¬

experiments=(
    "antimicrobial_focused"
    "antifungal_focused" 
    "antiviral_focused"
)

for exp in "${experiments[@]}"; do
    python scripts/run_complete_pipeline.py \
        --experiment-name "$exp" \
        --peptide-types ${exp%_*} \
        --num-samples 2000
done
```

#### 2. è¶…å‚æ•°æ‰«æ

```python
# é…ç½®æ–‡ä»¶ç”Ÿæˆè„šæœ¬
import yaml
from itertools import product

# è¶…å‚æ•°ç½‘æ ¼
learning_rates = [1e-4, 5e-5, 1e-5]
guidance_scales = [1.5, 2.0, 2.5]

for lr, gs in product(learning_rates, guidance_scales):
    config = load_base_config()
    config['separated_training']['stage1']['learning_rate'] = lr
    config['classifier_free_guidance']['guidance_scale'] = gs
    
    exp_name = f"lr_{lr}_gs_{gs}"
    config_path = f"configs/sweep_{exp_name}.yaml"
    
    with open(config_path, 'w') as f:
        yaml.dump(config, f)
    
    # æ‰§è¡Œå®éªŒ
    os.system(f"""
        python scripts/run_complete_pipeline.py \
            --config {config_path} \
            --experiment-name {exp_name}
    """)
```

#### 3. åˆ†å¸ƒå¼æ‰§è¡Œ

```bash
# ä½¿ç”¨å¤šGPUè®­ç»ƒ
CUDA_VISIBLE_DEVICES=0,1 python scripts/run_complete_pipeline.py \
    --config configs/separated_training.yaml \
    --experiment-name multi_gpu_experiment

# ä½¿ç”¨ç‰¹å®šGPU
CUDA_VISIBLE_DEVICES=2 python scripts/run_complete_pipeline.py \
    --device cuda \
    --experiment-name gpu2_experiment
```

---

## ğŸ“ è¾“å‡ºæ–‡ä»¶ç»“æ„

### å®Œæ•´çš„è¾“å‡ºç›®å½•ç»“æ„

```
outputs/experiment_name/
â”œâ”€â”€ training/                          # è®­ç»ƒé˜¶æ®µè¾“å‡º
â”‚   â”œâ”€â”€ logs/                         # è®­ç»ƒæ—¥å¿—
â”‚   â”œâ”€â”€ evaluations/                  # è®­ç»ƒä¸­è¯„ä¼°
â”‚   â”‚   â”œâ”€â”€ stage1_epoch_5/          # é˜¶æ®µ1å®šæœŸè¯„ä¼°
â”‚   â”‚   â”œâ”€â”€ stage1_epoch_10/
â”‚   â”‚   â”œâ”€â”€ stage1_final/            # é˜¶æ®µ1æœ€ç»ˆè¯„ä¼°
â”‚   â”‚   â”œâ”€â”€ stage2_epoch_5/          # é˜¶æ®µ2å®šæœŸè¯„ä¼°
â”‚   â”‚   â””â”€â”€ stage2_final/            # é˜¶æ®µ2æœ€ç»ˆè¯„ä¼°
â”‚   â”œâ”€â”€ training_config.json         # è®­ç»ƒé…ç½®å¤‡ä»½
â”‚   â”œâ”€â”€ training_stats.json          # è®­ç»ƒç»Ÿè®¡æ•°æ®
â”‚   â””â”€â”€ final_generated_sequences.fasta  # è®­ç»ƒåè‡ªåŠ¨ç”Ÿæˆ
â”‚
â”œâ”€â”€ checkpoints/                      # æ¨¡å‹æ£€æŸ¥ç‚¹
â”‚   â”œâ”€â”€ stage1_epoch_50.pth         # é˜¶æ®µ1æ£€æŸ¥ç‚¹
â”‚   â”œâ”€â”€ stage1_final.pth             # é˜¶æ®µ1æœ€ç»ˆæ¨¡å‹
â”‚   â”œâ”€â”€ stage2_epoch_20.pth         # é˜¶æ®µ2æ£€æŸ¥ç‚¹
â”‚   â””â”€â”€ stage2_final.pth             # é˜¶æ®µ2æœ€ç»ˆæ¨¡å‹
â”‚
â”œâ”€â”€ generation/                       # ç”Ÿæˆé˜¶æ®µè¾“å‡º
â”‚   â”œâ”€â”€ antimicrobial_sequences.fasta   # æŠ—èŒè‚½åºåˆ—
â”‚   â”œâ”€â”€ antifungal_sequences.fasta      # æŠ—çœŸèŒè‚½åºåˆ—
â”‚   â””â”€â”€ antiviral_sequences.fasta       # æŠ—ç—…æ¯’è‚½åºåˆ—
â”‚
â”œâ”€â”€ evaluation/                       # è¯„ä¼°é˜¶æ®µè¾“å‡º
â”‚   â”œâ”€â”€ antimicrobial/               # æŠ—èŒè‚½è¯„ä¼°ç»“æœ
â”‚   â”‚   â”œâ”€â”€ cpldiff_evaluation.html     # è¯¦ç»†è¯„ä¼°æŠ¥å‘Š
â”‚   â”‚   â”œâ”€â”€ metrics_summary.json        # æŒ‡æ ‡æ±‡æ€»
â”‚   â”‚   â”œâ”€â”€ sequence_analysis.csv       # åºåˆ—åˆ†æ
â”‚   â”‚   â””â”€â”€ visualization_plots/        # å¯è§†åŒ–å›¾è¡¨
â”‚   â”œâ”€â”€ antifungal/                  # æŠ—çœŸèŒè‚½è¯„ä¼°ç»“æœ
â”‚   â””â”€â”€ antiviral/                   # æŠ—ç—…æ¯’è‚½è¯„ä¼°ç»“æœ
â”‚
â”œâ”€â”€ logs/                            # æµæ°´çº¿æ—¥å¿—
â”‚   â”œâ”€â”€ pipeline.log                 # ä¸»æ—¥å¿—æ–‡ä»¶
â”‚   â”œâ”€â”€ training.log                 # è®­ç»ƒè¯¦ç»†æ—¥å¿—
â”‚   â”œâ”€â”€ generation.log               # ç”Ÿæˆè¯¦ç»†æ—¥å¿—
â”‚   â””â”€â”€ evaluation.log               # è¯„ä¼°è¯¦ç»†æ—¥å¿—
â”‚
â”œâ”€â”€ reports/                         # æœ€ç»ˆæŠ¥å‘Š
â”‚   â”œâ”€â”€ final_report.json            # å®Œæ•´JSONæŠ¥å‘Š
â”‚   â”œâ”€â”€ final_report.txt             # æ–‡æœ¬æ‘˜è¦æŠ¥å‘Š
â”‚   â”œâ”€â”€ executive_summary.html       # æ‰§è¡Œæ‘˜è¦ï¼ˆHTMLï¼‰
â”‚   â””â”€â”€ comparison_charts/           # å¯¹æ¯”å›¾è¡¨
â”‚
â””â”€â”€ metadata/                        # å…ƒæ•°æ®
    â”œâ”€â”€ experiment_config.yaml       # å®éªŒé…ç½®å¤‡ä»½
    â”œâ”€â”€ environment_info.json        # ç¯å¢ƒä¿¡æ¯
    â”œâ”€â”€ git_info.json               # ä»£ç ç‰ˆæœ¬ä¿¡æ¯
    â””â”€â”€ system_resources.json        # ç¡¬ä»¶èµ„æºä¿¡æ¯
```

### å…³é”®æ–‡ä»¶è¯´æ˜

#### 1. è®­ç»ƒç›¸å…³æ–‡ä»¶

- **`training_stats.json`**: åŒ…å«æŸå¤±æ›²çº¿ã€éªŒè¯æŒ‡æ ‡ã€è¯„ä¼°å†å²
- **`stage1_final.pth`**: é˜¶æ®µ1æœ€ç»ˆæ¨¡å‹ï¼ŒåŒ…å«å»å™ªå™¨æƒé‡
- **`stage2_final.pth`**: é˜¶æ®µ2æœ€ç»ˆæ¨¡å‹ï¼ŒåŒ…å«å®Œæ•´æ¨¡å‹æƒé‡

#### 2. ç”Ÿæˆç›¸å…³æ–‡ä»¶

- **`*_sequences.fasta`**: æ ‡å‡†FASTAæ ¼å¼çš„ç”Ÿæˆåºåˆ—
- **åºåˆ—å‘½åè§„åˆ™**: `>{peptide_type}_{index}`

#### 3. è¯„ä¼°ç›¸å…³æ–‡ä»¶

- **`cpldiff_evaluation.html`**: äº¤äº’å¼HTMLè¯„ä¼°æŠ¥å‘Š
- **`metrics_summary.json`**: æ‰€æœ‰æŒ‡æ ‡çš„æ•°å€¼æ€»ç»“
- **`sequence_analysis.csv`**: æ¯ä¸ªåºåˆ—çš„è¯¦ç»†åˆ†ææ•°æ®

#### 4. æŠ¥å‘Šç›¸å…³æ–‡ä»¶

- **`final_report.json`**: æœºå™¨å¯è¯»çš„å®Œæ•´æŠ¥å‘Š
- **`final_report.txt`**: äººç±»å¯è¯»çš„æ‘˜è¦æŠ¥å‘Š

---

## âš ï¸ å¸¸è§é—®é¢˜å’Œæ•…éšœæ’é™¤

### 1. å†…å­˜ç›¸å…³é—®é¢˜

#### é—®é¢˜ï¼šCUDA out of memory

**ç—‡çŠ¶**ï¼š
```
RuntimeError: CUDA out of memory. Tried to allocate 2.00 GiB
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# æ–¹æ¡ˆ1ï¼šå‡å°‘æ‰¹æ¬¡å¤§å°
python scripts/run_complete_pipeline.py \
    --config configs/separated_training.yaml \
    --batch-size 16  # ä»é»˜è®¤32å‡å°‘

# æ–¹æ¡ˆ2ï¼šä½¿ç”¨CPUæ¨¡å¼
python scripts/run_complete_pipeline.py \
    --device cpu \
    --config configs/separated_training.yaml

# æ–¹æ¡ˆ3ï¼šä¿®æ”¹é…ç½®æ–‡ä»¶
# åœ¨separated_training.yamlä¸­è°ƒæ•´ï¼š
separated_training:
  stage1:
    batch_size: 8
  stage2:
    batch_size: 16
```

#### é—®é¢˜ï¼šç³»ç»Ÿå†…å­˜ä¸è¶³

**ç—‡çŠ¶**ï¼š
```
OSError: [Errno 12] Cannot allocate memory
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
```yaml
# å‡å°‘æ•°æ®åŠ è½½è¿›ç¨‹
data:
  num_workers: 2        # ä»4å‡å°‘åˆ°2
  prefetch_factor: 1    # ä»2å‡å°‘åˆ°1

# ç¦ç”¨å†…å­˜é”å®š
resources:
  pin_memory: false
```

### 2. æ¨¡å‹åŠ è½½é—®é¢˜

#### é—®é¢˜ï¼šæ£€æŸ¥ç‚¹æ–‡ä»¶æŸå

**ç—‡çŠ¶**ï¼š
```
RuntimeError: Error(s) in loading state_dict
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# æ£€æŸ¥æ£€æŸ¥ç‚¹æ–‡ä»¶
import torch

checkpoint_path = "path/to/checkpoint.pth"
try:
    checkpoint = torch.load(checkpoint_path, map_location='cpu')
    print("æ£€æŸ¥ç‚¹æ–‡ä»¶æ­£å¸¸")
    print(f"åŒ…å«çš„é”®: {checkpoint.keys()}")
except Exception as e:
    print(f"æ£€æŸ¥ç‚¹æ–‡ä»¶æŸå: {e}")
    # ä½¿ç”¨å¤‡ä»½æ£€æŸ¥ç‚¹æˆ–é‡æ–°è®­ç»ƒ
```

#### é—®é¢˜ï¼šæ¨¡å‹ç»“æ„ä¸åŒ¹é…

**ç—‡çŠ¶**ï¼š
```
RuntimeError: size mismatch for denoiser.layers.0.weight
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# ç¡®ä¿é…ç½®æ–‡ä»¶ä¸æ£€æŸ¥ç‚¹åŒ¹é…
# æˆ–è€…åˆ é™¤æ£€æŸ¥ç‚¹é‡æ–°è®­ç»ƒ
rm -rf outputs/experiment_name/checkpoints/
python scripts/run_complete_pipeline.py --config configs/separated_training.yaml
```

### 3. æ•°æ®ç›¸å…³é—®é¢˜

#### é—®é¢˜ï¼šæ•°æ®æ–‡ä»¶ç¼ºå¤±

**ç—‡çŠ¶**ï¼š
```
FileNotFoundError: [Errno 2] No such file or directory: 'train.csv'
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# æ£€æŸ¥æ•°æ®ç›®å½•ç»“æ„
ls -la data/processed/
# åº”è¯¥åŒ…å«ï¼štrain.csv, val.csv (å¯é€‰), test.csv (å¯é€‰)

# å¦‚æœç¼ºå¤±ï¼Œè¿è¡Œæ•°æ®å‡†å¤‡è„šæœ¬
python scripts/prepare_data.py --data-dir data/raw --output-dir data/processed
```

#### é—®é¢˜ï¼šæ•°æ®æ ¼å¼é”™è¯¯

**ç—‡çŠ¶**ï¼š
```
KeyError: 'sequence' or 'structure'
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# æ£€æŸ¥CSVæ–‡ä»¶æ ¼å¼
import pandas as pd
df = pd.read_csv('data/processed/train.csv')
print(df.columns.tolist())
# åº”è¯¥åŒ…å«ï¼š['sequence', 'structure', 'peptide_type', 'activity']
```

### 4. è¯„ä¼°ç›¸å…³é—®é¢˜

#### é—®é¢˜ï¼šè¯„ä¼°å™¨åˆå§‹åŒ–å¤±è´¥

**ç—‡çŠ¶**ï¼š
```
ImportError: No module named 'modlamp'
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# å®‰è£…ç¼ºå¤±çš„ä¾èµ–
pip install modlamp
pip install biopython
pip install fair-esm

# æˆ–ä½¿ç”¨conda
conda install -c bioconda modlamp
```

#### é—®é¢˜ï¼šESMFoldå†…å­˜ä¸è¶³

**ç—‡çŠ¶**ï¼š
```
CUDA out of memory during ESMFold prediction
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
```yaml
# åœ¨é…ç½®æ–‡ä»¶ä¸­ç¦ç”¨ESMFold
model:
  structure_encoder:
    use_esmfold: false

# æˆ–è€…ä½¿ç”¨CPUæ¨¡å¼çš„ESMFold
evaluation:
  use_cpu_esmfold: true
```

### 5. æ€§èƒ½ä¼˜åŒ–å»ºè®®

#### 1. è®­ç»ƒåŠ é€Ÿ

```yaml
# å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
training_enhancements:
  use_amp: true
  amp_dtype: "float16"

# ä¼˜åŒ–æ•°æ®åŠ è½½
data:
  num_workers: 8        # æ ¹æ®CPUæ ¸å¿ƒæ•°è°ƒæ•´
  pin_memory: true
  prefetch_factor: 2

# ä½¿ç”¨LoRAå‡å°‘å‚æ•°é‡
model:
  sequence_encoder:
    use_lora: true
    lora_rank: 16       # å¯ä»¥å°è¯•8, 16, 32
```

#### 2. ç”ŸæˆåŠ é€Ÿ

```bash
# ä½¿ç”¨DDIMåŠ é€Ÿé‡‡æ ·
# åœ¨é…ç½®æ–‡ä»¶ä¸­ï¼š
diffusion:
  sampling_method: "ddim"
  ddim_steps: 20        # ä»50å‡å°‘åˆ°20

# æˆ–è€…ä½¿ç”¨è„šæœ¬å‚æ•°
python scripts/run_complete_pipeline.py \
    --fast-sampling \
    --ddim-steps 20
```

#### 3. è¯„ä¼°åŠ é€Ÿ

```python
# å‡å°‘è¯„ä¼°æ ·æœ¬æ•°é‡ï¼ˆå¼€å‘é˜¶æ®µï¼‰
evaluation:
  generation:
    num_samples: 100    # ä»1000å‡å°‘

# å¹¶è¡Œè¯„ä¼°
evaluation:
  parallel_workers: 4  # å¯ç”¨å¤šè¿›ç¨‹è¯„ä¼°
```

---

## ğŸ“ˆ æ€§èƒ½ç›‘æ§å’Œè°ƒè¯•

### 1. å®æ—¶ç›‘æ§

#### W&Bç›‘æ§

```python
# åœ¨é…ç½®æ–‡ä»¶ä¸­å¯ç”¨
monitoring:
  wandb:
    enabled: true
    project: "StructDiff-Production"
    log_frequency: 50

# æŸ¥çœ‹å®æ—¶è®­ç»ƒçŠ¶æ€
# æµè§ˆå™¨æ‰“å¼€: https://wandb.ai/your-username/StructDiff-Production
```

#### TensorBoardç›‘æ§

```bash
# å¯åŠ¨TensorBoard
tensorboard --logdir outputs/experiment_name/tensorboard

# æµè§ˆå™¨æ‰“å¼€: http://localhost:6006
```

### 2. è°ƒè¯•æ¨¡å¼

#### å¼€å‘è°ƒè¯•

```yaml
# åœ¨é…ç½®æ–‡ä»¶ä¸­å¯ç”¨è°ƒè¯•
debug:
  enabled: true
  use_small_dataset: true
  small_dataset_size: 100
  detailed_logging: true
  save_intermediate_results: true
```

#### è¯¦ç»†æ—¥å¿—

```bash
# å¯ç”¨è¯¦ç»†æ—¥å¿—
python scripts/run_complete_pipeline.py \
    --config configs/separated_training.yaml \
    --log-level DEBUG \
    --save-intermediate
```

### 3. æ€§èƒ½åˆ†æ

#### GPUåˆ©ç”¨ç‡ç›‘æ§

```bash
# åœ¨å¦ä¸€ä¸ªç»ˆç«¯è¿è¡Œ
nvidia-smi -l 1

# æˆ–ä½¿ç”¨ä¸“é—¨çš„ç›‘æ§å·¥å…·
pip install gpustat
gpustat -i 1
```

#### å†…å­˜ä½¿ç”¨åˆ†æ

```python
import psutil
import GPUtil

def monitor_resources():
    """ç›‘æ§ç³»ç»Ÿèµ„æºä½¿ç”¨"""
    # CPUå’Œå†…å­˜
    cpu_percent = psutil.cpu_percent()
    memory = psutil.virtual_memory()
    
    # GPU
    gpus = GPUtil.getGPUs()
    for gpu in gpus:
        print(f"GPU {gpu.id}: {gpu.memoryUtil*100:.1f}% memory, {gpu.load*100:.1f}% load")
```

---

## ğŸ”® æ‰©å±•å’Œå®šåˆ¶

### 1. æ·»åŠ æ–°çš„è‚½æ®µç±»å‹

```python
# åœ¨generationé˜¶æ®µæ·»åŠ æ–°ç±»å‹
def run_generation_stage(...):
    # æ·»åŠ æ–°çš„è‚½æ®µç±»å‹
    peptide_types = args.peptide_types + ['anticancer', 'antimalarial']
    
    for peptide_type in peptide_types:
        # æ ¹æ®ç±»å‹è°ƒæ•´ç”Ÿæˆå‚æ•°
        if peptide_type == 'anticancer':
            length_range = (15, 35)  # æŠ—ç™Œè‚½é€šå¸¸è¾ƒé•¿
        elif peptide_type == 'antimalarial':
            length_range = (10, 25)  # æŠ—ç–Ÿç–¾è‚½ä¸­ç­‰é•¿åº¦
```

### 2. é›†æˆæ–°çš„è¯„ä¼°æŒ‡æ ‡

```python
# æ‰©å±•è¯„ä¼°å™¨
class ExtendedEvaluator(CPLDiffStandardEvaluator):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        
    def evaluate_additional_metrics(self, sequences):
        """æ·»åŠ æ–°çš„è¯„ä¼°æŒ‡æ ‡"""
        results = {}
        
        # ç¤ºä¾‹ï¼šæ·»åŠ ç–æ°´æ€§è¯„ä¼°
        hydrophobicity_scores = []
        for seq in sequences:
            score = self.calculate_hydrophobicity(seq)
            hydrophobicity_scores.append(score)
        
        results['hydrophobicity'] = {
            'mean': np.mean(hydrophobicity_scores),
            'std': np.std(hydrophobicity_scores),
            'distribution': hydrophobicity_scores
        }
        
        return results
```

### 3. è‡ªå®šä¹‰æŠ¥å‘Šæ ¼å¼

```python
def generate_custom_report(results, output_path):
    """ç”Ÿæˆè‡ªå®šä¹‰æ ¼å¼çš„æŠ¥å‘Š"""
    
    # LaTeXæŠ¥å‘Š
    latex_template = r"""
    \documentclass{article}
    \begin{document}
    \title{StructDiff Experiment Report}
    \section{Results}
    Training Loss: {{ training_loss }}
    Generation Count: {{ generation_count }}
    \end{document}
    """
    
    # ä½¿ç”¨Jinja2æ¨¡æ¿å¼•æ“
    from jinja2 import Template
    template = Template(latex_template)
    
    report_content = template.render(
        training_loss=results['training']['final_loss'],
        generation_count=results['generation']['total_count']
    )
    
    with open(output_path / "report.tex", 'w') as f:
        f.write(report_content)
```

---

## ğŸ“š ç›¸å…³æ–‡æ¡£é“¾æ¥

- [é…ç½®æ–‡ä»¶è¯¦è§£](./separated_training_config_guide.md) - è¯¦ç»†çš„é…ç½®å‚æ•°è¯´æ˜
- [CPL-Diffè¯„ä¼°ä½“ç³»](./cpldiff_evaluation_guide.md) - è¯„ä¼°æŒ‡æ ‡å’Œæ ‡å‡†
- [æ¨¡å‹æ¶æ„è¯´æ˜](./model_architecture_guide.md) - StructDiffæ¨¡å‹è®¾è®¡
- [æ•°æ®å‡†å¤‡æŒ‡å—](./data_preparation_guide.md) - æ•°æ®æ ¼å¼å’Œé¢„å¤„ç†
- [éƒ¨ç½²å’Œç”Ÿäº§æŒ‡å—](./deployment_guide.md) - ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²å»ºè®®

---

*æœ¬æ–‡æ¡£å°†æŒç»­æ›´æ–°ï¼Œå¦‚æœ‰ç–‘é—®æˆ–å»ºè®®ï¼Œè¯·æäº¤Issueæˆ–è”ç³»é¡¹ç›®ç»´æŠ¤å›¢é˜Ÿã€‚*