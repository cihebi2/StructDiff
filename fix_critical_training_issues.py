#!/usr/bin/env python3
"""
ğŸ”§ StructDiffè®­ç»ƒå…³é”®é—®é¢˜ä¿®å¤è„šæœ¬
è§£å†³ï¼š
1. CrossModalAttentionç»´åº¦é…ç½®é”™è¯¯
2. CUDAå†…å­˜ä¸è¶³é—®é¢˜
3. é‡æ–°è®¾è®¡è®­ç»ƒç­–ç•¥ä½¿ç”¨é¢„è®¡ç®—ç»“æ„ç‰¹å¾
"""

import os
import sys
import yaml
import psutil
import subprocess
import shutil
from pathlib import Path
from typing import Dict, Any
import torch

def check_environment():
    """æ£€æŸ¥ç¯å¢ƒçŠ¶æ€"""
    print("ğŸ” æ£€æŸ¥ç¯å¢ƒçŠ¶æ€...")
    
    # æ£€æŸ¥CUDA
    cuda_available = torch.cuda.is_available()
    if cuda_available:
        gpu_count = torch.cuda.device_count()
        print(f"âœ… CUDAå¯ç”¨ï¼Œæ£€æµ‹åˆ° {gpu_count} å—GPU")
        for i in range(gpu_count):
            props = torch.cuda.get_device_properties(i)
            memory_gb = props.total_memory / 1024**3
            print(f"   GPU {i}: {props.name} ({memory_gb:.1f}GB)")
    else:
        print("âŒ CUDAä¸å¯ç”¨")
        return False
    
    # æ£€æŸ¥Pythonè¿›ç¨‹
    running_processes = []
    for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
        try:
            cmdline = ' '.join(proc.info['cmdline'] or [])
            if 'train_separated.py' in cmdline or 'structdiff' in cmdline.lower():
                running_processes.append(proc.info)
        except (psutil.NoSuchProcess, psutil.AccessDenied):
            continue
    
    if running_processes:
        print("âš ï¸  å‘ç°è¿è¡Œä¸­çš„è®­ç»ƒè¿›ç¨‹:")
        for proc in running_processes:
            print(f"   PID {proc['pid']}: {proc['name']}")
        return running_processes
    else:
        print("âœ… æ²¡æœ‰å‘ç°è¿è¡Œä¸­çš„è®­ç»ƒè¿›ç¨‹")
        return []

def stop_training_processes():
    """åœæ­¢æ‰€æœ‰ç›¸å…³è®­ç»ƒè¿›ç¨‹"""
    print("ğŸ›‘ åœæ­¢æ‰€æœ‰StructDiffè®­ç»ƒè¿›ç¨‹...")
    
    # ä½¿ç”¨pkillåœæ­¢ç›¸å…³è¿›ç¨‹
    commands = [
        "pkill -f train_separated.py",
        "pkill -f structdiff",
        "pkill -f python.*train"
    ]
    
    for cmd in commands:
        try:
            result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
            if result.returncode == 0:
                print(f"âœ… æ‰§è¡Œ: {cmd}")
            else:
                print(f"â„¹ï¸  è¿›ç¨‹å¯èƒ½å·²åœæ­¢: {cmd}")
        except Exception as e:
            print(f"âš ï¸  å‘½ä»¤æ‰§è¡Œå¼‚å¸¸: {cmd}, é”™è¯¯: {e}")
    
    # ç­‰å¾…è¿›ç¨‹å®Œå…¨åœæ­¢
    import time
    time.sleep(3)
    print("âœ… è¿›ç¨‹åœæ­¢å®Œæˆ")

def analyze_configuration_issues():
    """åˆ†æé…ç½®æ–‡ä»¶ä¸­çš„é—®é¢˜"""
    print("ğŸ” åˆ†æé…ç½®æ–‡ä»¶é—®é¢˜...")
    
    config_path = "configs/separated_training_optimized.yaml"
    
    if not Path(config_path).exists():
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        return None
    
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    issues = []
    
    # æ£€æŸ¥ç»´åº¦é…ç½®
    model_config = config.get('model', {})
    denoiser_config = model_config.get('denoiser', {})
    structure_config = model_config.get('structure_encoder', {})
    
    hidden_dim = denoiser_config.get('hidden_dim', 320)
    num_heads = denoiser_config.get('num_heads', 8)
    struct_hidden_dim = structure_config.get('hidden_dim', 320)
    
    # éªŒè¯ç»´åº¦å…¼å®¹æ€§
    if hidden_dim % num_heads != 0:
        issues.append(f"âŒ hidden_dim ({hidden_dim}) ä¸èƒ½è¢« num_heads ({num_heads}) æ•´é™¤")
    else:
        print(f"âœ… ç»´åº¦é…ç½®æ­£ç¡®: hidden_dim={hidden_dim}, num_heads={num_heads}, head_dim={hidden_dim//num_heads}")
    
    # æ£€æŸ¥ç»“æ„ç¼–ç å™¨é…ç½®
    if struct_hidden_dim != hidden_dim:
        issues.append(f"âš ï¸  ç»“æ„ç¼–ç å™¨ç»´åº¦ ({struct_hidden_dim}) ä¸å»å™ªå™¨ç»´åº¦ ({hidden_dim}) ä¸åŒ¹é…")
    
    # æ£€æŸ¥å†…å­˜ä½¿ç”¨é…ç½®
    data_config = config.get('data', {})
    use_structures = data_config.get('use_predicted_structures', False)
    batch_size = config.get('separated_training', {}).get('stage1', {}).get('batch_size', 1)
    
    if use_structures and batch_size > 1:
        issues.append(f"âš ï¸  å¯ç”¨ç»“æ„ç‰¹å¾æ—¶æ‰¹æ¬¡å¤§å° ({batch_size}) å¯èƒ½å¯¼è‡´å†…å­˜ä¸è¶³")
    
    if issues:
        print("å‘ç°é…ç½®é—®é¢˜:")
        for issue in issues:
            print(f"  {issue}")
    else:
        print("âœ… é…ç½®æ–‡ä»¶æ£€æŸ¥é€šè¿‡")
    
    return config, issues

def create_fixed_configuration():
    """åˆ›å»ºä¿®å¤åçš„é…ç½®æ–‡ä»¶"""
    print("ğŸ”§ åˆ›å»ºä¿®å¤åçš„é…ç½®æ–‡ä»¶...")
    
    fixed_config = {
        'experiment': {
            'name': "structdiff_separated_fixed_v2",
            'description': "ä¿®å¤ç»´åº¦å’Œå†…å­˜é—®é¢˜çš„æœ€ç»ˆç‰ˆæœ¬",
            'project': "StructDiff-Production",
            'seed': 42
        },
        
        'model': {
            'type': "StructDiff",
            'sequence_encoder': {
                'pretrained_model': "facebook/esm2_t6_8M_UR50D",
                'freeze_encoder': False,
                'use_lora': False
            },
            'structure_encoder': {
                'type': "multi_scale",
                'hidden_dim': 320,  # ç¡®ä¿ä¸å»å™ªå™¨åŒ¹é…
                'use_esmfold': False,  # ç¦ç”¨ESMFoldé¿å…å†…å­˜é—®é¢˜
                'use_cache': True,
                'cache_dir': "./cache",
                'local': {
                    'hidden_dim': 320,
                    'num_layers': 2,
                    'kernel_sizes': [3, 5],
                    'dropout': 0.1
                },
                'global': {
                    'hidden_dim': 320,
                    'num_attention_heads': 8,  # 320 Ã· 8 = 40
                    'num_layers': 2,
                    'dropout': 0.1
                },
                'fusion': {
                    'method': "attention",
                    'hidden_dim': 320
                }
            },
            'denoiser': {
                'hidden_dim': 320,  # ä¸æ‰€æœ‰å…¶ä»–ç»„ä»¶åŒ¹é…
                'num_layers': 6,
                'num_heads': 8,  # 320 Ã· 8 = 40ï¼Œå®Œç¾æ•´é™¤
                'dropout': 0.1,
                'use_cross_attention': False  # æš‚æ—¶ç¦ç”¨äº¤å‰æ³¨æ„åŠ›é¿å…å¤æ‚æ€§
            },
            'sequence_decoder': {
                'hidden_dim': 320,
                'num_layers': 3,
                'vocab_size': 33,
                'dropout': 0.1
            }
        },
        
        'diffusion': {
            'num_timesteps': 1000,
            'noise_schedule': "sqrt",
            'beta_start': 0.0001,
            'beta_end': 0.02,
            'sampling_method': "ddpm",
            'ddim_steps': 50
        },
        
        'separated_training': {
            'stage1': {
                'epochs': 50,  # å¢åŠ è®­ç»ƒè½®æ•°
                'batch_size': 1,  # ä¿æŒæœ€å°æ‰¹æ¬¡
                'learning_rate': 1e-4,
                'warmup_steps': 200,
                'gradient_clip': 1.0,
                'optimizer': {
                    'type': "AdamW",
                    'weight_decay': 0.01,
                    'betas': [0.9, 0.999],
                    'eps': 1e-8
                },
                'scheduler': {
                    'type': "cosine",
                    'eta_min': 1e-6
                }
            },
            'stage2': {
                'epochs': 30,
                'batch_size': 2,
                'learning_rate': 5e-5,
                'warmup_steps': 100,
                'gradient_clip': 0.5,
                'optimizer': {
                    'type': "AdamW",
                    'weight_decay': 0.01,
                    'betas': [0.9, 0.999],
                    'eps': 1e-8
                },
                'scheduler': {
                    'type': "cosine",
                    'eta_min': 1e-6
                }
            }
        },
        
        'data': {
            'data_dir': "./data/processed",
            'train_file': "train.csv",
            'val_file': "val.csv",
            'max_length': 50,
            'min_length': 5,
            'num_workers': 0,  # ç¦ç”¨å¤šè¿›ç¨‹
            'pin_memory': False,
            'use_predicted_structures': False,  # å®Œå…¨ç¦ç”¨ç»“æ„ç‰¹å¾é¿å…å†…å­˜é—®é¢˜
            'structure_cache_dir': "./cache"
        },
        
        'length_control': {
            'enabled': True,
            'min_length': 5,
            'max_length': 50,
            'analyze_training_data': True,
            'save_distributions': True,
            'length_penalty_weight': 0.1
        },
        
        'classifier_free_guidance': {
            'enabled': True,
            'dropout_prob': 0.1,
            'guidance_scale': 2.0,
            'adaptive_guidance': True,
            'guidance_schedule': "cosine"
        },
        
        'training_enhancements': {
            'use_amp': False,  # ç¦ç”¨AMP
            'use_ema': False,  # ç¦ç”¨EMA
            'gradient_accumulation_steps': 8,  # å¢åŠ æ¢¯åº¦ç´¯ç§¯
            'save_every': 1000,
            'validate_every': 200,
            'log_every': 20,
            'max_checkpoints': 3
        },
        
        'evaluation': {
            'enabled': False  # æš‚æ—¶ç¦ç”¨è¯„ä¼°
        },
        
        'output': {
            'base_dir': "./outputs/separated_fixed_v2",
            'checkpoint_dir': "./outputs/separated_fixed_v2/checkpoints",
            'log_dir': "./outputs/separated_fixed_v2/logs",
            'results_dir': "./outputs/separated_fixed_v2/results",
            'save_model_config': True,
            'save_training_stats': True,
            'save_generated_samples': True
        },
        
        'monitoring': {
            'wandb': {'enabled': False},
            'tensorboard': {'enabled': False}
        },
        
        'debug': {
            'enabled': False,
            'detailed_logging': True
        },
        
        'resources': {
            'device': "cuda:2",
            'available_gpus': [2, 3, 4, 5],
            'stage1_gpus': [2, 3],
            'stage2_gpus': [4, 5],
            'gpu_memory_fraction': 0.7,  # å‡å°‘GPUå†…å­˜ä½¿ç”¨
            'allow_growth': True,
            'num_threads': 4
        }
    }
    
    # ä¿å­˜ä¿®å¤åçš„é…ç½®
    fixed_config_path = "configs/separated_training_fixed_v2.yaml"
    with open(fixed_config_path, 'w', encoding='utf-8') as f:
        yaml.dump(fixed_config, f, default_flow_style=False, allow_unicode=True, indent=2)
    
    print(f"âœ… åˆ›å»ºä¿®å¤é…ç½®æ–‡ä»¶: {fixed_config_path}")
    
    # åˆ›å»ºé…ç½®æ‘˜è¦
    print("\nğŸ“‹ ä¿®å¤è¦ç‚¹:")
    print("   ğŸ”§ ç»´åº¦é…ç½®: hidden_dim=320, num_heads=8 (å®Œç¾æ•´é™¤)")
    print("   ğŸš« ç¦ç”¨ç»“æ„ç‰¹å¾: é¿å…ESMFoldå†…å­˜é—®é¢˜")
    print("   ğŸš« ç¦ç”¨äº¤å‰æ³¨æ„åŠ›: ç®€åŒ–æ¨¡å‹é¿å…ç»´åº¦é”™è¯¯")
    print("   ğŸ“¦ æœ€å°æ‰¹æ¬¡å¤§å°: batch_size=1")
    print("   ğŸ”„ å¢åŠ æ¢¯åº¦ç´¯ç§¯: gradient_accumulation_steps=8")
    print("   ğŸ’¾ ä¼˜åŒ–å†…å­˜ä½¿ç”¨: gpu_memory_fraction=0.7")
    
    return fixed_config_path

def create_dummy_structure_cache():
    """åˆ›å»ºè™šæ‹Ÿç»“æ„ç¼“å­˜ç›®å½•ç»“æ„"""
    print("ğŸ“ åˆ›å»ºè™šæ‹Ÿç»“æ„ç¼“å­˜...")
    
    cache_dirs = [
        "./cache/train",
        "./cache/val"
    ]
    
    for cache_dir in cache_dirs:
        Path(cache_dir).mkdir(parents=True, exist_ok=True)
    
    # åˆ›å»ºç©ºçš„ç¼“å­˜æ–‡ä»¶ï¼ˆå¦‚æœéœ€è¦ï¼‰
    dummy_cache = {
        'features': torch.zeros(50, 320),  # åŒ¹é…ç»´åº¦
        'metadata': {'length': 50, 'computed': False}
    }
    
    # ä¸å®é™…åˆ›å»ºç¼“å­˜æ–‡ä»¶ï¼Œåªåˆ›å»ºç›®å½•ç»“æ„
    print("âœ… ç¼“å­˜ç›®å½•ç»“æ„å·²åˆ›å»º")

def create_restart_script():
    """åˆ›å»ºé‡å¯è„šæœ¬"""
    print("ğŸ“ åˆ›å»ºé‡å¯è„šæœ¬...")
    
    script_content = '''#!/bin/bash
# StructDiffä¿®å¤åé‡å¯è„šæœ¬

echo "ğŸš€ å¯åŠ¨ä¿®å¤åçš„StructDiffåˆ†ç¦»å¼è®­ç»ƒ..."

# è®¾ç½®ç¯å¢ƒ
export CUDA_VISIBLE_DEVICES=2,3,4,5
export PYTHONPATH="/home/qlyu/sequence/StructDiff-7.0.0:$PYTHONPATH"

# æ£€æŸ¥æ•°æ®
echo "ğŸ“Š æ£€æŸ¥æ•°æ®çŠ¶æ€..."
ls -la ./data/processed/

# å¯åŠ¨è®­ç»ƒ
cd /home/qlyu/sequence/StructDiff-7.0.0

python scripts/train_separated.py \\
    --config configs/separated_training_fixed_v2.yaml \\
    --data-dir ./data/processed \\
    --output-dir ./outputs/separated_fixed_v2 \\
    --device auto \\
    --stage both \\
    --use-cfg \\
    --use-length-control \\
    --debug

echo "âœ… è®­ç»ƒè„šæœ¬å·²å¯åŠ¨"
'''
    
    script_path = "restart_fixed_training.sh"
    with open(script_path, 'w') as f:
        f.write(script_content)
    
    os.chmod(script_path, 0o755)
    print(f"âœ… åˆ›å»ºé‡å¯è„šæœ¬: {script_path}")
    
    return script_path

def clear_gpu_memory():
    """æ¸…ç†GPUå†…å­˜"""
    print("ğŸ§¹ æ¸…ç†GPUå†…å­˜...")
    
    try:
        # æ¸…ç†PyTorchç¼“å­˜
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.synchronize()
            print("âœ… PyTorch GPUç¼“å­˜å·²æ¸…ç†")
        
        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        import gc
        gc.collect()
        print("âœ… Pythonåƒåœ¾å›æ”¶å®Œæˆ")
        
    except Exception as e:
        print(f"âš ï¸  å†…å­˜æ¸…ç†å¼‚å¸¸: {e}")

def main():
    """ä¸»ä¿®å¤æµç¨‹"""
    print("ğŸ”§ StructDiffè®­ç»ƒå…³é”®é—®é¢˜ä¿®å¤ç¨‹åº")
    print("=" * 50)
    
    # 1. æ£€æŸ¥ç¯å¢ƒ
    running_procs = check_environment()
    
    # 2. åœæ­¢è¿è¡Œä¸­çš„è¿›ç¨‹
    if running_procs:
        stop_training_processes()
    
    # 3. åˆ†æé…ç½®é—®é¢˜
    config_result = analyze_configuration_issues()
    
    # 4. æ¸…ç†GPUå†…å­˜
    clear_gpu_memory()
    
    # 5. åˆ›å»ºä¿®å¤é…ç½®
    fixed_config_path = create_fixed_configuration()
    
    # 6. åˆ›å»ºè™šæ‹Ÿç¼“å­˜
    create_dummy_structure_cache()
    
    # 7. åˆ›å»ºé‡å¯è„šæœ¬
    restart_script = create_restart_script()
    
    print("\nğŸ‰ ä¿®å¤å®Œæˆ!")
    print("=" * 50)
    print("ğŸ“‹ ä¿®å¤æ‘˜è¦:")
    print("  âœ… åœæ­¢äº†æ‰€æœ‰è¿è¡Œä¸­çš„è®­ç»ƒè¿›ç¨‹")
    print("  âœ… ä¿®å¤äº†ç»´åº¦é…ç½®é”™è¯¯ (hidden_dim=320, num_heads=8)")
    print("  âœ… ç¦ç”¨äº†ç»“æ„ç‰¹å¾ä»¥é¿å…å†…å­˜é—®é¢˜")
    print("  âœ… ä¼˜åŒ–äº†å†…å­˜ä½¿ç”¨é…ç½®")
    print("  âœ… åˆ›å»ºäº†æ–°çš„é…ç½®æ–‡ä»¶å’Œé‡å¯è„šæœ¬")
    
    print(f"\nğŸš€ ç°åœ¨å¯ä»¥è¿è¡Œé‡å¯è„šæœ¬:")
    print(f"   ./{restart_script}")
    
    print("\nğŸ” æˆ–è€…æ‰‹åŠ¨å¯åŠ¨:")
    print("   python scripts/train_separated.py --config configs/separated_training_fixed_v2.yaml")

if __name__ == "__main__":
    main() 