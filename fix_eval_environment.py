#!/usr/bin/env python3
"""
å¿«é€Ÿä¿®å¤è¯„ä¼°é—®é¢˜çš„è„šæœ¬
"""

import torch
import gc
import os

def clear_gpu_memory():
    """æ¸…ç†GPUå†…å­˜"""
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
        gc.collect()
        print(f"ğŸ§¹ GPUå†…å­˜å·²æ¸…ç†ï¼Œå½“å‰ä½¿ç”¨: {torch.cuda.memory_allocated()/1024**3:.2f}GB")

def set_environment_for_eval():
    """è®¾ç½®ç¯å¢ƒå˜é‡ä¼˜åŒ–è¯„ä¼°"""
    # PyTorchå†…å­˜ç®¡ç†
    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'
    
    # ç¦ç”¨ä¸€äº›è°ƒè¯•åŠŸèƒ½
    os.environ['CUDA_LAUNCH_BLOCKING'] = '0'
    
    print("âœ… ç¯å¢ƒå˜é‡å·²ä¼˜åŒ–")

if __name__ == "__main__":
    print("ğŸ”§ è¿è¡Œè¯„ä¼°ä¿®å¤...")
    set_environment_for_eval()
    clear_gpu_memory()
    print("âœ… è¯„ä¼°ç¯å¢ƒå·²ä¼˜åŒ–ï¼Œå¯ä»¥é‡æ–°è¿è¡Œè®­ç»ƒè„šæœ¬")
