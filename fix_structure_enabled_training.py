#!/usr/bin/env python3
"""
ğŸ”§ StructDiffç»“æ„æ„ŸçŸ¥è®­ç»ƒä¿®å¤è„šæœ¬
ä¿ç•™æ ¸å¿ƒåŠŸèƒ½ï¼š
1. âœ… ç»“æ„ç‰¹å¾ (ESMFold)
2. âœ… äº¤å‰æ³¨æ„åŠ› (CrossModalAttention)
3. ğŸ”§ ä¿®å¤ç»´åº¦é…ç½®é”™è¯¯
4. ğŸ’¾ ä¼˜åŒ–å†…å­˜ä½¿ç”¨ç­–ç•¥
"""

import os
import sys
import yaml
import psutil
import subprocess
import shutil
from pathlib import Path
from typing import Dict, Any
import torch

def stop_all_training():
    """åœæ­¢æ‰€æœ‰è®­ç»ƒè¿›ç¨‹"""
    print("ğŸ›‘ åœæ­¢æ‰€æœ‰è®­ç»ƒè¿›ç¨‹...")
    
    commands = [
        "pkill -f train_separated.py",
        "pkill -f structdiff",
        "pkill -f python.*train"
    ]
    
    for cmd in commands:
        try:
            subprocess.run(cmd, shell=True, capture_output=True, text=True)
        except Exception:
            pass
    
    # ç­‰å¾…è¿›ç¨‹åœæ­¢
    import time
    time.sleep(2)
    print("âœ… è®­ç»ƒè¿›ç¨‹å·²åœæ­¢")

def analyze_dimension_issue():
    """åˆ†æç»´åº¦é…ç½®é—®é¢˜"""
    print("ğŸ” æ·±åº¦åˆ†æç»´åº¦é…ç½®é—®é¢˜...")
    
    # æ£€æŸ¥å½“å‰çš„é…ç½®æ–‡ä»¶
    config_files = [
        "configs/separated_training_optimized.yaml",
        "configs/separated_training_production.yaml",
        "configs/separated_training_fixed_v2.yaml"
    ]
    
    for config_file in config_files:
        if Path(config_file).exists():
            print(f"ğŸ“„ æ£€æŸ¥é…ç½®æ–‡ä»¶: {config_file}")
            
            with open(config_file, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            
            # æå–å…³é”®ç»´åº¦å‚æ•°
            model_config = config.get('model', {})
            denoiser_config = model_config.get('denoiser', {})
            structure_config = model_config.get('structure_encoder', {})
            
            hidden_dim = denoiser_config.get('hidden_dim', 'N/A')
            num_heads = denoiser_config.get('num_heads', 'N/A')
            struct_hidden_dim = structure_config.get('hidden_dim', 'N/A')
            use_cross_attention = denoiser_config.get('use_cross_attention', 'N/A')
            
            print(f"  å»å™ªå™¨: hidden_dim={hidden_dim}, num_heads={num_heads}")
            print(f"  ç»“æ„ç¼–ç å™¨: hidden_dim={struct_hidden_dim}")
            print(f"  äº¤å‰æ³¨æ„åŠ›: {use_cross_attention}")
            
            # æ£€æŸ¥ç»´åº¦å…¼å®¹æ€§
            if isinstance(hidden_dim, int) and isinstance(num_heads, int):
                if hidden_dim % num_heads == 0:
                    head_dim = hidden_dim // num_heads
                    print(f"  âœ… ç»´åº¦é…ç½®æ­£ç¡®: head_dim={head_dim}")
                else:
                    print(f"  âŒ ç»´åº¦é…ç½®é”™è¯¯: {hidden_dim} % {num_heads} != 0")
            
            print()

def create_structure_enabled_config():
    """åˆ›å»ºä¿ç•™ç»“æ„ç‰¹å¾çš„ä¼˜åŒ–é…ç½®"""
    print("ğŸ”§ åˆ›å»ºç»“æ„æ„ŸçŸ¥çš„ä¼˜åŒ–é…ç½®...")
    
    # è®¾è®¡ç»´åº¦å…¼å®¹çš„é…ç½®
    # ESM2_t6_8M_UR50D çš„ hidden_size æ˜¯ 320
    # é€‰æ‹©åˆé€‚çš„æ³¨æ„åŠ›å¤´æ•°ï¼š320 èƒ½è¢« 8, 10, 16, 20, 32, 40 æ•´é™¤
    # æˆ‘ä»¬é€‰æ‹© 8 å¤´ï¼Œæ¯å¤´ 40 ç»´åº¦
    
    optimized_config = {
        'experiment': {
            'name': "structdiff_structure_enabled_v1",
            'description': "ä¿ç•™ç»“æ„ç‰¹å¾å’Œäº¤å‰æ³¨æ„åŠ›çš„ä¼˜åŒ–ç‰ˆæœ¬",
            'project': "StructDiff-StructureAware",
            'seed': 42
        },
        
        'model': {
            'type': "StructDiff",
            'sequence_encoder': {
                'pretrained_model': "facebook/esm2_t6_8M_UR50D",
                'freeze_encoder': False,
                'use_lora': False
            },
            'structure_encoder': {
                'type': "multi_scale",
                'hidden_dim': 320,  # ä¸ESM2å®Œå…¨åŒ¹é…
                'use_esmfold': True,  # âœ… å¯ç”¨ESMFold
                'use_cache': True,   # ä½¿ç”¨ç¼“å­˜å‡å°‘è®¡ç®—
                'cache_dir': "./cache",
                'memory_efficient': True,  # å¯ç”¨å†…å­˜ä¼˜åŒ–
                'batch_size_limit': 1,     # ESMFoldæ‰¹æ¬¡é™åˆ¶
                
                'local': {
                    'hidden_dim': 320,
                    'num_layers': 2,  # å‡å°‘å±‚æ•°èŠ‚çœå†…å­˜
                    'kernel_sizes': [3, 5],
                    'dropout': 0.1
                },
                'global': {
                    'hidden_dim': 320,
                    'num_attention_heads': 8,  # 320 Ã· 8 = 40 (å®Œç¾æ•´é™¤)
                    'num_layers': 2,
                    'dropout': 0.1
                },
                'fusion': {
                    'method': "attention",
                    'hidden_dim': 320
                }
            },
            'denoiser': {
                'hidden_dim': 320,     # âœ… ç¡®ä¿ä¸å…¶ä»–ç»„ä»¶åŒ¹é…
                'num_layers': 4,       # å‡å°‘å±‚æ•°èŠ‚çœå†…å­˜
                'num_heads': 8,        # âœ… 320 Ã· 8 = 40 (å®Œç¾æ•´é™¤)
                'dropout': 0.1,
                'use_cross_attention': True  # âœ… å¯ç”¨äº¤å‰æ³¨æ„åŠ›
            },
            'sequence_decoder': {
                'hidden_dim': 320,
                'num_layers': 2,  # å‡å°‘å±‚æ•°
                'vocab_size': 33,
                'dropout': 0.1
            }
        },
        
        'diffusion': {
            'num_timesteps': 1000,
            'noise_schedule': "sqrt",
            'beta_start': 0.0001,
            'beta_end': 0.02,
            'sampling_method': "ddpm",
            'ddim_steps': 50
        },
        
        'separated_training': {
            'stage1': {
                'epochs': 30,      # é€‚åº¦å‡å°‘ç”¨äºæµ‹è¯•
                'batch_size': 1,   # æœ€å°æ‰¹æ¬¡é¿å…å†…å­˜é—®é¢˜
                'learning_rate': 1e-4,
                'warmup_steps': 100,
                'gradient_clip': 1.0,
                'optimizer': {
                    'type': "AdamW",
                    'weight_decay': 0.01,
                    'betas': [0.9, 0.999],
                    'eps': 1e-8
                },
                'scheduler': {
                    'type': "cosine",
                    'eta_min': 1e-6
                }
            },
            'stage2': {
                'epochs': 20,
                'batch_size': 1,   # ä¿æŒæœ€å°æ‰¹æ¬¡
                'learning_rate': 5e-5,
                'warmup_steps': 50,
                'gradient_clip': 0.5,
                'optimizer': {
                    'type': "AdamW",
                    'weight_decay': 0.01,
                    'betas': [0.9, 0.999],
                    'eps': 1e-8
                },
                'scheduler': {
                    'type': "cosine",
                    'eta_min': 1e-6
                }
            }
        },
        
        'data': {
            'data_dir': "./data/processed",
            'train_file': "train.csv",
            'val_file': "val.csv",
            'max_length': 50,
            'min_length': 5,
            'num_workers': 0,        # ç¦ç”¨å¤šè¿›ç¨‹é¿å…CUDAå†²çª
            'pin_memory': False,     # ç¦ç”¨pin_memoryèŠ‚çœå†…å­˜
            'use_predicted_structures': True,  # âœ… å¯ç”¨ç»“æ„ç‰¹å¾
            'structure_cache_dir': "./cache"
        },
        
        'length_control': {
            'enabled': True,
            'min_length': 5,
            'max_length': 50,
            'analyze_training_data': True,
            'save_distributions': True,
            'length_penalty_weight': 0.1
        },
        
        'classifier_free_guidance': {
            'enabled': True,
            'dropout_prob': 0.1,
            'guidance_scale': 2.0,
            'adaptive_guidance': True,
            'guidance_schedule': "cosine"
        },
        
        'training_enhancements': {
            'use_amp': False,        # ç¦ç”¨AMPé¿å…å¤æ‚æ€§
            'use_ema': False,        # ç¦ç”¨EMAèŠ‚çœå†…å­˜
            'gradient_accumulation_steps': 16,  # å¢åŠ æ¢¯åº¦ç´¯ç§¯è¡¥å¿å°æ‰¹æ¬¡
            'save_every': 500,
            'validate_every': 100,
            'log_every': 10,
            'max_checkpoints': 2
        },
        
        'evaluation': {
            'enabled': False  # è®­ç»ƒé˜¶æ®µæš‚æ—¶ç¦ç”¨
        },
        
        'output': {
            'base_dir': "./outputs/structure_enabled_v1",
            'checkpoint_dir': "./outputs/structure_enabled_v1/checkpoints",
            'log_dir': "./outputs/structure_enabled_v1/logs",
            'results_dir': "./outputs/structure_enabled_v1/results",
            'save_model_config': True,
            'save_training_stats': True,
            'save_generated_samples': True
        },
        
        'monitoring': {
            'wandb': {'enabled': False},
            'tensorboard': {'enabled': False}
        },
        
        'debug': {
            'enabled': True,         # å¯ç”¨è°ƒè¯•ä¿¡æ¯
            'detailed_logging': True
        },
        
        'resources': {
            'device': "cuda:2",
            'available_gpus': [2, 3, 4, 5],
            'stage1_gpus': [2, 3],
            'stage2_gpus': [4, 5],
            'gpu_memory_fraction': 0.6,  # é™åˆ¶GPUå†…å­˜ä½¿ç”¨
            'allow_growth': True,
            'num_threads': 2,            # å‡å°‘CPUçº¿ç¨‹æ•°
            
            # ESMFoldå†…å­˜ä¼˜åŒ–é…ç½®
            'esmfold_memory_limit': '8GB',
            'structure_cache_size': 1000,
            'enable_structure_cache_cleanup': True
        }
    }
    
    # ä¿å­˜é…ç½®æ–‡ä»¶
    config_path = "configs/structure_enabled_training.yaml"
    with open(config_path, 'w', encoding='utf-8') as f:
        yaml.dump(optimized_config, f, default_flow_style=False, allow_unicode=True, indent=2)
    
    print(f"âœ… åˆ›å»ºç»“æ„æ„ŸçŸ¥é…ç½®: {config_path}")
    
    # è¾“å‡ºé…ç½®æ‘˜è¦
    print("\nğŸ“‹ å…³é”®é…ç½®:")
    print("   ğŸ§¬ ç»“æ„ç‰¹å¾: âœ… å¯ç”¨ (ESMFold + ç¼“å­˜)")
    print("   ğŸ”— äº¤å‰æ³¨æ„åŠ›: âœ… å¯ç”¨")
    print("   ğŸ”§ ç»´åº¦é…ç½®: hidden_dim=320, num_heads=8, head_dim=40")
    print("   ğŸ“¦ æ‰¹æ¬¡å¤§å°: 1 (æœ€å°åŒ–å†…å­˜ä½¿ç”¨)")
    print("   ğŸ”„ æ¢¯åº¦ç´¯ç§¯: 16 (è¡¥å¿å°æ‰¹æ¬¡)")
    print("   ğŸ’¾ å†…å­˜é™åˆ¶: 60% GPUå†…å­˜")
    
    return config_path

def optimize_structure_cache():
    """ä¼˜åŒ–ç»“æ„ç¼“å­˜é…ç½®"""
    print("ğŸ“ ä¼˜åŒ–ç»“æ„ç¼“å­˜é…ç½®...")
    
    cache_dir = Path("./cache")
    
    # ç¡®ä¿ç¼“å­˜ç›®å½•å­˜åœ¨
    for subdir in ['train', 'val', 'test']:
        (cache_dir / subdir).mkdir(parents=True, exist_ok=True)
    
    # æ£€æŸ¥ç°æœ‰ç¼“å­˜
    train_cache = cache_dir / "train"
    if train_cache.exists():
        cache_files = list(train_cache.glob("*.pt"))
        print(f"   ğŸ“Š è®­ç»ƒç¼“å­˜æ–‡ä»¶: {len(cache_files)} ä¸ª")
    
    val_cache = cache_dir / "val"
    if val_cache.exists():
        cache_files = list(val_cache.glob("*.pt"))
        print(f"   ğŸ“Š éªŒè¯ç¼“å­˜æ–‡ä»¶: {len(cache_files)} ä¸ª")
    
    # åˆ›å»ºç¼“å­˜é…ç½®æ–‡ä»¶
    cache_config = {
        'version': '1.0',
        'structure_type': 'esmfold',
        'feature_dim': 320,
        'max_length': 50,
        'memory_limit': '8GB',
        'cleanup_policy': 'lru',
        'cache_size_limit': 1000
    }
    
    with open(cache_dir / "cache_config.yaml", 'w') as f:
        yaml.dump(cache_config, f, indent=2)
    
    print("âœ… ç¼“å­˜é…ç½®å·²ä¼˜åŒ–")

def create_memory_optimized_restart_script():
    """åˆ›å»ºå†…å­˜ä¼˜åŒ–çš„é‡å¯è„šæœ¬"""
    print("ğŸ“ åˆ›å»ºå†…å­˜ä¼˜åŒ–é‡å¯è„šæœ¬...")
    
    script_content = '''#!/bin/bash
# StructDiffç»“æ„æ„ŸçŸ¥è®­ç»ƒé‡å¯è„šæœ¬

echo "ğŸš€ å¯åŠ¨ç»“æ„æ„ŸçŸ¥StructDiffåˆ†ç¦»å¼è®­ç»ƒ..."

# è®¾ç½®ç¯å¢ƒå˜é‡
export CUDA_VISIBLE_DEVICES=2,3,4,5
export PYTHONPATH="/home/qlyu/sequence/StructDiff-7.0.0:$PYTHONPATH"

# å†…å­˜ä¼˜åŒ–è®¾ç½®
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
export CUDA_LAUNCH_BLOCKING=0

# æ£€æŸ¥GPUå†…å­˜
echo "ğŸ” æ£€æŸ¥GPUå†…å­˜çŠ¶æ€..."
nvidia-smi --query-gpu=index,name,memory.used,memory.total --format=csv

# æ¸…ç†GPUå†…å­˜
echo "ğŸ§¹ æ¸…ç†GPUå†…å­˜..."
python -c "
import torch
if torch.cuda.is_available():
    torch.cuda.empty_cache()
    print('GPUç¼“å­˜å·²æ¸…ç†')
"

# æ£€æŸ¥æ•°æ®
echo "ğŸ“Š æ£€æŸ¥æ•°æ®å’Œç¼“å­˜çŠ¶æ€..."
ls -la ./data/processed/
ls -la ./cache/

echo "ğŸ¯ å¼€å§‹ç»“æ„æ„ŸçŸ¥è®­ç»ƒ..."
cd /home/qlyu/sequence/StructDiff-7.0.0

python scripts/train_separated.py \\
    --config configs/structure_enabled_training.yaml \\
    --data-dir ./data/processed \\
    --output-dir ./outputs/structure_enabled_v1 \\
    --device auto \\
    --stage both \\
    --use-cfg \\
    --use-length-control \\
    --debug

echo "âœ… è®­ç»ƒå·²å¯åŠ¨"
'''
    
    script_path = "restart_structure_training.sh"
    with open(script_path, 'w') as f:
        f.write(script_content)
    
    os.chmod(script_path, 0o755)
    print(f"âœ… åˆ›å»ºé‡å¯è„šæœ¬: {script_path}")
    
    return script_path

def create_structure_cache_validator():
    """åˆ›å»ºç»“æ„ç¼“å­˜éªŒè¯è„šæœ¬"""
    print("ğŸ” åˆ›å»ºç»“æ„ç¼“å­˜éªŒè¯è„šæœ¬...")
    
    validator_content = '''#!/usr/bin/env python3
"""ç»“æ„ç¼“å­˜éªŒè¯å·¥å…·"""
import torch
from pathlib import Path
import pandas as pd

def validate_structure_cache():
    """éªŒè¯ç»“æ„ç¼“å­˜çš„å®Œæ•´æ€§"""
    print("ğŸ” éªŒè¯ç»“æ„ç¼“å­˜...")
    
    cache_dir = Path("./cache")
    data_dir = Path("./data/processed")
    
    # æ£€æŸ¥è®­ç»ƒæ•°æ®
    train_file = data_dir / "train.csv"
    if train_file.exists():
        train_df = pd.read_csv(train_file)
        print(f"è®­ç»ƒæ•°æ®: {len(train_df)} æ¡åºåˆ—")
        
        # æ£€æŸ¥å¯¹åº”çš„ç¼“å­˜æ–‡ä»¶
        train_cache_dir = cache_dir / "train"
        if train_cache_dir.exists():
            cache_files = list(train_cache_dir.glob("*.pt"))
            print(f"è®­ç»ƒç¼“å­˜: {len(cache_files)} ä¸ªæ–‡ä»¶")
            
            # éšæœºæ£€æŸ¥å‡ ä¸ªç¼“å­˜æ–‡ä»¶
            for i, cache_file in enumerate(cache_files[:3]):
                try:
                    cached_data = torch.load(cache_file, map_location='cpu')
                    if isinstance(cached_data, dict):
                        features = cached_data.get('features')
                        if features is not None:
                            print(f"  ç¼“å­˜æ–‡ä»¶ {i+1}: ç‰¹å¾ç»´åº¦ {features.shape}")
                        else:
                            print(f"  ç¼“å­˜æ–‡ä»¶ {i+1}: æ— ç‰¹å¾æ•°æ®")
                    else:
                        print(f"  ç¼“å­˜æ–‡ä»¶ {i+1}: ç‰¹å¾ç»´åº¦ {cached_data.shape}")
                except Exception as e:
                    print(f"  ç¼“å­˜æ–‡ä»¶ {i+1}: åŠ è½½å¤±è´¥ - {e}")
    
    print("âœ… ç¼“å­˜éªŒè¯å®Œæˆ")

if __name__ == "__main__":
    validate_structure_cache()
'''
    
    validator_path = "validate_structure_cache.py"
    with open(validator_path, 'w') as f:
        f.write(validator_content)
    
    os.chmod(validator_path, 0o755)
    print(f"âœ… åˆ›å»ºç¼“å­˜éªŒè¯è„šæœ¬: {validator_path}")

def main():
    """ä¸»ä¿®å¤æµç¨‹"""
    print("ğŸ”§ StructDiffç»“æ„æ„ŸçŸ¥è®­ç»ƒä¿®å¤ç¨‹åº")
    print("=" * 60)
    print("ç›®æ ‡: ä¿ç•™ç»“æ„ç‰¹å¾å’Œäº¤å‰æ³¨æ„åŠ›çš„åŒæ—¶è§£å†³ç»´åº¦å’Œå†…å­˜é—®é¢˜")
    print("=" * 60)
    
    # 1. åœæ­¢ç°æœ‰è®­ç»ƒ
    stop_all_training()
    
    # 2. åˆ†æç»´åº¦é—®é¢˜
    analyze_dimension_issue()
    
    # 3. åˆ›å»ºä¼˜åŒ–é…ç½®
    config_path = create_structure_enabled_config()
    
    # 4. ä¼˜åŒ–ç»“æ„ç¼“å­˜
    optimize_structure_cache()
    
    # 5. åˆ›å»ºé‡å¯è„šæœ¬
    restart_script = create_memory_optimized_restart_script()
    
    # 6. åˆ›å»ºéªŒè¯å·¥å…·
    create_structure_cache_validator()
    
    print("\nğŸ‰ ç»“æ„æ„ŸçŸ¥è®­ç»ƒä¿®å¤å®Œæˆ!")
    print("=" * 50)
    print("ğŸ“‹ ä¿®å¤æ‘˜è¦:")
    print("  âœ… ä¿ç•™ç»“æ„ç‰¹å¾ (ESMFold + ç¼“å­˜)")
    print("  âœ… ä¿ç•™äº¤å‰æ³¨æ„åŠ›æœºåˆ¶")
    print("  âœ… ä¿®å¤ç»´åº¦é…ç½® (320ç»´, 8å¤´, æ¯å¤´40ç»´)")
    print("  âœ… ä¼˜åŒ–å†…å­˜ä½¿ç”¨ç­–ç•¥")
    print("  âœ… åˆ›å»ºä¸“ç”¨é…ç½®å’Œè„šæœ¬")
    
    print(f"\nğŸš€ ä½¿ç”¨ä¿®å¤åçš„è®­ç»ƒ:")
    print(f"   ./{restart_script}")
    
    print(f"\nğŸ” éªŒè¯ç¼“å­˜çŠ¶æ€:")
    print(f"   python validate_structure_cache.py")
    
    print("\nğŸ¯ æ ¸å¿ƒæ”¹è¿›:")
    print("  â€¢ ç»´åº¦å…¼å®¹: hidden_dim=320, num_heads=8 (å®Œç¾æ•´é™¤)")
    print("  â€¢ å†…å­˜ä¼˜åŒ–: batch_size=1, æ¢¯åº¦ç´¯ç§¯=16")
    print("  â€¢ ç»“æ„ç¼“å­˜: å¯ç”¨é¢„è®¡ç®—å’Œæ¸…ç†ç­–ç•¥")
    print("  â€¢ GPUç®¡ç†: é™åˆ¶60%å†…å­˜ä½¿ç”¨")

if __name__ == "__main__":
    main() 