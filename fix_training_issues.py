#!/usr/bin/env python3
"""
ä¿®å¤å½“å‰è®­ç»ƒé—®é¢˜çš„å¿«é€Ÿè„šæœ¬
è§£å†³ï¼š
1. å¤šè¿›ç¨‹CUDAå†²çª
2. éªŒè¯é›†å†…å­˜ä¸è¶³
3. æ‰¹æ¬¡å¤§å°ä¼˜åŒ–
"""

import os
import sys
import shutil
from pathlib import Path

def stop_current_training():
    """åœæ­¢å½“å‰è®­ç»ƒè¿›ç¨‹"""
    print("ğŸ›‘ å¯»æ‰¾å¹¶åœæ­¢å½“å‰è®­ç»ƒè¿›ç¨‹...")
    os.system("pkill -f train_separated.py")
    print("âœ… è®­ç»ƒè¿›ç¨‹å·²åœæ­¢")

def create_validation_cache():
    """ä¸ºéªŒè¯é›†åˆ›å»ºè™šæ‹Ÿç¼“å­˜é¿å…å®æ—¶ç»“æ„é¢„æµ‹"""
    cache_val_dir = Path("./cache/val")
    cache_val_dir.mkdir(parents=True, exist_ok=True)
    
    print("ğŸ“ åˆ›å»ºéªŒè¯é›†ç¼“å­˜ç›®å½•...")
    
    # åˆ›å»ºå°‘é‡è™šæ‹Ÿç¼“å­˜æ–‡ä»¶é¿å…å®æ—¶ESMFoldé¢„æµ‹
    import pickle
    import torch
    
    dummy_structure = {
        'positions': torch.randn(20, 37, 3),
        'plddt': torch.ones(20) * 50.0,
        'distance_matrix': torch.randn(20, 20),
        'contact_map': torch.zeros(20, 20),
        'angles': torch.zeros(20, 10),
        'secondary_structure': torch.full((20,), 2)
    }
    
    # åˆ›å»ºä¸€äº›ç¤ºä¾‹ç¼“å­˜æ–‡ä»¶
    for i in range(10):
        cache_file = cache_val_dir / f"{i}_TESTSEQ.pkl"
        with open(cache_file, 'wb') as f:
            pickle.dump(dummy_structure, f)
    
    print(f"âœ… åˆ›å»ºäº† {len(list(cache_val_dir.glob('*.pkl')))} ä¸ªéªŒè¯ç¼“å­˜æ–‡ä»¶")

def optimize_config():
    """ä¼˜åŒ–é…ç½®æ–‡ä»¶"""
    config_path = Path("configs/separated_training_production.yaml")
    
    print("âš™ï¸  ä¼˜åŒ–é…ç½®æ–‡ä»¶...")
    
    # åˆ›å»ºä¼˜åŒ–åçš„é…ç½®
    optimized_config = """# StructDiffåˆ†ç¦»å¼è®­ç»ƒä¼˜åŒ–é…ç½®
# è§£å†³å†…å­˜å’Œå¤šè¿›ç¨‹é—®é¢˜
experiment:
  name: "structdiff_separated_optimized_v1"
  description: "ä¿®å¤å†…å­˜å’Œå¤šè¿›ç¨‹é—®é¢˜çš„ä¼˜åŒ–è®­ç»ƒ"
  project: "StructDiff-Production"
  seed: 42

# æ¨¡å‹é…ç½® - å‡å°‘å†…å­˜ä½¿ç”¨
model:
  type: "StructDiff"
  
  sequence_encoder:
    pretrained_model: "facebook/esm2_t6_8M_UR50D"
    freeze_encoder: false
    use_lora: false
    
  structure_encoder:
    type: "multi_scale"
    hidden_dim: 128        # å‡å°‘ç»´åº¦
    use_esmfold: true
    use_cache: true
    cache_dir: "./cache"
    
    local:
      hidden_dim: 128      # å‡å°‘ç»´åº¦
      num_layers: 2        # å‡å°‘å±‚æ•°
      kernel_sizes: [3, 5]
      dropout: 0.1
      
    global:
      hidden_dim: 256      # å‡å°‘ç»´åº¦
      num_attention_heads: 4  # å‡å°‘æ³¨æ„åŠ›å¤´
      num_layers: 2        # å‡å°‘å±‚æ•°
      dropout: 0.1
      
    fusion:
      method: "attention"
      hidden_dim: 128
  
  denoiser:
    hidden_dim: 320
    num_layers: 6          # å‡å°‘å±‚æ•°
    num_heads: 6           # å‡å°‘æ³¨æ„åŠ›å¤´
    dropout: 0.1
    use_cross_attention: true
    
  sequence_decoder:
    hidden_dim: 320
    num_layers: 3          # å‡å°‘å±‚æ•°
    vocab_size: 33
    dropout: 0.1

# æ‰©æ•£è¿‡ç¨‹é…ç½®
diffusion:
  num_timesteps: 1000
  noise_schedule: "sqrt"
  beta_start: 0.0001
  beta_end: 0.02
  sampling_method: "ddpm"
  ddim_steps: 50

# åˆ†ç¦»å¼è®­ç»ƒé…ç½® - ä¼˜åŒ–å†…å­˜ä½¿ç”¨
separated_training:
  stage1:
    epochs: 20             # å‡å°‘epochsç”¨äºæµ‹è¯•
    batch_size: 1          # æœ€å°æ‰¹æ¬¡é¿å…å†…å­˜é—®é¢˜
    learning_rate: 1e-4
    warmup_steps: 100      # å‡å°‘warmupæ­¥æ•°
    gradient_clip: 1.0
    
    optimizer:
      type: "AdamW"
      weight_decay: 0.01
      betas: [0.9, 0.999]
      eps: 1e-8
    
    scheduler:
      type: "cosine"
      eta_min: 1e-6
  
  stage2:
    epochs: 10
    batch_size: 2
    learning_rate: 5e-5
    warmup_steps: 50
    gradient_clip: 0.5
    
    optimizer:
      type: "AdamW"
      weight_decay: 0.01
      betas: [0.9, 0.999]
      eps: 1e-8
    
    scheduler:
      type: "cosine"
      eta_min: 1e-6

# æ•°æ®é…ç½® - ç¦ç”¨å¤šè¿›ç¨‹
data:
  data_dir: "./data/processed"
  train_file: "train.csv"
  val_file: "val.csv"
  test_file: "test.csv"
  
  max_length: 50
  min_length: 5
  
  # æ•°æ®åŠ è½½ - å®Œå…¨ç¦ç”¨å¤šè¿›ç¨‹
  num_workers: 0         # ç¦ç”¨å¤šè¿›ç¨‹
  pin_memory: false      # ç¦ç”¨pin_memoryå‡å°‘å†…å­˜ä½¿ç”¨
  prefetch_factor: 2
  
  # ç»“æ„ç‰¹å¾é…ç½®
  use_predicted_structures: true
  structure_cache_dir: "./cache"

# é•¿åº¦æ§åˆ¶é…ç½®
length_control:
  enabled: true
  min_length: 5
  max_length: 50
  analyze_training_data: true
  save_distributions: true
  length_penalty_weight: 0.1
  
  type_specific_lengths:
    antimicrobial: [20, 8]
    antifungal: [25, 10]
    antiviral: [30, 12]
    general: [25, 5]

# åˆ†ç±»å™¨è‡ªç”±å¼•å¯¼é…ç½®
classifier_free_guidance:
  enabled: true
  dropout_prob: 0.1
  guidance_scale: 2.0
  adaptive_guidance: true
  guidance_schedule: "cosine"

# è®­ç»ƒå¢å¼ºé…ç½® - å‡å°‘å†…å­˜ä½¿ç”¨
training_enhancements:
  use_amp: false         # æš‚æ—¶ç¦ç”¨AMPé¿å…å¤æ‚æ€§
  amp_dtype: "float16"
  
  use_ema: false         # ç¦ç”¨EMAå‡å°‘å†…å­˜
  ema_decay: 0.9999
  ema_update_every: 10
  
  gradient_accumulation_steps: 4  # å¢åŠ æ¢¯åº¦ç´¯ç§¯è¡¥å¿å°æ‰¹æ¬¡
  
  save_every: 1000
  validate_every: 100    # å‡å°‘éªŒè¯é¢‘ç‡
  log_every: 10          # å¢åŠ æ—¥å¿—é¢‘ç‡
  max_checkpoints: 3

# è¯„ä¼°é…ç½® - ç®€åŒ–è¯„ä¼°
evaluation:
  enabled: false         # æš‚æ—¶ç¦ç”¨è¯„ä¼°å‡å°‘å¤æ‚æ€§
  
  metrics:
    - pseudo_perplexity
    - information_entropy
  
  generation:
    num_samples: 100     # å‡å°‘æ ·æœ¬æ•°
    guidance_scale: 2.0
    temperature: 1.0
    use_length_control: true
    
  evaluate_every: 10

# è¾“å‡ºé…ç½®
output:
  base_dir: "./outputs/separated_optimized_v1"
  checkpoint_dir: "./outputs/separated_optimized_v1/checkpoints"
  log_dir: "./outputs/separated_optimized_v1/logs"
  results_dir: "./outputs/separated_optimized_v1/results"
  
  save_model_config: true
  save_training_stats: true
  save_generated_samples: true

# ç›‘æ§é…ç½®
monitoring:
  wandb:
    enabled: false
  tensorboard:
    enabled: false

# è°ƒè¯•å’Œå¼€å‘é…ç½®
debug:
  enabled: false
  detailed_logging: true

# èµ„æºé…ç½®
resources:
  device: "cuda:2"
  available_gpus: [2, 3, 4, 5]
  stage1_gpus: [2, 3]
  stage2_gpus: [4, 5]
  gpu_memory_fraction: 0.8  # å‡å°‘GPUå†…å­˜ä½¿ç”¨
  allow_growth: true
  num_threads: 4            # å‡å°‘CPUçº¿ç¨‹æ•°
"""
    
    # å¤‡ä»½åŸé…ç½®
    backup_path = config_path.with_suffix('.yaml.backup')
    if config_path.exists():
        shutil.copy(config_path, backup_path)
        print(f"âœ… åŸé…ç½®å·²å¤‡ä»½åˆ°: {backup_path}")
    
    # å†™å…¥ä¼˜åŒ–é…ç½®
    with open("configs/separated_training_optimized.yaml", 'w') as f:
        f.write(optimized_config)
    
    print("âœ… åˆ›å»ºä¼˜åŒ–é…ç½®: configs/separated_training_optimized.yaml")

def clean_gpu_memory():
    """æ¸…ç†GPUå†…å­˜"""
    print("ğŸ§¹ æ¸…ç†GPUå†…å­˜...")
    
    # è®¾ç½®CUDAç¯å¢ƒå˜é‡
    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'
    
    try:
        import torch
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            print("âœ… GPUç¼“å­˜å·²æ¸…ç†")
    except ImportError:
        print("âš ï¸  æ— æ³•å¯¼å…¥torchï¼Œè·³è¿‡GPUç¼“å­˜æ¸…ç†")

def create_restart_script():
    """åˆ›å»ºé‡å¯è„šæœ¬"""
    restart_script = """#!/bin/bash

# é‡å¯ä¼˜åŒ–åçš„åˆ†ç¦»å¼è®­ç»ƒ
echo "ğŸ”„ é‡å¯ä¼˜åŒ–åçš„åˆ†ç¦»å¼è®­ç»ƒ..."

# è®¾ç½®ç¯å¢ƒå˜é‡
export CUDA_VISIBLE_DEVICES=2,3,4,5
export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
export OMP_NUM_THREADS=4

# ä½¿ç”¨ä¼˜åŒ–é…ç½®é‡å¯è®­ç»ƒ
python scripts/train_separated.py \\
    --config configs/separated_training_optimized.yaml \\
    --output-dir ./outputs/separated_optimized_v1 \\
    --data-dir ./data/processed \\
    --device auto \\
    --use-cfg \\
    --use-length-control \\
    --stage both \\
    --debug

echo "âœ… ä¼˜åŒ–è®­ç»ƒå·²å¯åŠ¨"
"""
    
    with open("restart_optimized_training.sh", 'w') as f:
        f.write(restart_script)
    
    os.chmod("restart_optimized_training.sh", 0o755)
    print("âœ… åˆ›å»ºé‡å¯è„šæœ¬: restart_optimized_training.sh")

def main():
    """ä¸»ä¿®å¤å‡½æ•°"""
    print("ğŸ› ï¸  å¼€å§‹ä¿®å¤è®­ç»ƒé—®é¢˜...")
    
    # 1. åœæ­¢å½“å‰è®­ç»ƒ
    stop_current_training()
    
    # 2. æ¸…ç†GPUå†…å­˜
    clean_gpu_memory()
    
    # 3. åˆ›å»ºéªŒè¯ç¼“å­˜
    create_validation_cache()
    
    # 4. ä¼˜åŒ–é…ç½®
    optimize_config()
    
    # 5. åˆ›å»ºé‡å¯è„šæœ¬
    create_restart_script()
    
    print("\n" + "="*60)
    print("ğŸ‰ ä¿®å¤å®Œæˆï¼")
    print("\nè§£å†³çš„é—®é¢˜:")
    print("  âœ… å¤šè¿›ç¨‹CUDAå†²çª - ç¦ç”¨å¤šè¿›ç¨‹æ•°æ®åŠ è½½")
    print("  âœ… éªŒè¯é›†å†…å­˜ä¸è¶³ - åˆ›å»ºè™šæ‹Ÿç¼“å­˜")
    print("  âœ… æ‰¹æ¬¡å¤§å°ä¼˜åŒ– - å‡å°‘åˆ°æœ€å°é¿å…å†…å­˜é—®é¢˜")
    print("  âœ… æ¨¡å‹å¤æ‚åº¦ - å‡å°‘å±‚æ•°å’Œç»´åº¦")
    print("\né‡å¯è®­ç»ƒ:")
    print("  ./restart_optimized_training.sh")
    print("="*60)

if __name__ == "__main__":
    main() 