#!/usr/bin/env python3
"""
GPUèµ„æºç›‘æ§è„šæœ¬
ç›‘æ§GPUå¯ç”¨å†…å­˜ï¼Œå½“æ»¡è¶³è®­ç»ƒè¦æ±‚æ—¶å‘å‡ºé€šçŸ¥
"""

import time
import subprocess
import re
from datetime import datetime

def get_gpu_info():
    """è·å–GPUä¿¡æ¯"""
    try:
        result = subprocess.run(['nvidia-smi', '--query-gpu=index,memory.used,memory.total,utilization.gpu', '--format=csv'], 
                              capture_output=True, text=True)
        lines = result.stdout.strip().split('\n')[1:]  # è·³è¿‡è¡¨å¤´
        
        gpu_info = []
        for line in lines:
            parts = line.split(', ')
            gpu_id = int(parts[0])
            memory_used = int(parts[1].replace(' MiB', ''))  # MB
            memory_total = int(parts[2].replace(' MiB', ''))  # MB
            utilization = int(parts[3].replace(' %', ''))  # %
            
            memory_free = memory_total - memory_used
            memory_usage_percent = (memory_used / memory_total) * 100
            
            gpu_info.append({
                'id': gpu_id,
                'memory_used': memory_used,
                'memory_total': memory_total,
                'memory_free': memory_free,
                'memory_usage_percent': memory_usage_percent,
                'utilization': utilization
            })
        
        return gpu_info
    except Exception as e:
        print(f"è·å–GPUä¿¡æ¯å¤±è´¥: {e}")
        return []

def check_training_feasibility(gpu_info, min_memory_gb=8):
    """æ£€æŸ¥æ˜¯å¦æœ‰GPUæ»¡è¶³è®­ç»ƒè¦æ±‚"""
    min_memory_mb = min_memory_gb * 1024
    
    suitable_gpus = []
    for gpu in gpu_info:
        if gpu['memory_free'] >= min_memory_mb:
            suitable_gpus.append(gpu)
    
    return suitable_gpus

def main():
    print("ğŸ” GPUèµ„æºç›‘æ§å™¨")
    print("=" * 50)
    print("ç›‘æ§GPUå¯ç”¨å†…å­˜ï¼Œå¯»æ‰¾é€‚åˆè®­ç»ƒçš„æ—¶æœº")
    print("è®­ç»ƒéœ€è¦çº¦8GB GPUå†…å­˜ç”¨äºESM2æ¨¡å‹")
    print("æŒ‰ Ctrl+C åœæ­¢ç›‘æ§")
    print()
    
    check_interval = 30  # 30ç§’æ£€æŸ¥ä¸€æ¬¡
    
    while True:
        try:
            current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            print(f"[{current_time}] æ£€æŸ¥GPUçŠ¶æ€...")
            
            gpu_info = get_gpu_info()
            if not gpu_info:
                print("âŒ æ— æ³•è·å–GPUä¿¡æ¯")
                time.sleep(check_interval)
                continue
            
            # æ˜¾ç¤ºå½“å‰çŠ¶æ€
            print("\nğŸ“Š å½“å‰GPUçŠ¶æ€:")
            for gpu in gpu_info:
                status = "ğŸŸ¢ å¯ç”¨" if gpu['memory_free'] >= 8192 else "ğŸ”´ å¿™ç¢Œ"
                print(f"  GPU {gpu['id']}: {status}")
                print(f"    å†…å­˜: {gpu['memory_used']:.0f}/{gpu['memory_total']:.0f} MB "
                      f"({gpu['memory_usage_percent']:.1f}% å·²ç”¨)")
                print(f"    å¯ç”¨: {gpu['memory_free']:.0f} MB ({gpu['memory_free']/1024:.1f} GB)")
                print(f"    åˆ©ç”¨ç‡: {gpu['utilization']}%")
                print()
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨GPU
            suitable_gpus = check_training_feasibility(gpu_info, min_memory_gb=8)
            
            if suitable_gpus:
                print("ğŸ‰ å‘ç°å¯ç”¨GPU!")
                print("=" * 50)
                for gpu in suitable_gpus:
                    print(f"âœ… GPU {gpu['id']} æ»¡è¶³è®­ç»ƒè¦æ±‚:")
                    print(f"   å¯ç”¨å†…å­˜: {gpu['memory_free']/1024:.1f} GB")
                    print(f"   åˆ©ç”¨ç‡: {gpu['utilization']}%")
                
                print("\nğŸš€ å¯ä»¥å¯åŠ¨è®­ç»ƒäº†!")
                print("å»ºè®®ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¯åŠ¨è®­ç»ƒ:")
                best_gpu = max(suitable_gpus, key=lambda x: x['memory_free'])
                print(f"cd /home/qlyu/sequence/StructDiff-7.0.0")
                
                # æ ¹æ®å¯ç”¨å†…å­˜æ¨èé…ç½®
                available_gb = best_gpu['memory_free'] / 1024
                if available_gb >= 15:
                    batch_size = 16
                    accumulation = 2
                elif available_gb >= 10:
                    batch_size = 8
                    accumulation = 4
                else:
                    batch_size = 4
                    accumulation = 8
                
                print(f"# æ¨èé…ç½®: batch_size={batch_size}, accumulation_steps={accumulation}")
                print(f"# ä½¿ç”¨GPU {best_gpu['id']} (å¯ç”¨å†…å­˜: {available_gb:.1f} GB)")
                
                # åˆ›å»ºä¸´æ—¶é…ç½®æ–‡ä»¶
                config_script = f"""
# ä¿®æ”¹train_with_precomputed_features.pyä¸­çš„é…ç½®:
config = {{
    'batch_size': {batch_size},
    'num_workers': 2 if {batch_size} >= 8 else 0,
    'accumulation_steps': {accumulation},
    'device': 'cuda:{best_gpu["id"]}',
    # ... å…¶ä»–é…ç½®ä¿æŒä¸å˜
}}
"""
                print("\næ¨èé…ç½®:")
                print(config_script)
                
                break
            else:
                print("â³ æš‚æ— å¯ç”¨GPUï¼Œç»§ç»­ç›‘æ§...")
            
            print(f"ä¸‹æ¬¡æ£€æŸ¥æ—¶é—´: {check_interval}ç§’å")
            print("-" * 50)
            
            time.sleep(check_interval)
            
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ç›‘æ§å·²åœæ­¢")
            break
        except Exception as e:
            print(f"âŒ ç›‘æ§è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            time.sleep(check_interval)

if __name__ == "__main__":
    main() 