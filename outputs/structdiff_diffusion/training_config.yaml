experiment:
  name: structdiff_diffusion_generation
  project: StructDiff-Diffusion
  seed: 42
  output_dir: ./outputs/structdiff_diffusion
  checkpoint_dir: ./outputs/structdiff_diffusion/checkpoints
  log_dir: ./outputs/structdiff_diffusion/logs
model:
  type: StructDiff
  sequence_encoder:
    pretrained_model: facebook/esm2_t6_8M_UR50D
    freeze_encoder: false
    use_lora: true
    lora_rank: 16
    lora_alpha: 32
    lora_dropout: 0.1
  structure_encoder:
    type: multi_scale
    hidden_dim: 320
    use_esmfold: true
    local:
      hidden_dim: 320
      num_layers: 4
      kernel_sizes:
      - 3
      - 5
      - 7
      - 9
      dropout: 0.1
    global:
      hidden_dim: 512
      num_attention_heads: 8
      num_layers: 6
      dropout: 0.1
    fusion:
      method: attention
      hidden_dim: 320
  denoiser:
    hidden_dim: 256
    num_layers: 6
    num_heads: 8
    dropout: 0.1
    use_cross_attention: true
    use_adaptive_conditioning: true
    conditional_zero_init: true
data:
  train_path: ./data/processed/train.csv
  val_path: ./data/processed/val.csv
  test_path: ./data/processed/test.csv
  max_length: 50
  min_length: 5
  batch_size: 4
  num_workers: 0
  pin_memory: false
  prefetch_factor: 1
  use_predicted_structures: true
  structure_cache_dir: ./structure_cache
  target_columns:
    sequence: sequence
    label: label
    annotation: annotation
diffusion:
  num_timesteps: 1000
  noise_schedule: sqrt
  beta_start: 0.0001
  beta_end: 0.02
  loss_type: mse
  prediction_type: epsilon
  sampling_method: ddpm
  ddim_steps: 100
  conditioning:
    classifier_free_guidance: true
    guidance_scale: 1.5
    peptide_type: true
    structure_guidance: true
training:
  num_epochs: 50
  gradient_accumulation_steps: 8
  gradient_clip: 1.0
  use_amp: true
  amp_dtype: float16
  use_ema: true
  ema_decay: 0.9999
  ema_update_every: 5
  save_every: 500
  validate_every: 1
  log_every: 50
  max_checkpoints: 5
  optimizer:
    name: AdamW
    lr: 5.0e-05
    weight_decay: 0.01
    betas:
    - 0.9
    - 0.999
    eps: 1.0e-08
  scheduler:
    name: cosine
    warmup_epochs: 5
    min_lr: 1.0e-06
  early_stopping:
    enabled: true
    patience: 10
    metric: val_loss
    mode: min
training_config:
  loss_weights:
    diffusion_loss: 1.0
    structure_consistency_loss: 0.2
    auxiliary_loss: 0.05
memory_optimization:
  cleanup_frequency: 50
  generation_batch_size: 2
  gradient_checkpointing: true
evaluation:
  metrics:
  - perplexity
  - structure_consistency
  - diversity
  - peptide_properties
  generation:
    num_samples: 100
    guidance_scale: 1.5
    temperature: 1.0
logging:
  level: INFO
  format: '%(asctime)s - %(levelname)s - %(message)s'
  log_every: 50
system:
  cuda_visible_devices: '1'
  mixed_precision: true
  deterministic: false
  benchmark: true
