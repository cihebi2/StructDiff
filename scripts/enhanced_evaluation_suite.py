#!/usr/bin/env python3
"""
å¢å¼ºçš„å¤šè‚½ç”Ÿæˆæ¨¡å‹è¯„ä¼°å¥—ä»¶ - é›†æˆCPL-Diffè¯„ä¼°æŒ‡æ ‡
"""

import os
import sys
import json
import math
import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional
from pathlib import Path
from collections import Counter, defaultdict
import matplotlib.pyplot as plt
import seaborn as sns
from statistics import mean, stdev

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

class EnhancedPeptideEvaluationSuite:
    """
    å¢å¼ºçš„å¤šè‚½ç”Ÿæˆæ¨¡å‹è¯„ä¼°å¥—ä»¶
    é›†æˆäº†StructDiffåŸæœ‰è¯„ä¼°æŒ‡æ ‡å’ŒCPL-Diffçš„å…³é”®è¯„ä¼°æ–¹æ³•
    """
    
    def __init__(self, output_dir: str = "evaluation_results"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        # æ°¨åŸºé…¸å±æ€§
        self.aa_properties = {
            'hydrophobic': set('AILMFWYV'),
            'polar': set('NQST'),
            'charged_positive': set('KRH'),
            'charged_negative': set('DE'),
            'aromatic': set('FWY'),
            'small': set('AGSP'),
            'large': set('FWYH')
        }
        
        # å·²çŸ¥æŠ—èŒè‚½çš„æ°¨åŸºé…¸åå¥½
        self.amp_preferences = {
            'antimicrobial': {
                'preferred': set('KRLWF'),  # é˜³ç¦»å­ï¼Œç–æ°´
                'avoided': set('DE'),       # é˜´ç¦»å­
                'optimal_length_range': (8, 40),
                'optimal_charge_range': (2, 8)
            },
            'antifungal': {
                'preferred': set('KRFWYC'),
                'avoided': set('DE'),
                'optimal_length_range': (10, 50),
                'optimal_charge_range': (1, 6)
            },
            'antiviral': {
                'preferred': set('KRFWY'),
                'avoided': set('E'),
                'optimal_length_range': (12, 35),
                'optimal_charge_range': (3, 7)
            }
        }
        
        # åˆå§‹åŒ–æ¨¡å‹ï¼ˆå»¶è¿ŸåŠ è½½ï¼‰
        self.esm_model = None
        self.esm_tokenizer = None
        self.aligner = None
        
        print("ğŸ”¬ å¢å¼ºè¯„ä¼°å¥—ä»¶åˆå§‹åŒ–å®Œæˆ")
    
    def _init_esm_model(self):
        """å»¶è¿Ÿåˆå§‹åŒ–ESMæ¨¡å‹"""
        if self.esm_model is None:
            try:
                print("ğŸ“¥ æ­£åœ¨åŠ è½½ESM-2æ¨¡å‹è¿›è¡Œä¼ªå›°æƒ‘åº¦è®¡ç®—...")
                from transformers import AutoTokenizer, AutoModelForMaskedLM
                import torch
                
                model_name = 'facebook/esm2_t6_8M_UR50D'
                self.esm_tokenizer = AutoTokenizer.from_pretrained(model_name)
                self.esm_model = AutoModelForMaskedLM.from_pretrained(model_name)
                
                # ç§»åŠ¨åˆ°åˆé€‚çš„è®¾å¤‡
                device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
                self.esm_model = self.esm_model.to(device)
                self.esm_model.eval()
                
                print(f"âœ… ESM-2æ¨¡å‹åŠ è½½å®Œæˆï¼Œè®¾å¤‡: {device}")
                
            except ImportError as e:
                print(f"âš ï¸ æ— æ³•å¯¼å…¥transformersåº“: {e}")
                print("   è¯·å®‰è£…: pip install transformers torch")
                self.esm_model = None
            except Exception as e:
                print(f"âš ï¸ ESM-2æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
                self.esm_model = None
    
    def _init_aligner(self):
        """åˆå§‹åŒ–BLOSUM62æ¯”å¯¹å™¨"""
        if self.aligner is None:
            try:
                from Bio import Align
                self.aligner = Align.PairwiseAligner()
                self.aligner.substitution_matrix = Align.substitution_matrices.load("BLOSUM62")
                self.aligner.open_gap_score = -10
                self.aligner.extend_gap_score = -0.5
                print("âœ… BLOSUM62æ¯”å¯¹å™¨åˆå§‹åŒ–å®Œæˆ")
            except ImportError as e:
                print(f"âš ï¸ æ— æ³•å¯¼å…¥BioPython: {e}")
                print("   è¯·å®‰è£…: pip install biopython")
                self.aligner = None
            except Exception as e:
                print(f"âš ï¸ æ¯”å¯¹å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
                self.aligner = None
    
    def evaluate_pseudo_perplexity(self, sequences: List[str]) -> Dict:
        """
        è¯„ä¼°ä¼ªå›°æƒ‘åº¦ (Pseudo-Perplexity) - ä»CPL-Diffå€Ÿé‰´
        è¡¡é‡åºåˆ—çš„ç”Ÿç‰©å­¦åˆç†æ€§
        """
        print("ğŸ§® è®¡ç®—ä¼ªå›°æƒ‘åº¦...")
        self._init_esm_model()
        
        if self.esm_model is None:
            print("âŒ ESMæ¨¡å‹æœªå¯ç”¨ï¼Œè·³è¿‡ä¼ªå›°æƒ‘åº¦è®¡ç®—")
            return {
                'mean_pseudo_perplexity': float('nan'),
                'std_pseudo_perplexity': float('nan'),
                'valid_sequences': 0,
                'error': 'ESM model not available'
            }
        
        import torch
        import torch.nn.functional as F
        
        device = next(self.esm_model.parameters()).device
        pseudo_perplexities = []
        valid_sequences = 0
        
        for seq in sequences:
            if not seq or len(seq) < 2:
                continue
                
            try:
                # ç¼–ç åºåˆ—
                inputs = self.esm_tokenizer(
                    seq, 
                    return_tensors='pt', 
                    add_special_tokens=True,
                    max_length=512,
                    truncation=True
                )
                input_ids = inputs['input_ids'].to(device)
                attention_mask = inputs['attention_mask'].to(device)
                
                if input_ids.shape[1] < 3:  # è‡³å°‘éœ€è¦CLS, ä¸€ä¸ªæ°¨åŸºé…¸, SEP
                    continue
                
                total_loss = 0
                valid_positions = 0
                
                # é€ä½æ©ç é¢„æµ‹ (è·³è¿‡CLSå’ŒSEPæ ‡è®°)
                for pos in range(1, input_ids.shape[1] - 1):
                    if attention_mask[0, pos] == 0:  # è·³è¿‡padding
                        continue
                        
                    # åˆ›å»ºæ©ç è¾“å…¥
                    masked_input = input_ids.clone()
                    original_token = masked_input[0, pos].item()
                    masked_input[0, pos] = self.esm_tokenizer.mask_token_id
                    
                    # é¢„æµ‹
                    with torch.no_grad():
                        outputs = self.esm_model(masked_input, attention_mask=attention_mask)
                        logits = outputs.logits[0, pos]  # è·å–æ©ç ä½ç½®çš„logits
                        
                        # è®¡ç®—äº¤å‰ç†µæŸå¤±
                        loss = F.cross_entropy(logits.unsqueeze(0), torch.tensor([original_token], device=device))
                        total_loss += loss.item()
                        valid_positions += 1
                
                if valid_positions > 0:
                    avg_loss = total_loss / valid_positions
                    pseudo_perplexity = math.exp(avg_loss)
                    pseudo_perplexities.append(pseudo_perplexity)
                    valid_sequences += 1
                
            except Exception as e:
                print(f"âš ï¸ è®¡ç®—åºåˆ— '{seq[:20]}...' çš„ä¼ªå›°æƒ‘åº¦å¤±è´¥: {e}")
                continue
        
        if pseudo_perplexities:
            result = {
                'mean_pseudo_perplexity': mean(pseudo_perplexities),
                'std_pseudo_perplexity': stdev(pseudo_perplexities) if len(pseudo_perplexities) > 1 else 0.0,
                'valid_sequences': valid_sequences,
                'perplexity_distribution': pseudo_perplexities[:100]  # ä¿å­˜å‰100ä¸ªç”¨äºåˆ†æ
            }
            print(f"âœ… ä¼ªå›°æƒ‘åº¦è®¡ç®—å®Œæˆ: {result['mean_pseudo_perplexity']:.3f}Â±{result['std_pseudo_perplexity']:.3f}")
            return result
        else:
            return {
                'mean_pseudo_perplexity': float('nan'),
                'std_pseudo_perplexity': float('nan'),
                'valid_sequences': 0,
                'error': 'No valid sequences processed'
            }
    
    def evaluate_information_entropy(self, sequences: List[str]) -> Dict:
        """
        è¯„ä¼°ä¿¡æ¯ç†µ (Information Entropy) - ä»CPL-Diffå€Ÿé‰´
        è¡¡é‡åºåˆ—çš„æ°¨åŸºé…¸ç»„æˆå¤šæ ·æ€§
        """
        print("ğŸ“Š è®¡ç®—ä¿¡æ¯ç†µ...")
        
        entropies = []
        for seq in sequences:
            if not seq:
                continue
                
            # ç»Ÿè®¡æ°¨åŸºé…¸é¢‘ç‡
            aa_counts = Counter(seq)
            length = len(seq)
            
            if length == 0:
                continue
            
            # è®¡ç®—é¦™å†œç†µ
            entropy = 0
            for count in aa_counts.values():
                prob = count / length
                if prob > 0:  # é¿å…log(0)
                    entropy -= prob * math.log2(prob)
            
            entropies.append(entropy)
        
        if entropies:
            result = {
                'mean_entropy': mean(entropies),
                'std_entropy': stdev(entropies) if len(entropies) > 1 else 0.0,
                'min_entropy': min(entropies),
                'max_entropy': max(entropies),
                'entropy_distribution': entropies[:100]  # ä¿å­˜å‰100ä¸ªç”¨äºåˆ†æ
            }
            print(f"âœ… ä¿¡æ¯ç†µè®¡ç®—å®Œæˆ: {result['mean_entropy']:.3f}Â±{result['std_entropy']:.3f}")
            return result
        else:
            return {
                'mean_entropy': float('nan'),
                'std_entropy': float('nan'),
                'min_entropy': float('nan'),
                'max_entropy': float('nan'),
                'error': 'No valid sequences'
            }
    
    def evaluate_instability_index(self, sequences: List[str]) -> Dict:
        """
        è¯„ä¼°ä¸ç¨³å®šæ€§æŒ‡æ•° (Instability Index) - ä»CPL-Diffå€Ÿé‰´
        è¡¡é‡è‚½åºåˆ—çš„ç»“æ„ç¨³å®šæ€§
        """
        print("âš–ï¸ è®¡ç®—ä¸ç¨³å®šæ€§æŒ‡æ•°...")
        
        try:
            from modlamp.descriptors import GlobalDescriptor
            
            # åˆ›å»ºä¸´æ—¶fastaæ–‡ä»¶
            temp_fasta = self.output_dir / "temp_sequences.fasta"
            with open(temp_fasta, 'w') as f:
                for i, seq in enumerate(sequences):
                    if seq:  # è·³è¿‡ç©ºåºåˆ—
                        f.write(f">seq_{i}\n{seq}\n")
            
            # è®¡ç®—ä¸ç¨³å®šæ€§æŒ‡æ•°
            desc = GlobalDescriptor(str(temp_fasta))
            desc.instability_index()
            instability_scores = desc.descriptor.squeeze()
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            temp_fasta.unlink()
            
            if len(instability_scores) > 0:
                # ç¡®ä¿æ˜¯æ•°ç»„
                if isinstance(instability_scores, (int, float)):
                    instability_scores = [instability_scores]
                
                result = {
                    'mean_instability': mean(instability_scores),
                    'std_instability': stdev(instability_scores) if len(instability_scores) > 1 else 0.0,
                    'min_instability': min(instability_scores),
                    'max_instability': max(instability_scores),
                    'stable_peptides_ratio': len([s for s in instability_scores if s < 40]) / len(instability_scores)
                }
                print(f"âœ… ä¸ç¨³å®šæ€§æŒ‡æ•°è®¡ç®—å®Œæˆ: {result['mean_instability']:.2f}Â±{result['std_instability']:.2f}")
                return result
            else:
                return {'error': 'No instability scores computed'}
                
        except ImportError:
            print("âš ï¸ modlampåº“æœªå®‰è£…ï¼Œè·³è¿‡ä¸ç¨³å®šæ€§æŒ‡æ•°è®¡ç®—")
            print("   è¯·å®‰è£…: pip install modlamp")
            return {'error': 'modlamp not available'}
        except Exception as e:
            print(f"âš ï¸ ä¸ç¨³å®šæ€§æŒ‡æ•°è®¡ç®—å¤±è´¥: {e}")
            return {'error': str(e)}
    
    def evaluate_similarity_scores(self, generated_sequences: List[str], reference_sequences: List[str]) -> Dict:
        """
        è¯„ä¼°åºåˆ—ç›¸ä¼¼æ€§å¾—åˆ† - ä»CPL-Diffå€Ÿé‰´
        ä½¿ç”¨BLOSUM62çŸ©é˜µè®¡ç®—ä¸å‚è€ƒåºåˆ—çš„ç›¸ä¼¼æ€§
        """
        print("ğŸ” è®¡ç®—åºåˆ—ç›¸ä¼¼æ€§å¾—åˆ†...")
        self._init_aligner()
        
        if self.aligner is None:
            print("âŒ BLOSUM62æ¯”å¯¹å™¨æœªå¯ç”¨ï¼Œè·³è¿‡ç›¸ä¼¼æ€§è®¡ç®—")
            return {
                'mean_similarity': float('nan'),
                'std_similarity': float('nan'),
                'novelty_ratio': float('nan'),
                'error': 'Aligner not available'
            }
        
        similarity_scores = []
        high_similarity_threshold = 50  # å¯è°ƒèŠ‚çš„ç›¸ä¼¼æ€§é˜ˆå€¼
        
        for gen_seq in generated_sequences:
            if not gen_seq:
                continue
                
            max_similarity = 0
            try:
                for ref_seq in reference_sequences[:1000]:  # é™åˆ¶å‚è€ƒåºåˆ—æ•°é‡ä»¥æé«˜é€Ÿåº¦
                    if not ref_seq:
                        continue
                    
                    # è®¡ç®—æ¯”å¯¹å¾—åˆ†
                    alignments = self.aligner.align(gen_seq, ref_seq)
                    if alignments:
                        score = alignments.score
                        max_similarity = max(max_similarity, score)
                
                similarity_scores.append(max_similarity)
                
            except Exception as e:
                print(f"âš ï¸ è®¡ç®—åºåˆ—ç›¸ä¼¼æ€§å¤±è´¥: {e}")
                continue
        
        if similarity_scores:
            # è®¡ç®—æ–°é¢–æ€§æ¯”ä¾‹ï¼ˆä½ç›¸ä¼¼æ€§çš„åºåˆ—æ¯”ä¾‹ï¼‰
            novel_sequences = [s for s in similarity_scores if s < high_similarity_threshold]
            novelty_ratio = len(novel_sequences) / len(similarity_scores)
            
            result = {
                'mean_similarity': mean(similarity_scores),
                'std_similarity': stdev(similarity_scores) if len(similarity_scores) > 1 else 0.0,
                'min_similarity': min(similarity_scores),
                'max_similarity': max(similarity_scores),
                'novelty_ratio': novelty_ratio,
                'similarity_threshold': high_similarity_threshold,
                'total_comparisons': len(similarity_scores)
            }
            print(f"âœ… ç›¸ä¼¼æ€§è®¡ç®—å®Œæˆ: {result['mean_similarity']:.2f}Â±{result['std_similarity']:.2f}, æ–°é¢–æ€§: {novelty_ratio:.3f}")
            return result
        else:
            return {
                'mean_similarity': float('nan'),
                'std_similarity': float('nan'),
                'novelty_ratio': float('nan'),
                'error': 'No valid comparisons'
            }
    
    def evaluate_length_distribution(self, generated_lengths: List[int], reference_lengths: List[int]) -> Dict:
        """
        è¯„ä¼°é•¿åº¦åˆ†å¸ƒä¸€è‡´æ€§ - ä»CPL-Diffå€Ÿé‰´
        æ¯”è¾ƒç”Ÿæˆåºåˆ—ä¸å‚è€ƒåºåˆ—çš„é•¿åº¦åˆ†å¸ƒ
        """
        print("ğŸ“ è¯„ä¼°é•¿åº¦åˆ†å¸ƒä¸€è‡´æ€§...")
        
        try:
            from scipy.stats import ks_2samp, wasserstein_distance
            
            # Kolmogorov-Smirnovæ£€éªŒ
            ks_stat, p_value = ks_2samp(generated_lengths, reference_lengths)
            
            # Wassersteinè·ç¦»ï¼ˆEarth Mover's Distanceï¼‰
            wasserstein_dist = wasserstein_distance(generated_lengths, reference_lengths)
            
            # åŸºæœ¬ç»Ÿè®¡
            gen_stats = {
                'mean': mean(generated_lengths),
                'std': stdev(generated_lengths) if len(generated_lengths) > 1 else 0.0,
                'min': min(generated_lengths),
                'max': max(generated_lengths)
            }
            
            ref_stats = {
                'mean': mean(reference_lengths),
                'std': stdev(reference_lengths) if len(reference_lengths) > 1 else 0.0,
                'min': min(reference_lengths),
                'max': max(reference_lengths)
            }
            
            result = {
                'ks_statistic': ks_stat,
                'ks_p_value': p_value,
                'wasserstein_distance': wasserstein_dist,
                'generated_stats': gen_stats,
                'reference_stats': ref_stats,
                'distribution_match': p_value > 0.05  # æ˜¾è‘—æ€§æ°´å¹³0.05
            }
            
            print(f"âœ… é•¿åº¦åˆ†å¸ƒè¯„ä¼°å®Œæˆ: KS={ks_stat:.3f}, p={p_value:.3f}, Wasserstein={wasserstein_dist:.2f}")
            return result
            
        except ImportError:
            print("âš ï¸ scipyåº“æœªå®‰è£…ï¼Œè·³è¿‡ç»Ÿè®¡æ£€éªŒ")
            print("   è¯·å®‰è£…: pip install scipy")
            
            # åŸºæœ¬ç»Ÿè®¡ä½œä¸ºfallback
            gen_stats = {
                'mean': mean(generated_lengths),
                'std': stdev(generated_lengths) if len(generated_lengths) > 1 else 0.0
            }
            ref_stats = {
                'mean': mean(reference_lengths),
                'std': stdev(reference_lengths) if len(reference_lengths) > 1 else 0.0
            }
            
            return {
                'generated_stats': gen_stats,
                'reference_stats': ref_stats,
                'error': 'scipy not available'
            }
        except Exception as e:
            print(f"âš ï¸ é•¿åº¦åˆ†å¸ƒè¯„ä¼°å¤±è´¥: {e}")
            return {'error': str(e)}
    
    def comprehensive_evaluation(self, 
                                generated_sequences: List[str], 
                                reference_sequences: Optional[List[str]] = None,
                                peptide_type: str = 'antimicrobial') -> Dict:
        """
        ç»¼åˆè¯„ä¼° - é›†æˆæ‰€æœ‰è¯„ä¼°æŒ‡æ ‡
        """
        print(f"ğŸš€ å¼€å§‹ç»¼åˆè¯„ä¼° - è‚½ç±»å‹: {peptide_type}")
        print(f"ğŸ“Š ç”Ÿæˆåºåˆ—æ•°é‡: {len(generated_sequences)}")
        if reference_sequences:
            print(f"ğŸ“š å‚è€ƒåºåˆ—æ•°é‡: {len(reference_sequences)}")
        
        results = {
            'metadata': {
                'peptide_type': peptide_type,
                'generated_count': len(generated_sequences),
                'reference_count': len(reference_sequences) if reference_sequences else 0,
                'evaluation_timestamp': pd.Timestamp.now().isoformat()
            }
        }
        
        # 1. åŸºç¡€åºåˆ—è´¨é‡è¯„ä¼°ï¼ˆåŸæœ‰æŒ‡æ ‡ï¼‰
        print("\nğŸ”¸ åŸºç¡€åºåˆ—è´¨é‡è¯„ä¼°...")
        results['basic_quality'] = self.evaluate_sequence_quality(generated_sequences)
        
        # 2. CPL-Diffè¯„ä¼°æŒ‡æ ‡
        print("\nğŸ”¸ CPL-Diffè¯„ä¼°æŒ‡æ ‡...")
        
        # ä¼ªå›°æƒ‘åº¦
        results['pseudo_perplexity'] = self.evaluate_pseudo_perplexity(generated_sequences)
        
        # ä¿¡æ¯ç†µ
        results['information_entropy'] = self.evaluate_information_entropy(generated_sequences)
        
        # ä¸ç¨³å®šæ€§æŒ‡æ•°
        results['instability_index'] = self.evaluate_instability_index(generated_sequences)
        
        # 3. ä¸å‚è€ƒåºåˆ—çš„æ¯”è¾ƒè¯„ä¼°
        if reference_sequences:
            print("\nğŸ”¸ å‚è€ƒåºåˆ—æ¯”è¾ƒè¯„ä¼°...")
            
            # ç›¸ä¼¼æ€§å¾—åˆ†
            results['similarity_analysis'] = self.evaluate_similarity_scores(
                generated_sequences, reference_sequences
            )
            
            # é•¿åº¦åˆ†å¸ƒæ¯”è¾ƒ
            gen_lengths = [len(seq) for seq in generated_sequences if seq]
            ref_lengths = [len(seq) for seq in reference_sequences if seq]
            results['length_distribution'] = self.evaluate_length_distribution(gen_lengths, ref_lengths)
            
            # å¤šæ ·æ€§è¯„ä¼°
            results['diversity_analysis'] = self.evaluate_diversity(generated_sequences)
            
            # æ–°é¢–æ€§è¯„ä¼°
            results['novelty_analysis'] = self.evaluate_novelty(generated_sequences, reference_sequences)
        
        # 4. æ¡ä»¶ç‰¹å¼‚æ€§è¯„ä¼°ï¼ˆå¦‚æœæŒ‡å®šäº†è‚½ç±»å‹ï¼‰
        if peptide_type in self.amp_preferences:
            print(f"\nğŸ”¸ {peptide_type}ç‰¹å¼‚æ€§è¯„ä¼°...")
            sequences_by_condition = {peptide_type: generated_sequences}
            results['condition_specificity'] = self.evaluate_condition_specificity(sequences_by_condition)
        
        print("\nâœ… ç»¼åˆè¯„ä¼°å®Œæˆ!")
        return results
    
    # ä¿ç•™åŸæœ‰çš„è¯„ä¼°æ–¹æ³•ï¼ˆä»åŸevaluation_suite.pyç»§æ‰¿ï¼‰
    def evaluate_sequence_quality(self, sequences: List[str]) -> Dict:
        """è¯„ä¼°åºåˆ—è´¨é‡ï¼ˆåŸæœ‰æ–¹æ³•ï¼‰"""
        results = {
            'total_sequences': len(sequences),
            'valid_sequences': 0,
            'average_length': 0,
            'length_distribution': {},
            'amino_acid_composition': {},
            'hydrophobicity_scores': [],
            'charge_scores': [],
            'complexity_scores': []
        }
        
        valid_sequences = []
        valid_aa = set('ACDEFGHIKLMNPQRSTVWY')
        
        for seq in sequences:
            # æ£€æŸ¥åºåˆ—æœ‰æ•ˆæ€§
            if all(aa in valid_aa for aa in seq) and len(seq) > 0:
                valid_sequences.append(seq)
                results['valid_sequences'] += 1
        
        if not valid_sequences:
            return results
        
        # é•¿åº¦ç»Ÿè®¡
        lengths = [len(seq) for seq in valid_sequences]
        results['average_length'] = np.mean(lengths)
        results['length_distribution'] = dict(Counter(lengths))
        
        # æ°¨åŸºé…¸ç»„æˆ
        all_aas = ''.join(valid_sequences)
        aa_counts = Counter(all_aas)
        total_aas = len(all_aas)
        results['amino_acid_composition'] = {
            aa: count/total_aas for aa, count in aa_counts.items()
        }
        
        # ç”Ÿç‰©åŒ–å­¦å±æ€§åˆ†æ
        for seq in valid_sequences:
            # ç–æ°´æ€§å¾—åˆ†
            hydrophobic_count = sum(1 for aa in seq if aa in self.aa_properties['hydrophobic'])
            hydrophobicity = hydrophobic_count / len(seq)
            results['hydrophobicity_scores'].append(hydrophobicity)
            
            # ç”µè·å¾—åˆ†
            positive_charge = sum(1 for aa in seq if aa in self.aa_properties['charged_positive'])
            negative_charge = sum(1 for aa in seq if aa in self.aa_properties['charged_negative'])
            net_charge = positive_charge - negative_charge
            results['charge_scores'].append(net_charge)
            
            # å¤æ‚æ€§å¾—åˆ† (åŸºäºæ°¨åŸºé…¸å¤šæ ·æ€§)
            aa_diversity = len(set(seq)) / 20  # 20ç§æ°¨åŸºé…¸
            results['complexity_scores'].append(aa_diversity)
        
        return results
    
    def evaluate_condition_specificity(self, sequences_by_condition: Dict[str, List[str]]) -> Dict:
        """è¯„ä¼°æ¡ä»¶ç‰¹å¼‚æ€§ï¼ˆåŸæœ‰æ–¹æ³•ï¼‰"""
        results = {}
        
        for condition, sequences in sequences_by_condition.items():
            if condition in self.amp_preferences:
                prefs = self.amp_preferences[condition]
                
                condition_results = {
                    'sequences_count': len(sequences),
                    'preferred_aa_ratio': [],
                    'avoided_aa_ratio': [],
                    'length_compliance': 0,
                    'charge_compliance': 0
                }
                
                for seq in sequences:
                    if not seq:
                        continue
                    
                    # ä¼˜é€‰æ°¨åŸºé…¸æ¯”ä¾‹
                    preferred_count = sum(1 for aa in seq if aa in prefs['preferred'])
                    preferred_ratio = preferred_count / len(seq)
                    condition_results['preferred_aa_ratio'].append(preferred_ratio)
                    
                    # é¿å…æ°¨åŸºé…¸æ¯”ä¾‹
                    avoided_count = sum(1 for aa in seq if aa in prefs['avoided'])
                    avoided_ratio = avoided_count / len(seq)
                    condition_results['avoided_aa_ratio'].append(avoided_ratio)
                    
                    # é•¿åº¦åˆè§„æ€§
                    min_len, max_len = prefs['optimal_length_range']
                    if min_len <= len(seq) <= max_len:
                        condition_results['length_compliance'] += 1
                    
                    # ç”µè·åˆè§„æ€§
                    net_charge = self._calculate_net_charge(seq)
                    min_charge, max_charge = prefs['optimal_charge_range']
                    if min_charge <= net_charge <= max_charge:
                        condition_results['charge_compliance'] += 1
                
                # è®¡ç®—åˆè§„ç‡
                total_seqs = len(sequences) if sequences else 1
                condition_results['length_compliance'] /= total_seqs
                condition_results['charge_compliance'] /= total_seqs
                
                results[condition] = condition_results
        
        return results
    
    def evaluate_diversity(self, sequences: List[str]) -> Dict:
        """è¯„ä¼°åºåˆ—å¤šæ ·æ€§ï¼ˆåŸæœ‰æ–¹æ³•ï¼‰"""
        if len(sequences) < 2:
            return {'diversity_score': 0, 'unique_sequences': len(sequences)}
        
        # å»é‡
        unique_sequences = list(set(sequences))
        uniqueness_ratio = len(unique_sequences) / len(sequences)
        
        # è®¡ç®—ç¼–è¾‘è·ç¦»å¤šæ ·æ€§
        edit_distances = []
        for i in range(min(100, len(unique_sequences))):  # é‡‡æ ·100ä¸ªåºåˆ—é¿å…è®¡ç®—é‡è¿‡å¤§
            for j in range(i+1, min(100, len(unique_sequences))):
                distance = self._edit_distance(unique_sequences[i], unique_sequences[j])
                edit_distances.append(distance)
        
        diversity_score = np.mean(edit_distances) if edit_distances else 0
        
        return {
            'diversity_score': diversity_score,
            'unique_sequences': len(unique_sequences),
            'uniqueness_ratio': uniqueness_ratio,
            'average_edit_distance': diversity_score
        }
    
    def evaluate_novelty(self, generated_sequences: List[str], reference_sequences: List[str]) -> Dict:
        """è¯„ä¼°åºåˆ—æ–°é¢–æ€§ï¼ˆåŸæœ‰æ–¹æ³•ï¼‰"""
        reference_set = set(reference_sequences)
        
        novel_sequences = []
        similar_sequences = []
        
        for seq in generated_sequences:
            if seq in reference_set:
                similar_sequences.append(seq)
            else:
                # æ£€æŸ¥æ˜¯å¦ä¸å·²çŸ¥åºåˆ—é«˜åº¦ç›¸ä¼¼
                is_similar = False
                for ref_seq in reference_set:
                    if self._sequence_similarity(seq, ref_seq) > 0.8:
                        is_similar = True
                        break
                
                if is_similar:
                    similar_sequences.append(seq)
                else:
                    novel_sequences.append(seq)
        
        total_generated = len(generated_sequences)
        novelty_ratio = len(novel_sequences) / total_generated if total_generated > 0 else 0
        
        return {
            'total_generated': total_generated,
            'novel_sequences': len(novel_sequences),
            'similar_sequences': len(similar_sequences),
            'novelty_ratio': novelty_ratio
        }
    
    def _calculate_net_charge(self, sequence: str) -> int:
        """è®¡ç®—åºåˆ—å‡€ç”µè·"""
        positive = sum(1 for aa in sequence if aa in self.aa_properties['charged_positive'])
        negative = sum(1 for aa in sequence if aa in self.aa_properties['charged_negative'])
        return positive - negative
    
    def _edit_distance(self, s1: str, s2: str) -> int:
        """è®¡ç®—ç¼–è¾‘è·ç¦»"""
        if len(s1) < len(s2):
            return self._edit_distance(s2, s1)
        
        if len(s2) == 0:
            return len(s1)
        
        previous_row = list(range(len(s2) + 1))
        for i, c1 in enumerate(s1):
            current_row = [i + 1]
            for j, c2 in enumerate(s2):
                insertions = previous_row[j + 1] + 1
                deletions = current_row[j] + 1
                substitutions = previous_row[j] + (c1 != c2)
                current_row.append(min(insertions, deletions, substitutions))
            previous_row = current_row
        
        return previous_row[-1]
    
    def _sequence_similarity(self, s1: str, s2: str) -> float:
        """è®¡ç®—åºåˆ—ç›¸ä¼¼æ€§ (åŸºäºç¼–è¾‘è·ç¦»)"""
        max_len = max(len(s1), len(s2))
        if max_len == 0:
            return 1.0
        edit_dist = self._edit_distance(s1, s2)
        return 1 - (edit_dist / max_len)
    
    def generate_report(self, evaluation_results: Dict, output_name: str = "enhanced_evaluation_report"):
        """ç”Ÿæˆå¢å¼ºè¯„ä¼°æŠ¥å‘Š"""
        report_path = self.output_dir / f"{output_name}.json"
        
        # ä¿å­˜JSONæŠ¥å‘Š
        with open(report_path, 'w') as f:
            json.dump(evaluation_results, f, indent=2, default=str)
        
        # ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Š
        self._generate_visualizations(evaluation_results, output_name)
        
        # ç”Ÿæˆæ–‡æœ¬æ‘˜è¦
        self._generate_text_summary(evaluation_results, output_name)
        
        print(f"ğŸ“Š å¢å¼ºè¯„ä¼°æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
    
    def _generate_visualizations(self, results: Dict, output_name: str):
        """ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨"""
        try:
            fig, axes = plt.subplots(2, 3, figsize=(18, 12))
            fig.suptitle('Enhanced Peptide Generation Evaluation', fontsize=16)
            
            # 1. ä¼ªå›°æƒ‘åº¦åˆ†å¸ƒ
            if 'pseudo_perplexity' in results and 'perplexity_distribution' in results['pseudo_perplexity']:
                perplexities = results['pseudo_perplexity']['perplexity_distribution']
                axes[0, 0].hist(perplexities, bins=20, alpha=0.7, color='blue')
                axes[0, 0].set_title('Pseudo-Perplexity Distribution')
                axes[0, 0].set_xlabel('Pseudo-Perplexity')
                axes[0, 0].set_ylabel('Frequency')
            
            # 2. ä¿¡æ¯ç†µåˆ†å¸ƒ
            if 'information_entropy' in results and 'entropy_distribution' in results['information_entropy']:
                entropies = results['information_entropy']['entropy_distribution']
                axes[0, 1].hist(entropies, bins=20, alpha=0.7, color='green')
                axes[0, 1].set_title('Information Entropy Distribution')
                axes[0, 1].set_xlabel('Entropy')
                axes[0, 1].set_ylabel('Frequency')
            
            # 3. é•¿åº¦åˆ†å¸ƒæ¯”è¾ƒ
            if 'length_distribution' in results:
                gen_stats = results['length_distribution'].get('generated_stats', {})
                ref_stats = results['length_distribution'].get('reference_stats', {})
                
                if gen_stats and ref_stats:
                    categories = ['Mean', 'Std', 'Min', 'Max']
                    gen_values = [gen_stats.get('mean', 0), gen_stats.get('std', 0), 
                                 gen_stats.get('min', 0), gen_stats.get('max', 0)]
                    ref_values = [ref_stats.get('mean', 0), ref_stats.get('std', 0),
                                 ref_stats.get('min', 0), ref_stats.get('max', 0)]
                    
                    x = np.arange(len(categories))
                    width = 0.35
                    
                    axes[0, 2].bar(x - width/2, gen_values, width, label='Generated', alpha=0.7)
                    axes[0, 2].bar(x + width/2, ref_values, width, label='Reference', alpha=0.7)
                    axes[0, 2].set_title('Length Statistics Comparison')
                    axes[0, 2].set_xlabel('Statistics')
                    axes[0, 2].set_ylabel('Length')
                    axes[0, 2].set_xticks(x)
                    axes[0, 2].set_xticklabels(categories)
                    axes[0, 2].legend()
            
            # 4. æ°¨åŸºé…¸ç»„æˆ
            if 'basic_quality' in results and 'amino_acid_composition' in results['basic_quality']:
                aa_comp = results['basic_quality']['amino_acid_composition']
                if aa_comp:
                    aas = list(aa_comp.keys())
                    freqs = list(aa_comp.values())
                    axes[1, 0].bar(aas, freqs, alpha=0.7, color='orange')
                    axes[1, 0].set_title('Amino Acid Composition')
                    axes[1, 0].set_xlabel('Amino Acid')
                    axes[1, 0].set_ylabel('Frequency')
                    axes[1, 0].tick_params(axis='x', rotation=45)
            
            # 5. è¯„ä¼°æŒ‡æ ‡æ€»ç»“
            metrics_data = []
            if 'pseudo_perplexity' in results:
                pp = results['pseudo_perplexity']
                if 'mean_pseudo_perplexity' in pp and not math.isnan(pp['mean_pseudo_perplexity']):
                    metrics_data.append(('Pseudo-Perplexity', pp['mean_pseudo_perplexity']))
            
            if 'information_entropy' in results:
                ie = results['information_entropy']
                if 'mean_entropy' in ie and not math.isnan(ie['mean_entropy']):
                    metrics_data.append(('Information Entropy', ie['mean_entropy']))
            
            if 'instability_index' in results:
                ii = results['instability_index']
                if 'mean_instability' in ii and not math.isnan(ii['mean_instability']):
                    metrics_data.append(('Instability Index', ii['mean_instability']))
            
            if metrics_data:
                metrics, values = zip(*metrics_data)
                axes[1, 1].barh(metrics, values, alpha=0.7, color='purple')
                axes[1, 1].set_title('Key Evaluation Metrics')
                axes[1, 1].set_xlabel('Value')
            
            # 6. æ¡ä»¶ç‰¹å¼‚æ€§ï¼ˆå¦‚æœæœ‰ï¼‰
            if 'condition_specificity' in results:
                cs = results['condition_specificity']
                for condition, data in cs.items():
                    if 'length_compliance' in data and 'charge_compliance' in data:
                        categories = ['Length Compliance', 'Charge Compliance']
                        values = [data['length_compliance'], data['charge_compliance']]
                        axes[1, 2].bar(categories, values, alpha=0.7, color='red')
                        axes[1, 2].set_title(f'{condition.title()} Specificity')
                        axes[1, 2].set_ylabel('Compliance Ratio')
                        break
            
            plt.tight_layout()
            plt.savefig(self.output_dir / f"{output_name}_visualization.png", dpi=300, bbox_inches='tight')
            plt.close()
            
            print(f"ğŸ“ˆ å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜: {output_name}_visualization.png")
            
        except Exception as e:
            print(f"âš ï¸ å¯è§†åŒ–ç”Ÿæˆå¤±è´¥: {e}")
    
    def _generate_text_summary(self, results: Dict, output_name: str):
        """ç”Ÿæˆå¢å¼ºæ–‡æœ¬æ‘˜è¦"""
        summary_path = self.output_dir / f"{output_name}_summary.txt"
        
        with open(summary_path, 'w', encoding='utf-8') as f:
            f.write("å¢å¼ºå¤šè‚½ç”Ÿæˆæ¨¡å‹è¯„ä¼°æ‘˜è¦ (Enhanced Evaluation)\n")
            f.write("=" * 60 + "\n\n")
            
            # å…ƒæ•°æ®
            if 'metadata' in results:
                meta = results['metadata']
                f.write("è¯„ä¼°ä¿¡æ¯:\n")
                f.write(f"  è‚½ç±»å‹: {meta.get('peptide_type', 'N/A')}\n")
                f.write(f"  ç”Ÿæˆåºåˆ—æ•°: {meta.get('generated_count', 0)}\n")
                f.write(f"  å‚è€ƒåºåˆ—æ•°: {meta.get('reference_count', 0)}\n")
                f.write(f"  è¯„ä¼°æ—¶é—´: {meta.get('evaluation_timestamp', 'N/A')}\n\n")
            
            # CPL-Diffè¯„ä¼°æŒ‡æ ‡
            f.write("CPL-Diffè¯„ä¼°æŒ‡æ ‡:\n")
            f.write("-" * 30 + "\n")
            
            # ä¼ªå›°æƒ‘åº¦
            if 'pseudo_perplexity' in results:
                pp = results['pseudo_perplexity']
                if 'error' not in pp:
                    f.write(f"  ä¼ªå›°æƒ‘åº¦: {pp.get('mean_pseudo_perplexity', 'N/A'):.3f}Â±{pp.get('std_pseudo_perplexity', 0):.3f}\n")
                    f.write(f"  æœ‰æ•ˆåºåˆ—æ•°: {pp.get('valid_sequences', 0)}\n")
                else:
                    f.write(f"  ä¼ªå›°æƒ‘åº¦: è®¡ç®—å¤±è´¥ ({pp['error']})\n")
            
            # ä¿¡æ¯ç†µ
            if 'information_entropy' in results:
                ie = results['information_entropy']
                if 'error' not in ie:
                    f.write(f"  ä¿¡æ¯ç†µ: {ie.get('mean_entropy', 'N/A'):.3f}Â±{ie.get('std_entropy', 0):.3f}\n")
                    f.write(f"  ç†µèŒƒå›´: {ie.get('min_entropy', 'N/A'):.3f} - {ie.get('max_entropy', 'N/A'):.3f}\n")
                else:
                    f.write(f"  ä¿¡æ¯ç†µ: è®¡ç®—å¤±è´¥ ({ie['error']})\n")
            
            # ä¸ç¨³å®šæ€§æŒ‡æ•°
            if 'instability_index' in results:
                ii = results['instability_index']
                if 'error' not in ii:
                    f.write(f"  ä¸ç¨³å®šæ€§æŒ‡æ•°: {ii.get('mean_instability', 'N/A'):.2f}Â±{ii.get('std_instability', 0):.2f}\n")
                    f.write(f"  ç¨³å®šè‚½æ¯”ä¾‹: {ii.get('stable_peptides_ratio', 'N/A'):.3f}\n")
                else:
                    f.write(f"  ä¸ç¨³å®šæ€§æŒ‡æ•°: è®¡ç®—å¤±è´¥ ({ii['error']})\n")
            
            f.write("\n")
            
            # åŸºç¡€åºåˆ—è´¨é‡
            if 'basic_quality' in results:
                sq = results['basic_quality']
                f.write("åŸºç¡€åºåˆ—è´¨é‡:\n")
                f.write("-" * 20 + "\n")
                f.write(f"  æ€»åºåˆ—æ•°: {sq.get('total_sequences', 0)}\n")
                f.write(f"  æœ‰æ•ˆåºåˆ—æ•°: {sq.get('valid_sequences', 0)}\n")
                f.write(f"  å¹³å‡é•¿åº¦: {sq.get('average_length', 0):.1f}\n")
                
                if 'hydrophobicity_scores' in sq and sq['hydrophobicity_scores']:
                    avg_hydro = np.mean(sq['hydrophobicity_scores'])
                    f.write(f"  å¹³å‡ç–æ°´æ€§: {avg_hydro:.3f}\n")
                
                if 'charge_scores' in sq and sq['charge_scores']:
                    avg_charge = np.mean(sq['charge_scores'])
                    f.write(f"  å¹³å‡å‡€ç”µè·: {avg_charge:.1f}\n")
                f.write("\n")
            
            # ç›¸ä¼¼æ€§åˆ†æ
            if 'similarity_analysis' in results:
                sa = results['similarity_analysis']
                if 'error' not in sa:
                    f.write("ç›¸ä¼¼æ€§åˆ†æ:\n")
                    f.write("-" * 15 + "\n")
                    f.write(f"  å¹³å‡ç›¸ä¼¼æ€§å¾—åˆ†: {sa.get('mean_similarity', 'N/A'):.2f}Â±{sa.get('std_similarity', 0):.2f}\n")
                    f.write(f"  æ–°é¢–æ€§æ¯”ä¾‹: {sa.get('novelty_ratio', 'N/A'):.3f}\n")
                    f.write(f"  ç›¸ä¼¼æ€§é˜ˆå€¼: {sa.get('similarity_threshold', 'N/A')}\n\n")
            
            # é•¿åº¦åˆ†å¸ƒåˆ†æ
            if 'length_distribution' in results:
                ld = results['length_distribution']
                if 'error' not in ld:
                    f.write("é•¿åº¦åˆ†å¸ƒåˆ†æ:\n")
                    f.write("-" * 20 + "\n")
                    if 'ks_p_value' in ld:
                        f.write(f"  KSæ£€éªŒpå€¼: {ld['ks_p_value']:.6f}\n")
                        f.write(f"  åˆ†å¸ƒåŒ¹é…: {'æ˜¯' if ld.get('distribution_match', False) else 'å¦'}\n")
                    if 'wasserstein_distance' in ld:
                        f.write(f"  Wassersteinè·ç¦»: {ld['wasserstein_distance']:.3f}\n")
                    f.write("\n")
            
            # æ¡ä»¶ç‰¹å¼‚æ€§
            if 'condition_specificity' in results:
                f.write("æ¡ä»¶ç‰¹å¼‚æ€§è¯„ä¼°:\n")
                f.write("-" * 25 + "\n")
                for condition, data in results['condition_specificity'].items():
                    f.write(f"  {condition}:\n")
                    f.write(f"    åºåˆ—æ•°: {data.get('sequences_count', 0)}\n")
                    f.write(f"    é•¿åº¦åˆè§„ç‡: {data.get('length_compliance', 0):.3f}\n")
                    f.write(f"    ç”µè·åˆè§„ç‡: {data.get('charge_compliance', 0):.3f}\n")
                f.write("\n")
            
            # å¤šæ ·æ€§å’Œæ–°é¢–æ€§
            if 'diversity_analysis' in results:
                div = results['diversity_analysis']
                f.write("å¤šæ ·æ€§è¯„ä¼°:\n")
                f.write("-" * 15 + "\n")
                f.write(f"  ç‹¬ç‰¹åºåˆ—æ¯”ä¾‹: {div.get('uniqueness_ratio', 0):.3f}\n")
                f.write(f"  å¤šæ ·æ€§å¾—åˆ†: {div.get('diversity_score', 0):.3f}\n\n")


def main():
    """ä¸»å‡½æ•° - ç¤ºä¾‹ç”¨æ³•"""
    evaluator = EnhancedPeptideEvaluationSuite()
    
    # ç¤ºä¾‹æ•°æ®
    generated_sequences = [
        "KRWWKWIRWKK",
        "FRLKWFKRLLK", 
        "KLRFKKLRWFK",
        "GILDTILKILR",
        "KLAKLRWKLKL",
        "KWKLFKKIEK",
        "GLFDVIKKV",
        "RWWRRRWWRR",
        "KLKLLLLLKL"
    ]
    
    reference_sequences = [
        "MAGAININ1PEPTIDE",
        "KRWWKWIRWKK",  # å·²çŸ¥åºåˆ—
        "CECROPIN",
        "DEFENSIN",
        "MELITTIN"
    ]
    
    # è¿è¡Œç»¼åˆè¯„ä¼°
    print("ğŸš€ å¼€å§‹å¢å¼ºè¯„ä¼°æ¼”ç¤º...")
    results = evaluator.comprehensive_evaluation(
        generated_sequences=generated_sequences,
        reference_sequences=reference_sequences,
        peptide_type='antimicrobial'
    )
    
    # ç”ŸæˆæŠ¥å‘Š
    evaluator.generate_report(results, "enhanced_evaluation_demo")
    
    print("\nâœ… å¢å¼ºè¯„ä¼°æ¼”ç¤ºå®Œæˆ!")
    print("ğŸ“Š æŸ¥çœ‹ç”Ÿæˆçš„æŠ¥å‘Šæ–‡ä»¶:")
    print("   - enhanced_evaluation_demo.json")
    print("   - enhanced_evaluation_demo_summary.txt") 
    print("   - enhanced_evaluation_demo_visualization.png")


if __name__ == "__main__":
    main()