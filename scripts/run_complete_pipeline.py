#!/usr/bin/env python3
"""
å®Œæ•´çš„ç«¯åˆ°ç«¯è®­ç»ƒ-ç”Ÿæˆ-è¯„ä¼°æµæ°´çº¿
é›†æˆäº†StructDiffçš„åˆ†ç¦»å¼è®­ç»ƒã€åºåˆ—ç”Ÿæˆå’ŒCPL-Diffæ ‡å‡†è¯„ä¼°
"""

import os
import sys
import argparse
import logging
from pathlib import Path
from typing import Dict, Optional, List
import json
import time

import torch
from transformers import AutoTokenizer

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from structdiff.models.structdiff import StructDiff
from structdiff.diffusion.gaussian_diffusion import GaussianDiffusion
from structdiff.training.separated_training import SeparatedTrainingManager, SeparatedTrainingConfig
from structdiff.utils.logger import setup_logger, get_logger
from structdiff.utils.config import load_config
from scripts.cpldiff_standard_evaluation import CPLDiffStandardEvaluator

logger = get_logger(__name__)


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description="StructDiffå®Œæ•´æµæ°´çº¿ï¼šè®­ç»ƒâ†’ç”Ÿæˆâ†’è¯„ä¼°")
    
    # åŸºç¡€é…ç½®
    parser.add_argument(
        "--config", 
        type=str, 
        default="configs/separated_training.yaml",
        help="é…ç½®æ–‡ä»¶è·¯å¾„"
    )
    parser.add_argument(
        "--data-dir",
        type=str,
        default="./data/processed",
        help="æ•°æ®ç›®å½•"
    )
    parser.add_argument(
        "--output-dir",
        type=str,
        default="./outputs/complete_pipeline",
        help="è¾“å‡ºç›®å½•"
    )
    parser.add_argument(
        "--device",
        type=str,
        default="auto",
        help="è®¾å¤‡ (cuda/cpu/auto)"
    )
    
    # æµæ°´çº¿æ§åˆ¶
    parser.add_argument(
        "--skip-training",
        action="store_true",
        help="è·³è¿‡è®­ç»ƒé˜¶æ®µï¼ˆä½¿ç”¨ç°æœ‰æ£€æŸ¥ç‚¹ï¼‰"
    )
    parser.add_argument(
        "--checkpoint-path",
        type=str,
        help="ç°æœ‰æ£€æŸ¥ç‚¹è·¯å¾„ï¼ˆè·³è¿‡è®­ç»ƒæ—¶ä½¿ç”¨ï¼‰"
    )
    parser.add_argument(
        "--skip-generation",
        action="store_true", 
        help="è·³è¿‡ç”Ÿæˆé˜¶æ®µï¼ˆä»…è®­ç»ƒï¼‰"
    )
    parser.add_argument(
        "--skip-evaluation",
        action="store_true",
        help="è·³è¿‡è¯„ä¼°é˜¶æ®µ"
    )
    
    # ç”Ÿæˆé…ç½®
    parser.add_argument(
        "--num-samples",
        type=int,
        default=1000,
        help="ç”Ÿæˆæ ·æœ¬æ•°é‡"
    )
    parser.add_argument(
        "--peptide-types",
        nargs="+",
        default=["antimicrobial"],
        choices=["antimicrobial", "antifungal", "antiviral"],
        help="ç”Ÿæˆçš„è‚½æ®µç±»å‹"
    )
    
    # å®éªŒè®¾ç½®
    parser.add_argument(
        "--experiment-name",
        type=str,
        default=None,
        help="å®éªŒåç§°ï¼ˆç”¨äºç»“æœç»„ç»‡ï¼‰"
    )
    parser.add_argument(
        "--seed",
        type=int,
        default=42,
        help="éšæœºç§å­"
    )
    
    return parser.parse_args()


def setup_experiment(args) -> Dict:
    """è®¾ç½®å®éªŒç¯å¢ƒ"""
    # ç¡®å®šå®éªŒåç§°
    if args.experiment_name is None:
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        args.experiment_name = f"pipeline_{timestamp}"
    
    # åˆ›å»ºå®éªŒç›®å½•
    experiment_dir = Path(args.output_dir) / args.experiment_name
    experiment_dir.mkdir(parents=True, exist_ok=True)
    
    # è®¾ç½®æ—¥å¿—
    setup_logger(
        level=logging.INFO,
        log_file=experiment_dir / "pipeline.log"
    )
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(args.seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(args.seed)
    
    # è®¾ç½®è®¾å¤‡
    if args.device == "auto":
        device = "cuda" if torch.cuda.is_available() else "cpu"
    else:
        device = args.device
    
    if device == "cuda" and not torch.cuda.is_available():
        logger.warning("CUDAä¸å¯ç”¨ï¼Œå›é€€åˆ°CPU")
        device = "cpu"
    
    logger.info(f"ğŸ”§ å®éªŒè®¾ç½®å®Œæˆ")
    logger.info(f"  - å®éªŒåç§°: {args.experiment_name}")
    logger.info(f"  - è®¾å¤‡: {device}")
    logger.info(f"  - ç§å­: {args.seed}")
    logger.info(f"  - è¾“å‡ºç›®å½•: {experiment_dir}")
    
    return {
        "experiment_dir": experiment_dir,
        "device": device,
        "experiment_name": args.experiment_name
    }


def run_training_stage(args, config: Dict, experiment_info: Dict) -> Optional[Dict]:
    """æ‰§è¡Œè®­ç»ƒé˜¶æ®µ"""
    if args.skip_training:
        logger.info("â­ï¸  è·³è¿‡è®­ç»ƒé˜¶æ®µ")
        return {"skipped": True, "checkpoint_path": args.checkpoint_path}
    
    logger.info("ğŸš€ å¼€å§‹è®­ç»ƒé˜¶æ®µ")
    
    try:
        # åˆ›å»ºæ¨¡å‹å’Œç»„ä»¶
        device = experiment_info["device"]
        
        # åˆ›å»ºåˆ†è¯å™¨
        tokenizer_name = config.model.sequence_encoder.pretrained_model
        tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)
        
        # åˆ›å»ºæ¨¡å‹å’Œæ‰©æ•£è¿‡ç¨‹
        model = StructDiff(config.model).to(device)
        diffusion = GaussianDiffusion(config.diffusion)
        
        # åˆ›å»ºè®­ç»ƒé…ç½®
        training_config = SeparatedTrainingConfig(
            data_dir=args.data_dir,
            output_dir=str(experiment_info["experiment_dir"] / "training"),
            checkpoint_dir=str(experiment_info["experiment_dir"] / "checkpoints"),
            enable_evaluation=True,
            evaluate_every=5,
            auto_generate_after_training=True
        )
        
        # åˆ›å»ºè®­ç»ƒç®¡ç†å™¨
        trainer = SeparatedTrainingManager(
            config=training_config,
            model=model,
            diffusion=diffusion,
            device=device,
            tokenizer=tokenizer
        )
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        from structdiff.data.dataset import PeptideStructureDataset
        from torch.utils.data import DataLoader
        
        train_dataset = PeptideStructureDataset(
            data_path=str(Path(args.data_dir) / "train.csv"),
            config=config,
            is_training=True
        )
        
        train_loader = DataLoader(
            train_dataset,
            batch_size=32,
            shuffle=True,
            num_workers=4,
            pin_memory=True
        )
        
        val_loader = None
        val_path = Path(args.data_dir) / "val.csv"
        if val_path.exists():
            val_dataset = PeptideStructureDataset(
                data_path=str(val_path),
                config=config,
                is_training=False
            )
            val_loader = DataLoader(
                val_dataset,
                batch_size=32,
                shuffle=False,
                num_workers=4,
                pin_memory=True
            )
        
        # æ‰§è¡Œè®­ç»ƒ
        training_stats = trainer.run_complete_training(train_loader, val_loader)
        
        # è·å–æœ€ä½³æ£€æŸ¥ç‚¹è·¯å¾„
        checkpoint_dir = Path(training_config.checkpoint_dir)
        best_checkpoint = None
        if checkpoint_dir.exists():
            checkpoints = list(checkpoint_dir.glob("*.pth"))
            if checkpoints:
                best_checkpoint = str(max(checkpoints, key=os.path.getctime))
        
        logger.info("âœ… è®­ç»ƒé˜¶æ®µå®Œæˆ")
        return {
            "training_stats": training_stats,
            "checkpoint_path": best_checkpoint,
            "training_config": training_config
        }
        
    except Exception as e:
        logger.error(f"è®­ç»ƒé˜¶æ®µå¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return None


def run_generation_stage(args, config: Dict, experiment_info: Dict, training_result: Dict) -> Optional[Dict]:
    """æ‰§è¡Œç”Ÿæˆé˜¶æ®µ"""
    if args.skip_generation:
        logger.info("â­ï¸  è·³è¿‡ç”Ÿæˆé˜¶æ®µ")
        return {"skipped": True}
    
    logger.info("ğŸ¯ å¼€å§‹ç”Ÿæˆé˜¶æ®µ")
    
    try:
        checkpoint_path = training_result.get("checkpoint_path")
        if not checkpoint_path or not Path(checkpoint_path).exists():
            logger.error("æ— æ³•æ‰¾åˆ°æœ‰æ•ˆçš„æ£€æŸ¥ç‚¹æ–‡ä»¶")
            return None
        
        device = experiment_info["device"]
        
        # åŠ è½½æ¨¡å‹
        checkpoint = torch.load(checkpoint_path, map_location=device)
        model = StructDiff(config.model).to(device)
        model.load_state_dict(checkpoint['model_state_dict'])
        model.eval()
        
        # åˆ›å»ºæ‰©æ•£è¿‡ç¨‹
        diffusion = GaussianDiffusion(config.diffusion)
        
        # åˆ›å»ºåˆ†è¯å™¨
        tokenizer_name = config.model.sequence_encoder.pretrained_model
        tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)
        
        # ç”Ÿæˆä¸åŒç±»å‹çš„è‚½æ®µ
        all_generated = {}
        generation_dir = experiment_info["experiment_dir"] / "generation"
        generation_dir.mkdir(exist_ok=True)
        
        for peptide_type in args.peptide_types:
            logger.info(f"ç”Ÿæˆ {peptide_type} è‚½æ®µ...")
            
            sequences = []
            with torch.no_grad():
                for i in range(0, args.num_samples, 10):
                    batch_size = min(10, args.num_samples - i)
                    
                    for _ in range(batch_size):
                        try:
                            length = torch.randint(10, 30, (1,)).item()
                            
                            # ç”Ÿæˆå™ªå£°åµŒå…¥
                            seq_embeddings = torch.randn(
                                1, length, 
                                getattr(model.sequence_encoder.config, 'hidden_size', 768),
                                device=device
                            )
                            attention_mask = torch.ones(1, length, device=device)
                            
                            # ç®€å•å»å™ªè¿‡ç¨‹
                            for t in reversed(range(0, 1000, 50)):
                                timesteps = torch.tensor([t], device=device)
                                if hasattr(model, 'denoiser'):
                                    noise_pred = model.denoiser(
                                        seq_embeddings, timesteps, attention_mask
                                    )
                                    seq_embeddings = seq_embeddings - 0.01 * noise_pred
                            
                            # è§£ç åºåˆ—
                            if hasattr(model, 'sequence_decoder') and model.sequence_decoder is not None:
                                logits = model.sequence_decoder(seq_embeddings, attention_mask)
                                token_ids = torch.argmax(logits, dim=-1).squeeze(0)
                                sequence = tokenizer.decode(token_ids, skip_special_tokens=True)
                                
                                # æ¸…ç†åºåˆ—
                                amino_acids = set('ACDEFGHIKLMNPQRSTVWY')
                                clean_sequence = ''.join([c for c in sequence.upper() if c in amino_acids])
                                
                                if clean_sequence and len(clean_sequence) >= 5:
                                    sequences.append(clean_sequence)
                            else:
                                # å›é€€æ–¹æ¡ˆ
                                import random
                                amino_acids = 'ACDEFGHIKLMNPQRSTVWY'
                                sequence = ''.join(random.choices(amino_acids, k=length))
                                sequences.append(sequence)
                                
                        except Exception as e:
                            logger.debug(f"ç”Ÿæˆåºåˆ—å¤±è´¥: {e}")
                            continue
            
            # ä¿å­˜ç”Ÿæˆçš„åºåˆ—
            output_file = generation_dir / f"{peptide_type}_sequences.fasta"
            with open(output_file, 'w') as f:
                for i, seq in enumerate(sequences):
                    f.write(f">{peptide_type}_{i}\n{seq}\n")
            
            all_generated[peptide_type] = {
                "sequences": sequences,
                "count": len(sequences),
                "file": str(output_file)
            }
            
            logger.info(f"âœ“ ç”Ÿæˆ {len(sequences)} ä¸ª {peptide_type} åºåˆ—")
        
        logger.info("âœ… ç”Ÿæˆé˜¶æ®µå®Œæˆ")
        return all_generated
        
    except Exception as e:
        logger.error(f"ç”Ÿæˆé˜¶æ®µå¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return None


def run_evaluation_stage(args, experiment_info: Dict, generation_result: Dict) -> Optional[Dict]:
    """æ‰§è¡Œè¯„ä¼°é˜¶æ®µ"""
    if args.skip_evaluation:
        logger.info("â­ï¸  è·³è¿‡è¯„ä¼°é˜¶æ®µ")
        return {"skipped": True}
    
    logger.info("ğŸ”¬ å¼€å§‹è¯„ä¼°é˜¶æ®µ")
    
    try:
        evaluation_dir = experiment_info["experiment_dir"] / "evaluation"
        evaluator = CPLDiffStandardEvaluator(output_dir=str(evaluation_dir))
        
        all_evaluations = {}
        
        for peptide_type, gen_data in generation_result.items():
            if gen_data.get("skipped"):
                continue
                
            sequences = gen_data["sequences"]
            if not sequences:
                logger.warning(f"æ²¡æœ‰ {peptide_type} åºåˆ—å¯ä¾›è¯„ä¼°")
                continue
            
            logger.info(f"è¯„ä¼° {peptide_type} åºåˆ— ({len(sequences)} ä¸ª)...")
            
            # è¿è¡ŒCPL-Diffæ ‡å‡†è¯„ä¼°
            eval_results = evaluator.comprehensive_cpldiff_evaluation(
                generated_sequences=sequences,
                reference_sequences=[],
                peptide_type=peptide_type
            )
            
            # ç”ŸæˆæŠ¥å‘Š
            report_name = f"{experiment_info['experiment_name']}_{peptide_type}"
            evaluator.generate_cpldiff_report(eval_results, report_name)
            
            all_evaluations[peptide_type] = eval_results
            
            logger.info(f"âœ“ {peptide_type} è¯„ä¼°å®Œæˆ")
        
        logger.info("âœ… è¯„ä¼°é˜¶æ®µå®Œæˆ")
        return all_evaluations
        
    except Exception as e:
        logger.error(f"è¯„ä¼°é˜¶æ®µå¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return None


def generate_final_report(args, experiment_info: Dict, results: Dict):
    """ç”Ÿæˆæœ€ç»ˆçš„å®éªŒæŠ¥å‘Š"""
    logger.info("ğŸ“Š ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š...")
    
    report_data = {
        "experiment_info": {
            "name": experiment_info["experiment_name"],
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "config": vars(args),
            "device": experiment_info["device"]
        },
        "pipeline_results": results
    }
    
    # ä¿å­˜JSONæŠ¥å‘Š
    json_report = experiment_info["experiment_dir"] / "final_report.json"
    with open(json_report, 'w', encoding='utf-8') as f:
        json.dump(report_data, f, indent=2, ensure_ascii=False)
    
    # ç”Ÿæˆæ–‡æœ¬æ‘˜è¦æŠ¥å‘Š
    text_report = experiment_info["experiment_dir"] / "final_report.txt"
    with open(text_report, 'w', encoding='utf-8') as f:
        f.write(f"StructDiffå®Œæ•´æµæ°´çº¿å®éªŒæŠ¥å‘Š\n")
        f.write("=" * 50 + "\n\n")
        
        f.write(f"å®éªŒåç§°: {experiment_info['experiment_name']}\n")
        f.write(f"æ‰§è¡Œæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"è®¾å¤‡: {experiment_info['device']}\n\n")
        
        # è®­ç»ƒç»“æœæ‘˜è¦
        if "training" in results and not results["training"].get("skipped"):
            f.write("è®­ç»ƒé˜¶æ®µç»“æœ:\n")
            f.write("-" * 20 + "\n")
            training_stats = results["training"].get("training_stats", {})
            if "stage1" in training_stats:
                f.write(f"  é˜¶æ®µ1 - æœ€ç»ˆæŸå¤±: {training_stats['stage1'].get('losses', [-1])[-1]:.4f}\n")
            if "stage2" in training_stats:
                f.write(f"  é˜¶æ®µ2 - æœ€ç»ˆæŸå¤±: {training_stats['stage2'].get('losses', [-1])[-1]:.4f}\n")
            f.write(f"  æ£€æŸ¥ç‚¹: {results['training'].get('checkpoint_path', 'N/A')}\n\n")
        
        # ç”Ÿæˆç»“æœæ‘˜è¦
        if "generation" in results and not results["generation"].get("skipped"):
            f.write("ç”Ÿæˆé˜¶æ®µç»“æœ:\n")
            f.write("-" * 20 + "\n")
            for peptide_type, gen_data in results["generation"].items():
                if not gen_data.get("skipped"):
                    f.write(f"  {peptide_type}: {gen_data['count']} ä¸ªåºåˆ—\n")
            f.write("\n")
        
        # è¯„ä¼°ç»“æœæ‘˜è¦
        if "evaluation" in results and not results["evaluation"].get("skipped"):
            f.write("è¯„ä¼°é˜¶æ®µç»“æœ:\n")
            f.write("-" * 20 + "\n")
            for peptide_type, eval_data in results["evaluation"].items():
                if not eval_data.get("skipped"):
                    core_metrics = eval_data.get('cpldiff_core_metrics', {})
                    f.write(f"  {peptide_type}:\n")
                    
                    # æ ¸å¿ƒæŒ‡æ ‡
                    if 'pseudo_perplexity' in core_metrics:
                        pp = core_metrics['pseudo_perplexity']
                        if 'error' not in pp:
                            f.write(f"    Perplexity: {pp.get('mean_pseudo_perplexity', 'N/A'):.3f}\n")
                    
                    if 'plddt' in core_metrics:
                        plddt = core_metrics['plddt']
                        if 'error' not in plddt:
                            f.write(f"    pLDDT: {plddt.get('mean_plddt', 'N/A'):.2f}\n")
                    
                    if 'instability' in core_metrics:
                        inst = core_metrics['instability']
                        if 'error' not in inst:
                            f.write(f"    Instability: {inst.get('mean_instability', 'N/A'):.2f}\n")
            f.write("\n")
        
        f.write("è¯¦ç»†ç»“æœè¯·æŸ¥çœ‹ç›¸åº”ç›®å½•ä¸­çš„å…·ä½“æ–‡ä»¶ã€‚\n")
    
    logger.info(f"ğŸ“„ æœ€ç»ˆæŠ¥å‘Šå·²ç”Ÿæˆ:")
    logger.info(f"  - JSON: {json_report}")
    logger.info(f"  - æ–‡æœ¬: {text_report}")


def main():
    """ä¸»å‡½æ•°"""
    args = parse_args()
    
    # è®¾ç½®å®éªŒç¯å¢ƒ
    experiment_info = setup_experiment(args)
    
    logger.info("ğŸš€ StructDiffå®Œæ•´æµæ°´çº¿å¼€å§‹")
    logger.info(f"æµæ°´çº¿é˜¶æ®µ: è®­ç»ƒ{'(è·³è¿‡)' if args.skip_training else ''} â†’ "
               f"ç”Ÿæˆ{'(è·³è¿‡)' if args.skip_generation else ''} â†’ "
               f"è¯„ä¼°{'(è·³è¿‡)' if args.skip_evaluation else ''}")
    
    # åŠ è½½é…ç½®
    if Path(args.config).exists():
        config = load_config(args.config)
        logger.info(f"âœ“ é…ç½®æ–‡ä»¶: {args.config}")
    else:
        logger.error(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {args.config}")
        return
    
    pipeline_results = {}
    
    try:
        # é˜¶æ®µ1: è®­ç»ƒ
        training_result = run_training_stage(args, config, experiment_info)
        pipeline_results["training"] = training_result
        
        if training_result is None and not args.skip_training:
            logger.error("è®­ç»ƒé˜¶æ®µå¤±è´¥ï¼Œç»ˆæ­¢æµæ°´çº¿")
            return
        
        # é˜¶æ®µ2: ç”Ÿæˆ
        generation_result = run_generation_stage(args, config, experiment_info, training_result)
        pipeline_results["generation"] = generation_result
        
        if generation_result is None and not args.skip_generation:
            logger.error("ç”Ÿæˆé˜¶æ®µå¤±è´¥ï¼Œä½†ç»§ç»­æ‰§è¡Œè¯„ä¼°é˜¶æ®µ")
            generation_result = {"skipped": True}
        
        # é˜¶æ®µ3: è¯„ä¼°
        evaluation_result = run_evaluation_stage(args, experiment_info, generation_result)
        pipeline_results["evaluation"] = evaluation_result
        
        # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        generate_final_report(args, experiment_info, pipeline_results)
        
        logger.info("ğŸ‰ StructDiffå®Œæ•´æµæ°´çº¿æ‰§è¡Œå®Œæˆï¼")
        logger.info(f"ğŸ”— å®éªŒç›®å½•: {experiment_info['experiment_dir']}")
        
    except Exception as e:
        logger.error(f"æµæ°´çº¿æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())


if __name__ == "__main__":
    main()