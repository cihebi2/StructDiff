#!/usr/bin/env python3
"""
æµ‹è¯•AlphaFold3æ”¹è¿›ç»„ä»¶
"""

import torch
import numpy as np
import sys
from pathlib import Path

# Add project root to path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

def test_af3_noise_schedule():
    """æµ‹è¯•AlphaFold3å™ªå£°è°ƒåº¦"""
    print("æµ‹è¯•AF3å™ªå£°è°ƒåº¦...")
    
    from structdiff.diffusion.noise_schedule import get_noise_schedule
    
    # æµ‹è¯•æ‰€æœ‰å™ªå£°è°ƒåº¦ç±»å‹
    schedules = ["linear", "cosine", "sqrt", "alphafold3"]
    num_timesteps = 100
    
    for schedule in schedules:
        try:
            betas = get_noise_schedule(schedule, num_timesteps)
            print(f"âœ… {schedule}: shape={betas.shape}, range=[{betas.min():.6f}, {betas.max():.6f}]")
            
            # æ£€æŸ¥æ˜¯å¦å•è°ƒé€’å¢
            if schedule != "alphafold3":  # AF3è°ƒåº¦å¯èƒ½ä¸å®Œå…¨å•è°ƒ
                is_monotonic = np.all(np.diff(betas) >= 0)
                print(f"   å•è°ƒé€’å¢: {is_monotonic}")
                
        except Exception as e:
            print(f"âŒ {schedule}: é”™è¯¯ - {e}")
    
    print()

def test_af3_embeddings():
    """æµ‹è¯•AlphaFold3åµŒå…¥å±‚"""
    print("æµ‹è¯•AF3åµŒå…¥å±‚...")
    
    from structdiff.models.layers.alphafold3_embeddings import (
        AF3FourierEmbedding, 
        AF3TimestepEmbedding,
        AF3AdaptiveLayerNorm
    )
    
    batch_size = 4
    seq_len = 20
    hidden_dim = 256
    
    # æµ‹è¯•FourieråµŒå…¥
    try:
        fourier_emb = AF3FourierEmbedding(embedding_dim=hidden_dim)
        timesteps = torch.randint(0, 1000, (batch_size,))
        fourier_out = fourier_emb(timesteps)
        print(f"âœ… AF3FourierEmbedding: {fourier_out.shape}")
    except Exception as e:
        print(f"âŒ AF3FourierEmbedding: {e}")
    
    # æµ‹è¯•æ—¶é—´åµŒå…¥
    try:
        time_emb = AF3TimestepEmbedding(hidden_dim)
        timesteps = torch.randint(0, 1000, (batch_size,))
        time_out = time_emb(timesteps)
        print(f"âœ… AF3TimestepEmbedding: {time_out.shape}")
    except Exception as e:
        print(f"âŒ AF3TimestepEmbedding: {e}")
    
    # æµ‹è¯•è‡ªé€‚åº”LayerNorm
    try:
        adaptive_norm = AF3AdaptiveLayerNorm(hidden_dim, condition_dim=64)
        x = torch.randn(batch_size, seq_len, hidden_dim)
        condition = torch.randn(batch_size, 64)
        norm_out = adaptive_norm(x, condition)
        print(f"âœ… AF3AdaptiveLayerNorm: {norm_out.shape}")
    except Exception as e:
        print(f"âŒ AF3AdaptiveLayerNorm: {e}")
    
    print()

def test_glu_feedforward():
    """æµ‹è¯•GLUå‰é¦ˆç½‘ç»œ"""
    print("æµ‹è¯•GLUå‰é¦ˆç½‘ç»œ...")
    
    from structdiff.models.layers.mlp import FeedForward
    
    batch_size = 4
    seq_len = 20
    hidden_dim = 256
    
    # æµ‹è¯•æ ‡å‡†FFN
    try:
        standard_ffn = FeedForward(
            hidden_dim=hidden_dim,
            use_gate=False
        )
        x = torch.randn(batch_size, seq_len, hidden_dim)
        standard_out = standard_ffn(x)
        print(f"âœ… æ ‡å‡†FFN: {standard_out.shape}")
    except Exception as e:
        print(f"âŒ æ ‡å‡†FFN: {e}")
    
    # æµ‹è¯•GLU FFN
    try:
        glu_ffn = FeedForward(
            hidden_dim=hidden_dim,
            use_gate=True,
            activation="silu"
        )
        x = torch.randn(batch_size, seq_len, hidden_dim)
        glu_out = glu_ffn(x)
        print(f"âœ… GLU FFN: {glu_out.shape}")
    except Exception as e:
        print(f"âŒ GLU FFN: {e}")
    
    print()

def test_denoiser_integration():
    """æµ‹è¯•å»å™ªå™¨é›†æˆ"""
    print("æµ‹è¯•å»å™ªå™¨é›†æˆ...")
    
    try:
        from structdiff.models.denoise import StructureAwareDenoiser
        
        # é…ç½®
        denoiser_config = type('obj', (object,), {
            'hidden_dim': 256,
            'num_heads': 8,
            'num_layers': 6,
            'dropout': 0.1,
            'use_cross_attention': True
        })()
        
        # åˆ›å»ºå»å™ªå™¨
        denoiser = StructureAwareDenoiser(
            seq_hidden_dim=768,  # ESM-2 hidden dim
            struct_hidden_dim=320,  # ç»“æ„ç‰¹å¾ç»´åº¦
            denoiser_config=denoiser_config
        )
        
        # æµ‹è¯•è¾“å…¥
        batch_size = 2
        seq_len = 20
        noisy_embeddings = torch.randn(batch_size, seq_len, 768)
        timesteps = torch.randint(0, 1000, (batch_size,))
        attention_mask = torch.ones(batch_size, seq_len, dtype=torch.bool)
        structure_features = torch.randn(batch_size, seq_len, 320)
        
        # å‰å‘ä¼ æ’­
        denoised, cross_attn = denoiser(
            noisy_embeddings=noisy_embeddings,
            timesteps=timesteps,
            attention_mask=attention_mask,
            structure_features=structure_features
        )
        
        print(f"âœ… StructureAwareDenoiser: è¾“å…¥{noisy_embeddings.shape} -> è¾“å‡º{denoised.shape}")
        print(f"   å‚æ•°æ•°é‡: {sum(p.numel() for p in denoiser.parameters()):,}")
        
    except Exception as e:
        print(f"âŒ StructureAwareDenoiser: {e}")
        import traceback
        traceback.print_exc()
    
    print()

def test_performance_comparison():
    """æ€§èƒ½å¯¹æ¯”æµ‹è¯•"""
    print("æ€§èƒ½å¯¹æ¯”æµ‹è¯•...")
    
    from structdiff.models.layers.mlp import FeedForward
    import time
    
    batch_size = 16
    seq_len = 50
    hidden_dim = 512
    num_runs = 100
    
    x = torch.randn(batch_size, seq_len, hidden_dim)
    
    # æ ‡å‡†FFN
    standard_ffn = FeedForward(hidden_dim=hidden_dim, use_gate=False)
    
    # GLU FFN
    glu_ffn = FeedForward(hidden_dim=hidden_dim, use_gate=True, activation="silu")
    
    # é¢„çƒ­
    for _ in range(10):
        _ = standard_ffn(x)
        _ = glu_ffn(x)
    
    # æµ‹è¯•æ ‡å‡†FFN
    torch.cuda.synchronize() if torch.cuda.is_available() else None
    start_time = time.time()
    for _ in range(num_runs):
        _ = standard_ffn(x)
    torch.cuda.synchronize() if torch.cuda.is_available() else None
    standard_time = time.time() - start_time
    
    # æµ‹è¯•GLU FFN
    torch.cuda.synchronize() if torch.cuda.is_available() else None
    start_time = time.time()
    for _ in range(num_runs):
        _ = glu_ffn(x)
    torch.cuda.synchronize() if torch.cuda.is_available() else None
    glu_time = time.time() - start_time
    
    print(f"æ ‡å‡†FFNæ—¶é—´: {standard_time:.4f}s ({standard_time/num_runs*1000:.2f}ms/run)")
    print(f"GLU FFNæ—¶é—´: {glu_time:.4f}s ({glu_time/num_runs*1000:.2f}ms/run)")
    print(f"é€Ÿåº¦æ¯”: {standard_time/glu_time:.2f}x")
    
    # å‚æ•°æ•°é‡å¯¹æ¯”
    standard_params = sum(p.numel() for p in standard_ffn.parameters())
    glu_params = sum(p.numel() for p in glu_ffn.parameters())
    
    print(f"æ ‡å‡†FFNå‚æ•°: {standard_params:,}")
    print(f"GLU FFNå‚æ•°: {glu_params:,}")
    print(f"å‚æ•°æ¯”: {glu_params/standard_params:.2f}x")
    
    print()

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª æµ‹è¯•AlphaFold3æ”¹è¿›ç»„ä»¶\n")
    print("=" * 50)
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ä½¿ç”¨è®¾å¤‡: {device}\n")
    
    # è¿è¡Œæµ‹è¯•
    test_af3_noise_schedule()
    test_af3_embeddings()
    test_glu_feedforward()
    test_denoiser_integration()
    test_performance_comparison()
    
    print("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆ!")

if __name__ == "__main__":
    main()