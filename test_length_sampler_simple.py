#!/usr/bin/env python3
"""
ç®€åŒ–çš„é•¿åº¦é‡‡æ ·å™¨æµ‹è¯•è„šæœ¬
"""

import torch
import sys
from pathlib import Path

# Add project root to path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from structdiff.sampling.length_sampler import (
    LengthSamplerConfig, AdaptiveLengthSampler
)

def test_length_sampler_device():
    """æµ‹è¯•é•¿åº¦é‡‡æ ·å™¨çš„è®¾å¤‡ä¸€è‡´æ€§"""
    print("ðŸ§ª æµ‹è¯•é•¿åº¦é‡‡æ ·å™¨è®¾å¤‡ä¸€è‡´æ€§...")
    
    # è®¾å¤‡
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºé…ç½®
    config = LengthSamplerConfig(
        min_length=5,
        max_length=50,
        distribution_type="normal",
        normal_mean=25.0,
        normal_std=8.0
    )
    
    # åˆ›å»ºé‡‡æ ·å™¨
    sampler = AdaptiveLengthSampler(config)
    
    print("âœ“ æµ‹è¯•æ¦‚çŽ‡è®¡ç®—...")
    # æµ‹è¯•æ¦‚çŽ‡è®¡ç®—
    probs = sampler.get_length_probabilities(device=device)
    print(f"  æ¦‚çŽ‡å¼ é‡å½¢çŠ¶: {probs.shape}")
    print(f"  æ¦‚çŽ‡å¼ é‡è®¾å¤‡: {probs.device}")
    print(f"  æ¦‚çŽ‡æ€»å’Œ: {torch.sum(probs, dim=-1)}")
    
    # éªŒè¯æ¦‚çŽ‡å’Œ
    prob_sums = torch.sum(probs, dim=-1)
    expected_ones = torch.ones(probs.shape[0], device=device)
    
    if torch.allclose(prob_sums, expected_ones):
        print("âœ… æ¦‚çŽ‡è®¡ç®—è®¾å¤‡ä¸€è‡´æ€§æµ‹è¯•é€šè¿‡ï¼")
    else:
        print("âŒ æ¦‚çŽ‡è®¡ç®—è®¾å¤‡ä¸€è‡´æ€§æµ‹è¯•å¤±è´¥ï¼")
        return False
    
    print("âœ“ æµ‹è¯•é•¿åº¦é‡‡æ ·...")
    # æµ‹è¯•é•¿åº¦é‡‡æ ·
    lengths = sampler.sample_lengths(
        batch_size=10,
        temperature=1.0,
        device=device
    )
    print(f"  é‡‡æ ·é•¿åº¦å½¢çŠ¶: {lengths.shape}")
    print(f"  é‡‡æ ·é•¿åº¦è®¾å¤‡: {lengths.device}")
    print(f"  é‡‡æ ·é•¿åº¦èŒƒå›´: {lengths.min()} - {lengths.max()}")
    
    if lengths.device.type == device.split(':')[0]:
        print("âœ… é•¿åº¦é‡‡æ ·è®¾å¤‡ä¸€è‡´æ€§æµ‹è¯•é€šè¿‡ï¼")
        return True
    else:
        print("âŒ é•¿åº¦é‡‡æ ·è®¾å¤‡ä¸€è‡´æ€§æµ‹è¯•å¤±è´¥ï¼")
        return False

def test_length_sampler_functionality():
    """æµ‹è¯•é•¿åº¦é‡‡æ ·å™¨åŠŸèƒ½"""
    print("\nðŸ§ª æµ‹è¯•é•¿åº¦é‡‡æ ·å™¨åŠŸèƒ½...")
    
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    config = LengthSamplerConfig(
        min_length=10,
        max_length=30,
        distribution_type="normal",
        normal_mean=20.0,
        normal_std=5.0
    )
    
    sampler = AdaptiveLengthSampler(config)
    
    # å¤šæ¬¡é‡‡æ ·æµ‹è¯•
    batch_size = 100
    lengths = sampler.sample_lengths(
        batch_size=batch_size,
        temperature=1.0,
        device=device
    )
    
    # ç»Ÿè®¡
    mean_length = lengths.float().mean()
    std_length = lengths.float().std()
    
    print(f"âœ“ é‡‡æ ·ç»Ÿè®¡:")
    print(f"  å¹³å‡é•¿åº¦: {mean_length:.2f} (æœŸæœ›: {config.normal_mean})")
    print(f"  æ ‡å‡†å·®: {std_length:.2f} (æœŸæœ›: {config.normal_std})")
    print(f"  æœ€å°é•¿åº¦: {lengths.min()} (é™åˆ¶: {config.min_length})")
    print(f"  æœ€å¤§é•¿åº¦: {lengths.max()} (é™åˆ¶: {config.max_length})")
    
    # éªŒè¯èŒƒå›´
    if lengths.min() >= config.min_length and lengths.max() <= config.max_length:
        print("âœ… é•¿åº¦èŒƒå›´é™åˆ¶æ­£ç¡®ï¼")
    else:
        print("âŒ é•¿åº¦èŒƒå›´é™åˆ¶å¤±è´¥ï¼")
        return False
    
    # éªŒè¯å‡å€¼å¤§è‡´æ­£ç¡®
    if abs(mean_length - config.normal_mean) < 3.0:
        print("âœ… é•¿åº¦åˆ†å¸ƒç»Ÿè®¡åˆç†ï¼")
        return True
    else:
        print("âŒ é•¿åº¦åˆ†å¸ƒç»Ÿè®¡å¼‚å¸¸ï¼")
        return False

if __name__ == "__main__":
    print("=== é•¿åº¦é‡‡æ ·å™¨ç®€åŒ–æµ‹è¯• ===")
    
    try:
        # è®¾å¤‡ä¸€è‡´æ€§æµ‹è¯•
        success1 = test_length_sampler_device()
        
        # åŠŸèƒ½æµ‹è¯•
        success2 = test_length_sampler_functionality()
        
        if success1 and success2:
            print("\nðŸŽ‰ æ‰€æœ‰é•¿åº¦é‡‡æ ·å™¨æµ‹è¯•é€šè¿‡ï¼")
        else:
            print("\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥")
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()