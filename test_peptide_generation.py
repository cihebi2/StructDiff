#!/usr/bin/env python3
"""
ä½¿ç”¨è®­ç»ƒå¥½çš„StructDiffæ¨¡å‹ç”Ÿæˆè‚½æ®µæ ·æœ¬
"""

import os
import sys
import torch
import numpy as np
from pathlib import Path
from omegaconf import OmegaConf
import json
from collections import Counter
import pandas as pd
from Bio import SeqIO
from Bio.SeqRecord import SeqRecord
from Bio.Seq import Seq

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from structdiff.models.structdiff import StructDiff
from structdiff.diffusion.gaussian_diffusion import GaussianDiffusion
from structdiff.utils.logger import setup_logger, get_logger

logger = get_logger(__name__)


class PeptideGenerator:
    """ä½¿ç”¨è®­ç»ƒå¥½çš„StructDiffæ¨¡å‹ç”Ÿæˆè‚½æ®µ"""
    
    def __init__(self, model_path: str, device: str = 'cuda'):
        self.device = torch.device(device)
        self.model_path = model_path
        
        # åˆ›å»ºé…ç½®
        self.config = self._create_config()
        
        # åŠ è½½æ¨¡å‹
        self.model = self._load_model()
        
        # åˆ›å»ºæ‰©æ•£è¿‡ç¨‹
        self.diffusion = GaussianDiffusion(
            num_timesteps=self.config.diffusion.num_timesteps,
            noise_schedule=self.config.diffusion.noise_schedule,
            beta_start=0.0001,
            beta_end=0.02
        )
        
        # è‚½æ®µç±»å‹æ˜ å°„
        self.peptide_type_map = {
            'antimicrobial': 0,
            'antifungal': 1,
            'antiviral': 2
        }
        
        logger.info("âœ… PeptideGeneratoråˆå§‹åŒ–å®Œæˆ")
    
    def _create_config(self):
        """åˆ›å»ºæ¨¡å‹é…ç½®"""
        config = OmegaConf.create({
            'sequence_encoder': {
                'pretrained_model': 'facebook/esm2_t6_8M_UR50D',
                'freeze_encoder': False,
                'use_lora': True,
                'lora_rank': 16,
                'lora_alpha': 32,
                'lora_dropout': 0.1
            },
            'structure_encoder': {
                'hidden_dim': 256,
                'num_layers': 3,
                'use_esmfold': False,
                'use_coordinates': False,
                'use_distances': False,
                'use_angles': False,
                'use_secondary_structure': True
            },
            'denoiser': {
                'hidden_dim': 320,
                'num_layers': 6,
                'num_heads': 8,
                'dropout': 0.1,
                'use_cross_attention': True,
                'use_cfg': True,
                'cfg_dropout': 0.1
            },
            'diffusion': {
                'num_timesteps': 1000,
                'noise_schedule': 'cosine',
                'model_mean_type': 'epsilon',
                'model_var_type': 'fixed_small',
                'loss_type': 'mse'
            },
            'data': {
                'max_length': 512
            }
        })
        return config
    
    def _load_model(self):
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
        logger.info(f"ğŸ”„ ä» {self.model_path} åŠ è½½æ¨¡å‹...")
        
        # åˆ›å»ºæ¨¡å‹
        model = StructDiff(self.config)
        
        # åŠ è½½æ£€æŸ¥ç‚¹
        if os.path.exists(self.model_path):
            checkpoint = torch.load(self.model_path, map_location=self.device, weights_only=False)
            
            # å¤„ç†ä¸åŒçš„æ£€æŸ¥ç‚¹æ ¼å¼
            if 'model_state_dict' in checkpoint:
                state_dict = checkpoint['model_state_dict']
            elif 'state_dict' in checkpoint:
                state_dict = checkpoint['state_dict']
            else:
                state_dict = checkpoint
            
            # åŠ è½½çŠ¶æ€å­—å…¸
            model.load_state_dict(state_dict, strict=False)
            logger.info("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        else:
            logger.warning(f"âš ï¸ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.model_path}")
            logger.warning("å°†ä½¿ç”¨éšæœºåˆå§‹åŒ–çš„æ¨¡å‹")
        
        model.to(self.device)
        model.eval()
        
        return model
    
    def generate_sequences(
        self,
        peptide_type: str = 'antimicrobial',
        num_samples: int = 20,
        max_length: int = 30,
        min_length: int = 10,
        guidance_scale: float = 2.0,
        num_inference_steps: int = 50,
        temperature: float = 1.0
    ):
        """ç”Ÿæˆè‚½æ®µåºåˆ—"""
        logger.info(f"ğŸ§¬ ç”Ÿæˆ {num_samples} ä¸ª {peptide_type} è‚½æ®µ...")
        
        # å‡†å¤‡æ¡ä»¶
        peptide_type_id = self.peptide_type_map.get(peptide_type, 0)
        conditions = {
            'peptide_type': torch.full((num_samples,), peptide_type_id, 
                                     device=self.device, dtype=torch.long)
        }
        
        # éšæœºé€‰æ‹©åºåˆ—é•¿åº¦
        lengths = np.random.randint(min_length, max_length + 1, size=num_samples)
        
        generated_sequences = []
        
        for i in range(num_samples):
            try:
                # ç”Ÿæˆå•ä¸ªåºåˆ—
                seq_length = lengths[i]
                sequences = self._sample_single_sequence(
                    seq_length=seq_length,
                    peptide_type_id=peptide_type_id,
                    guidance_scale=guidance_scale,
                    num_inference_steps=num_inference_steps,
                    temperature=temperature
                )
                
                if sequences:
                    generated_sequences.extend(sequences)
                    
                if (i + 1) % 5 == 0:
                    logger.info(f"  è¿›åº¦: {i + 1}/{num_samples}")
                    
            except Exception as e:
                logger.warning(f"ç”Ÿæˆç¬¬ {i+1} ä¸ªåºåˆ—æ—¶å‡ºé”™: {e}")
                continue
        
        logger.info(f"âœ… æˆåŠŸç”Ÿæˆ {len(generated_sequences)} ä¸ªåºåˆ—")
        return generated_sequences
    
    def _sample_single_sequence(
        self,
        seq_length: int,
        peptide_type_id: int,
        guidance_scale: float = 2.0,
        num_inference_steps: int = 50,
        temperature: float = 1.0
    ):
        """ç”Ÿæˆå•ä¸ªåºåˆ—"""
        batch_size = 1
        device = self.device
        
        # åˆ›å»ºéšæœºå™ªå£°ä½œä¸ºèµ·ç‚¹
        # æ³¨æ„ï¼šéœ€è¦è€ƒè™‘CLSå’ŒSEP token
        total_length = seq_length + 2
        noise_shape = (batch_size, total_length, self.model.seq_hidden_dim)
        x_t = torch.randn(noise_shape, device=device) * temperature
        
        # åˆ›å»ºæ³¨æ„åŠ›æ©ç 
        attention_mask = torch.ones(batch_size, total_length, device=device)
        
        # åˆ›å»ºæ¡ä»¶
        conditions = {
            'peptide_type': torch.tensor([peptide_type_id], device=device, dtype=torch.long)
        }
        
        # é€æ­¥å»å™ª
        timesteps = torch.linspace(
            self.diffusion.num_timesteps - 1, 0, 
            num_inference_steps, dtype=torch.long, device=device
        )
        
        x = x_t
        for t in timesteps:
            # åˆ›å»ºæ—¶é—´æ­¥å¼ é‡
            t_batch = torch.full((batch_size,), t, device=device, dtype=torch.long)
            
            # ä½¿ç”¨classifier-free guidance
            if guidance_scale > 1.0:
                # æ— æ¡ä»¶é¢„æµ‹
                with torch.no_grad():
                    uncond_output = self.model(
                        sequences=torch.zeros(batch_size, total_length, device=device, dtype=torch.long),
                        attention_mask=attention_mask,
                        timesteps=t_batch,
                        conditions=None,
                        return_loss=False
                    )
                    uncond_pred = uncond_output['denoised_embeddings']
                
                # æœ‰æ¡ä»¶é¢„æµ‹
                with torch.no_grad():
                    cond_output = self.model(
                        sequences=torch.zeros(batch_size, total_length, device=device, dtype=torch.long),
                        attention_mask=attention_mask,
                        timesteps=t_batch,
                        conditions=conditions,
                        return_loss=False
                    )
                    cond_pred = cond_output['denoised_embeddings']
                
                # åº”ç”¨guidance
                noise_pred = uncond_pred + guidance_scale * (cond_pred - uncond_pred)
            else:
                # ç›´æ¥é¢„æµ‹
                with torch.no_grad():
                    output = self.model(
                        sequences=torch.zeros(batch_size, total_length, device=device, dtype=torch.long),
                        attention_mask=attention_mask,
                        timesteps=t_batch,
                        conditions=conditions,
                        return_loss=False
                    )
                    noise_pred = output['denoised_embeddings']
            
            # æ›´æ–°xï¼ˆè¿™é‡Œç®€åŒ–äº†æ‰©æ•£è¿‡ç¨‹çš„æ›´æ–°æ­¥éª¤ï¼‰
            alpha_t = self.diffusion.alphas_cumprod[t]
            alpha_t_prev = self.diffusion.alphas_cumprod[max(0, t-1)] if t > 0 else torch.tensor(1.0, device=device)
            
            # è®¡ç®—å‰ä¸€æ­¥çš„æ ·æœ¬
            pred_x0 = (x - torch.sqrt(1 - alpha_t) * noise_pred) / torch.sqrt(alpha_t)
            
            if t > 0:
                # æ·»åŠ å™ªå£°ç”¨äºä¸‹ä¸€æ­¥
                noise = torch.randn_like(x)
                x = torch.sqrt(alpha_t_prev) * pred_x0 + torch.sqrt(1 - alpha_t_prev) * noise
            else:
                x = pred_x0
        
        # è§£ç ä¸ºåºåˆ—
        sequences = self.model._decode_embeddings(x, attention_mask)
        
        return sequences
    
    def analyze_sequences(self, sequences, peptide_type):
        """åˆ†æç”Ÿæˆçš„åºåˆ—"""
        if not sequences:
            return {}
        
        analysis = {
            'total_sequences': len(sequences),
            'peptide_type': peptide_type,
            'unique_sequences': len(set(sequences)),
            'average_length': np.mean([len(seq) for seq in sequences]),
            'length_std': np.std([len(seq) for seq in sequences]),
            'min_length': min(len(seq) for seq in sequences),
            'max_length': max(len(seq) for seq in sequences)
        }
        
        # æ°¨åŸºé…¸é¢‘ç‡åˆ†æ
        all_chars = ''.join(sequences)
        char_counts = Counter(all_chars)
        total_chars = len(all_chars)
        
        aa_freq = {}
        for aa in 'ACDEFGHIKLMNPQRSTVWY':
            aa_freq[f'freq_{aa}'] = char_counts.get(aa, 0) / total_chars if total_chars > 0 else 0
        
        analysis.update(aa_freq)
        
        # è®¡ç®—å¤šæ ·æ€§æŒ‡æ ‡
        analysis['uniqueness_ratio'] = len(set(sequences)) / len(sequences)
        
        # è®¡ç®—åºåˆ—å¤æ‚åº¦ï¼ˆä¿¡æ¯ç†µï¼‰
        if total_chars > 0:
            entropy = 0
            for count in char_counts.values():
                prob = count / total_chars
                if prob > 0:
                    entropy -= prob * np.log2(prob)
            analysis['sequence_entropy'] = entropy
        else:
            analysis['sequence_entropy'] = 0
        
        return analysis
    
    def save_sequences(self, sequences, output_file, peptide_type):
        """ä¿å­˜åºåˆ—åˆ°FASTAæ–‡ä»¶"""
        if not sequences:
            logger.warning("æ²¡æœ‰åºåˆ—å¯ä¿å­˜")
            return
        
        records = []
        for i, seq in enumerate(sequences):
            record = SeqRecord(
                Seq(seq),
                id=f"generated_{peptide_type}_{i+1:03d}",
                description=f"Generated {peptide_type} peptide (length: {len(seq)})"
            )
            records.append(record)
        
        SeqIO.write(records, output_file, "fasta")
        logger.info(f"ğŸ’¾ åºåˆ—å·²ä¿å­˜åˆ°: {output_file}")


def main():
    """ä¸»å‡½æ•°"""
    setup_logger()
    
    # æ£€æŸ¥CUDAå¯ç”¨æ€§
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    logger.info(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # æ¨¡å‹è·¯å¾„
    model_path = "./outputs/structdiff_fixed/best_model.pt"
    
    if not os.path.exists(model_path):
        logger.error(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        logger.info("è¯·å…ˆè¿è¡Œè®­ç»ƒè„šæœ¬ç”Ÿæˆæ¨¡å‹")
        return
    
    # åˆ›å»ºç”Ÿæˆå™¨
    try:
        generator = PeptideGenerator(model_path, device)
    except Exception as e:
        logger.error(f"âŒ åˆ›å»ºç”Ÿæˆå™¨å¤±è´¥: {e}")
        return
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path("./test_generation_results")
    output_dir.mkdir(exist_ok=True)
    
    # ç”Ÿæˆå‚æ•°
    generation_params = {
        'num_samples': 20,
        'max_length': 30,
        'min_length': 10,
        'guidance_scale': 2.0,
        'num_inference_steps': 50,
        'temperature': 1.0
    }
    
    # å¯¹æ¯ç§è‚½ç±»å‹è¿›è¡Œç”Ÿæˆ
    peptide_types = ['antimicrobial', 'antifungal', 'antiviral']
    all_results = {}
    
    for peptide_type in peptide_types:
        logger.info(f"\nğŸ§¬ å¼€å§‹ç”Ÿæˆ {peptide_type} è‚½æ®µ...")
        
        try:
            # ç”Ÿæˆåºåˆ—
            sequences = generator.generate_sequences(
                peptide_type=peptide_type,
                **generation_params
            )
            
            if sequences:
                # åˆ†æåºåˆ—
                analysis = generator.analyze_sequences(sequences, peptide_type)
                all_results[peptide_type] = analysis
                
                # ä¿å­˜åºåˆ—
                fasta_file = output_dir / f"generated_{peptide_type}_sequences.fasta"
                generator.save_sequences(sequences, fasta_file, peptide_type)
                
                # æ‰“å°ä¸€äº›ç¤ºä¾‹åºåˆ—
                logger.info(f"âœ… {peptide_type} ç”Ÿæˆå®Œæˆï¼Œå…± {len(sequences)} ä¸ªåºåˆ—")
                logger.info("ç¤ºä¾‹åºåˆ—:")
                for i, seq in enumerate(sequences[:5]):
                    logger.info(f"  {i+1}. {seq} (é•¿åº¦: {len(seq)})")
                
                if len(sequences) > 5:
                    logger.info(f"  ... è¿˜æœ‰ {len(sequences)-5} ä¸ªåºåˆ—")
            else:
                logger.warning(f"âš ï¸ {peptide_type} æ²¡æœ‰ç”Ÿæˆä»»ä½•åºåˆ—")
                
        except Exception as e:
            logger.error(f"âŒ {peptide_type} ç”Ÿæˆå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            continue
    
    # ä¿å­˜åˆ†æç»“æœ
    if all_results:
        results_file = output_dir / "generation_analysis.json"
        with open(results_file, 'w') as f:
            json.dump(all_results, f, indent=2)
        
        # æ‰“å°ç»“æœæ‘˜è¦
        logger.info("\n" + "="*60)
        logger.info("ğŸ¯ ç”Ÿæˆç»“æœæ‘˜è¦")
        logger.info("="*60)
        
        for peptide_type, analysis in all_results.items():
            logger.info(f"\nğŸ“Š {peptide_type.upper()} è‚½æ®µ:")
            logger.info(f"  æ€»åºåˆ—æ•°: {analysis['total_sequences']}")
            logger.info(f"  å”¯ä¸€åºåˆ—: {analysis['unique_sequences']}")
            logger.info(f"  å¹³å‡é•¿åº¦: {analysis['average_length']:.1f} Â± {analysis['length_std']:.1f}")
            logger.info(f"  é•¿åº¦èŒƒå›´: {analysis['min_length']}-{analysis['max_length']}")
            logger.info(f"  å”¯ä¸€æ€§æ¯”ç‡: {analysis['uniqueness_ratio']:.3f}")
            logger.info(f"  åºåˆ—ç†µ: {analysis['sequence_entropy']:.3f}")
        
        logger.info(f"\nğŸ“ è¯¦ç»†ç»“æœä¿å­˜åˆ°: {results_file}")
    
    logger.info("\nğŸ‰ è‚½æ®µç”Ÿæˆæµ‹è¯•å®Œæˆï¼")


if __name__ == "__main__":
    main() 