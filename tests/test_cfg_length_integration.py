#!/usr/bin/env python3
"""
CFG + é•¿åº¦é‡‡æ ·å™¨é›†æˆæµ‹è¯•
éªŒè¯Classifier-Free Guidanceå’Œé•¿åº¦åˆ†å¸ƒé‡‡æ ·å™¨çš„åŠŸèƒ½æ­£ç¡®æ€§
"""

import torch
import torch.nn as nn
import numpy as np
import pytest
from typing import Dict, List, Optional, Tuple
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from structdiff.models.classifier_free_guidance import (
    CFGConfig, ClassifierFreeGuidance, CFGTrainingMixin, create_cfg_model
)
from structdiff.sampling.length_sampler import (
    LengthSamplerConfig, AdaptiveLengthSampler, LengthConstrainedSampler,
    NormalLengthDistribution, UniformLengthDistribution,
    get_default_length_config
)


class TestCFGFunctionality:
    """æµ‹è¯•CFGåŠŸèƒ½"""
    
    def setup_method(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        self.batch_size = 4
        self.seq_length = 20
        self.hidden_dim = 128
        
        # åˆ›å»ºCFGé…ç½®
        self.cfg_config = CFGConfig(
            dropout_prob=0.1,
            guidance_scale=2.0,
            adaptive_guidance=True
        )
        
        # åˆ›å»ºCFGå®ä¾‹
        self.cfg = ClassifierFreeGuidance(self.cfg_config)
    
    def test_cfg_initialization(self):
        """æµ‹è¯•CFGåˆå§‹åŒ–"""
        assert self.cfg.config.dropout_prob == 0.1
        assert self.cfg.config.guidance_scale == 2.0
        assert self.cfg.config.adaptive_guidance == True
    
    def test_condition_preparation(self):
        """æµ‹è¯•æ¡ä»¶å‡†å¤‡åŠŸèƒ½"""
        # æœ‰æ¡ä»¶è¾“å…¥
        conditions = {
            'peptide_type': torch.tensor([0, 1, 2, 0], device=self.device)
        }
        
        # è®­ç»ƒæ¨¡å¼ï¼ˆåº”ç”¨ä¸¢å¼ƒï¼‰
        processed = self.cfg.prepare_conditions(conditions, self.batch_size, training=True)
        assert 'peptide_type' in processed
        assert 'is_unconditional' in processed
        
        # æ¨ç†æ¨¡å¼ï¼ˆä¸ä¸¢å¼ƒï¼‰
        processed = self.cfg.prepare_conditions(conditions, self.batch_size, training=False)
        assert torch.equal(processed['peptide_type'], conditions['peptide_type'])
    
    def test_unconditional_batch_creation(self):
        """æµ‹è¯•æ— æ¡ä»¶æ‰¹æ¬¡åˆ›å»º"""
        uncond_batch = self.cfg._create_unconditional_batch(self.batch_size)
        
        assert uncond_batch['peptide_type'].shape == (self.batch_size,)
        assert torch.all(uncond_batch['peptide_type'] == -1)
        assert torch.all(uncond_batch['is_unconditional'] == True)
    
    def test_condition_dropout(self):
        """æµ‹è¯•æ¡ä»¶ä¸¢å¼ƒ"""
        conditions = {
            'peptide_type': torch.tensor([0, 1, 2, 0], device=self.device)
        }
        
        # å¤šæ¬¡æµ‹è¯•ä»¥éªŒè¯éšæœºæ€§
        dropout_counts = 0
        num_tests = 100
        
        for _ in range(num_tests):
            processed = self.cfg._apply_condition_dropout(conditions, self.batch_size)
            dropout_mask = processed['is_unconditional']
            dropout_counts += torch.sum(dropout_mask).item()
        
        # éªŒè¯ä¸¢å¼ƒç‡æ¥è¿‘è®¾å®šå€¼
        dropout_rate = dropout_counts / (num_tests * self.batch_size)
        assert 0.05 <= dropout_rate <= 0.2  # å…è®¸ä¸€å®šèŒƒå›´çš„éšæœºæ³¢åŠ¨
    
    def test_adaptive_guidance_scale(self):
        """æµ‹è¯•è‡ªé€‚åº”å¼•å¯¼å¼ºåº¦"""
        total_timesteps = 100
        base_scale = 2.0
        
        # æµ‹è¯•ä¸åŒæ—¶é—´æ­¥çš„å¼•å¯¼å¼ºåº¦
        for timestep in [0, 25, 50, 75, 99]:
            scale = self.cfg.adaptive_guidance_scale(timestep, total_timesteps, base_scale)
            assert isinstance(scale, float)
            assert scale > 0
    
    def test_guided_denoising(self):
        """æµ‹è¯•å¼•å¯¼å»å™ª"""
        # åˆ›å»ºç®€å•çš„æ¨¡å‹å‡½æ•°
        def simple_model(x_t, t, conditions):
            # ç®€å•è¿”å›è¾“å…¥ï¼ˆä»…ç”¨äºæµ‹è¯•ï¼‰
            return x_t * 0.9
        
        x_t = torch.randn(self.batch_size, self.seq_length, self.hidden_dim, device=self.device)
        t = torch.randint(0, 100, (self.batch_size,), device=self.device)
        conditions = {
            'peptide_type': torch.tensor([0, 1, 2, 0], device=self.device)
        }
        
        # æµ‹è¯•æœ‰å¼•å¯¼å’Œæ— å¼•å¯¼çš„å·®å¼‚
        guided_output = self.cfg.guided_denoising(simple_model, x_t, t, conditions, 2.0)
        unguided_output = self.cfg.guided_denoising(simple_model, x_t, t, conditions, 1.0)
        
        assert guided_output.shape == x_t.shape
        assert unguided_output.shape == x_t.shape
        # å¼•å¯¼è¾“å‡ºåº”è¯¥ä¸æ— å¼•å¯¼è¾“å‡ºä¸åŒ
        assert not torch.allclose(guided_output, unguided_output)


class TestLengthSampler:
    """æµ‹è¯•é•¿åº¦é‡‡æ ·å™¨åŠŸèƒ½"""
    
    def setup_method(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        self.batch_size = 8
        
        # åˆ›å»ºé•¿åº¦é‡‡æ ·é…ç½®
        self.length_config = LengthSamplerConfig(
            min_length=5,
            max_length=50,
            distribution_type="normal",
            normal_mean=25.0,
            normal_std=8.0,
            use_adaptive_sampling=True
        )
        
        # åˆ›å»ºé•¿åº¦é‡‡æ ·å™¨
        self.length_sampler = AdaptiveLengthSampler(self.length_config)
        self.length_sampler = self.length_sampler.to(self.device)
    
    def test_length_sampler_initialization(self):
        """æµ‹è¯•é•¿åº¦é‡‡æ ·å™¨åˆå§‹åŒ–"""
        assert self.length_sampler.config.min_length == 5
        assert self.length_sampler.config.max_length == 50
        assert 'normal' in self.length_sampler.base_distributions
        assert 'uniform' in self.length_sampler.base_distributions
    
    def test_basic_length_sampling(self):
        """æµ‹è¯•åŸºç¡€é•¿åº¦é‡‡æ ·"""
        # æµ‹è¯•ä¸åŒåˆ†å¸ƒç±»å‹
        for dist_type in ['normal', 'uniform', 'gamma', 'beta']:
            lengths = self.length_sampler.sample_lengths(
                batch_size=self.batch_size,
                distribution_type=dist_type,
                device=self.device
            )
            
            assert lengths.shape == (self.batch_size,)
            assert torch.all(lengths >= self.length_config.min_length)
            assert torch.all(lengths <= self.length_config.max_length)
            assert lengths.dtype == torch.long
    
    def test_conditional_length_sampling(self):
        """æµ‹è¯•æ¡ä»¶é•¿åº¦é‡‡æ ·"""
        conditions = {
            'peptide_type': torch.tensor([0, 1, 2, 0, 1, 2, 0, 1], device=self.device)
        }
        
        lengths = self.length_sampler.sample_lengths(
            batch_size=self.batch_size,
            conditions=conditions,
            device=self.device
        )
        
        assert lengths.shape == (self.batch_size,)
        assert torch.all(lengths >= self.length_config.min_length)
        assert torch.all(lengths <= self.length_config.max_length)
    
    def test_length_distribution_properties(self):
        """æµ‹è¯•é•¿åº¦åˆ†å¸ƒç‰¹æ€§"""
        num_samples = 1000
        
        # æ­£æ€åˆ†å¸ƒæµ‹è¯•
        normal_dist = self.length_sampler.base_distributions['normal']
        lengths = normal_dist.sample(num_samples, self.device)
        
        # éªŒè¯å‡å€¼å’Œæ ‡å‡†å·®æ¥è¿‘è®¾å®šå€¼
        mean_val = torch.mean(lengths.float()).item()
        std_val = torch.std(lengths.float()).item()
        
        assert abs(mean_val - self.length_config.normal_mean) < 2.0
        assert abs(std_val - self.length_config.normal_std) < 2.0
    
    def test_length_probability_calculation(self):
        """æµ‹è¯•é•¿åº¦æ¦‚ç‡è®¡ç®—"""
        probs = self.length_sampler.get_length_probabilities(device=self.device)
        
        # éªŒè¯æ¦‚ç‡åˆ†å¸ƒçš„æ€§è´¨
        assert probs.shape[1] == self.length_config.max_length - self.length_config.min_length + 1
        assert torch.allclose(torch.sum(probs, dim=-1), torch.ones(probs.shape[0]))
        assert torch.all(probs >= 0)
    
    def test_temperature_effects(self):
        """æµ‹è¯•æ¸©åº¦å¯¹é‡‡æ ·çš„å½±å“"""
        # ä½æ¸©åº¦åº”è¯¥äº§ç”Ÿæ›´é›†ä¸­çš„åˆ†å¸ƒ
        low_temp_lengths = self.length_sampler.sample_lengths(
            batch_size=100,
            temperature=0.5,
            device=self.device
        )
        
        # é«˜æ¸©åº¦åº”è¯¥äº§ç”Ÿæ›´åˆ†æ•£çš„åˆ†å¸ƒ
        high_temp_lengths = self.length_sampler.sample_lengths(
            batch_size=100,
            temperature=1.5,
            device=self.device
        )
        
        # è®¡ç®—æ–¹å·®
        low_temp_var = torch.var(low_temp_lengths.float()).item()
        high_temp_var = torch.var(high_temp_lengths.float()).item()
        
        # é«˜æ¸©åº¦çš„æ–¹å·®åº”è¯¥æ›´å¤§ï¼ˆå…è®¸ä¸€å®šçš„éšæœºæ€§ï¼‰
        assert high_temp_var >= low_temp_var * 0.8


class TestLengthConstrainedSampler:
    """æµ‹è¯•é•¿åº¦çº¦æŸé‡‡æ ·å™¨"""
    
    def setup_method(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        self.length_config = get_default_length_config()
        self.length_sampler = AdaptiveLengthSampler(self.length_config)
        self.constrainer = LengthConstrainedSampler(self.length_sampler)
    
    def test_length_mask_creation(self):
        """æµ‹è¯•é•¿åº¦æ©ç åˆ›å»º"""
        target_lengths = torch.tensor([10, 15, 20, 8], device=self.device)
        max_seq_length = 25
        
        mask = self.constrainer.create_length_mask(target_lengths, max_seq_length, self.device)
        
        assert mask.shape == (4, max_seq_length)
        
        # éªŒè¯æ©ç æ­£ç¡®æ€§
        for i, length in enumerate(target_lengths):
            expected_mask = torch.zeros(max_seq_length, device=self.device)
            expected_mask[:length] = 1.0
            assert torch.equal(mask[i], expected_mask)
    
    def test_length_constraint_enforcement(self):
        """æµ‹è¯•é•¿åº¦çº¦æŸå¼ºåˆ¶æ‰§è¡Œ"""
        batch_size = 4
        seq_length = 30
        target_lengths = torch.tensor([10, 15, 20, 25], device=self.device)
        
        # åˆ›å»ºéšæœºåºåˆ—
        sequences = torch.randint(0, 20, (batch_size, seq_length), device=self.device)
        
        # åº”ç”¨é•¿åº¦çº¦æŸ
        constrained = self.constrainer.enforce_length_constraint(sequences, target_lengths, pad_token_id=0)
        
        assert constrained.shape == sequences.shape
        
        # éªŒè¯æ¯ä¸ªåºåˆ—çš„é•¿åº¦çº¦æŸ
        for i, target_len in enumerate(target_lengths):
            # æ£€æŸ¥ç›®æ ‡é•¿åº¦å†…çš„éƒ¨åˆ†ä¿æŒä¸å˜
            assert torch.equal(constrained[i, :target_len], sequences[i, :target_len])
            # æ£€æŸ¥è¶…å‡ºéƒ¨åˆ†è¢«å¡«å……ä¸º0
            if target_len < seq_length:
                assert torch.all(constrained[i, target_len:] == 0)


class TestCFGLengthIntegration:
    """æµ‹è¯•CFGå’Œé•¿åº¦é‡‡æ ·å™¨çš„é›†æˆ"""
    
    def setup_method(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        self.batch_size = 4
        
        # åˆ›å»ºé…ç½®
        self.cfg_config = CFGConfig(dropout_prob=0.1, guidance_scale=2.0)
        self.length_config = get_default_length_config()
        
        # åˆ›å»ºç»„ä»¶
        self.cfg = ClassifierFreeGuidance(self.cfg_config)
        self.length_sampler = AdaptiveLengthSampler(self.length_config)
        self.length_sampler = self.length_sampler.to(self.device)
    
    def test_integrated_condition_processing(self):
        """æµ‹è¯•é›†æˆçš„æ¡ä»¶å¤„ç†"""
        # åˆ›å»ºæ¡ä»¶
        conditions = {
            'peptide_type': torch.tensor([0, 1, 2, 0], device=self.device)
        }
        
        # CFGæ¡ä»¶å¤„ç†
        cfg_conditions = self.cfg.prepare_conditions(conditions, self.batch_size, training=True)
        
        # é•¿åº¦é‡‡æ ·ï¼ˆä½¿ç”¨CFGå¤„ç†åçš„æ¡ä»¶ï¼‰
        lengths = self.length_sampler.sample_lengths(
            batch_size=self.batch_size,
            conditions=cfg_conditions,
            device=self.device
        )
        
        assert lengths.shape == (self.batch_size,)
        assert torch.all(lengths >= self.length_config.min_length)
        assert torch.all(lengths <= self.length_config.max_length)
    
    def test_condition_dropout_with_length_sampling(self):
        """æµ‹è¯•æ¡ä»¶ä¸¢å¼ƒå¯¹é•¿åº¦é‡‡æ ·çš„å½±å“"""
        conditions = {
            'peptide_type': torch.tensor([0, 1, 2, 0], device=self.device)
        }
        
        # å¤šæ¬¡æµ‹è¯•ä»¥è§‚å¯Ÿæ¡ä»¶ä¸¢å¼ƒçš„å½±å“
        lengths_with_dropout = []
        lengths_without_dropout = []
        
        for _ in range(10):
            # å¸¦æ¡ä»¶ä¸¢å¼ƒ
            cfg_conditions = self.cfg.prepare_conditions(conditions, self.batch_size, training=True)
            lengths_dropout = self.length_sampler.sample_lengths(
                batch_size=self.batch_size,
                conditions=cfg_conditions,
                device=self.device
            )
            lengths_with_dropout.append(lengths_dropout)
            
            # ä¸å¸¦æ¡ä»¶ä¸¢å¼ƒ
            lengths_no_dropout = self.length_sampler.sample_lengths(
                batch_size=self.batch_size,
                conditions=conditions,
                device=self.device
            )
            lengths_without_dropout.append(lengths_no_dropout)
        
        # éªŒè¯æœ‰å·®å¼‚ï¼ˆç”±äºæ¡ä»¶ä¸¢å¼ƒçš„éšæœºæ€§ï¼‰
        all_dropout_lengths = torch.stack(lengths_with_dropout)
        all_no_dropout_lengths = torch.stack(lengths_without_dropout)
        
        # è®¡ç®—æ–¹å·®ï¼Œæœ‰æ¡ä»¶ä¸¢å¼ƒçš„åº”è¯¥æ–¹å·®æ›´å¤§
        dropout_var = torch.var(all_dropout_lengths.float(), dim=0).mean().item()
        no_dropout_var = torch.var(all_no_dropout_lengths.float(), dim=0).mean().item()
        
        # å…è®¸ä¸€å®šçš„éšæœºæ€§
        assert dropout_var >= no_dropout_var * 0.8


class TestPerformance:
    """æ€§èƒ½æµ‹è¯•"""
    
    def setup_method(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    def test_cfg_performance(self):
        """æµ‹è¯•CFGæ€§èƒ½"""
        cfg_config = CFGConfig()
        cfg = ClassifierFreeGuidance(cfg_config)
        
        batch_size = 32
        seq_length = 50
        hidden_dim = 768
        
        def mock_model(x, t, cond):
            return torch.randn_like(x)
        
        x_t = torch.randn(batch_size, seq_length, hidden_dim, device=self.device)
        t = torch.randint(0, 1000, (batch_size,), device=self.device)
        conditions = {'peptide_type': torch.randint(0, 3, (batch_size,), device=self.device)}
        
        # æµ‹é‡æ—¶é—´
        import time
        start_time = time.time()
        
        for _ in range(10):
            output = cfg.guided_denoising(mock_model, x_t, t, conditions, 2.0)
        
        end_time = time.time()
        avg_time = (end_time - start_time) / 10
        
        print(f"CFGå¹³å‡æ¨ç†æ—¶é—´: {avg_time:.4f}s")
        assert avg_time < 1.0  # åº”è¯¥åœ¨1ç§’å†…å®Œæˆ
    
    def test_length_sampler_performance(self):
        """æµ‹è¯•é•¿åº¦é‡‡æ ·å™¨æ€§èƒ½"""
        length_config = get_default_length_config()
        sampler = AdaptiveLengthSampler(length_config).to(self.device)
        
        batch_size = 128
        
        # æµ‹é‡æ—¶é—´
        import time
        start_time = time.time()
        
        for _ in range(100):
            lengths = sampler.sample_lengths(batch_size=batch_size, device=self.device)
        
        end_time = time.time()
        avg_time = (end_time - start_time) / 100
        
        print(f"é•¿åº¦é‡‡æ ·å™¨å¹³å‡é‡‡æ ·æ—¶é—´: {avg_time:.4f}s")
        assert avg_time < 0.1  # åº”è¯¥åœ¨0.1ç§’å†…å®Œæˆ


def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("ğŸ§ª å¼€å§‹CFG + é•¿åº¦é‡‡æ ·å™¨é›†æˆæµ‹è¯•")
    print("=" * 50)
    
    # CFGåŠŸèƒ½æµ‹è¯•
    print("ğŸ”¸ æµ‹è¯•CFGåŠŸèƒ½...")
    cfg_test = TestCFGFunctionality()
    cfg_test.setup_method()
    cfg_test.test_cfg_initialization()
    cfg_test.test_condition_preparation()
    cfg_test.test_unconditional_batch_creation()
    cfg_test.test_condition_dropout()
    cfg_test.test_adaptive_guidance_scale()
    cfg_test.test_guided_denoising()
    print("âœ… CFGåŠŸèƒ½æµ‹è¯•é€šè¿‡")
    
    # é•¿åº¦é‡‡æ ·å™¨æµ‹è¯•
    print("ğŸ”¸ æµ‹è¯•é•¿åº¦é‡‡æ ·å™¨...")
    length_test = TestLengthSampler()
    length_test.setup_method()
    length_test.test_length_sampler_initialization()
    length_test.test_basic_length_sampling()
    length_test.test_conditional_length_sampling()
    length_test.test_length_distribution_properties()
    length_test.test_length_probability_calculation()
    length_test.test_temperature_effects()
    print("âœ… é•¿åº¦é‡‡æ ·å™¨æµ‹è¯•é€šè¿‡")
    
    # é•¿åº¦çº¦æŸæµ‹è¯•
    print("ğŸ”¸ æµ‹è¯•é•¿åº¦çº¦æŸ...")
    constraint_test = TestLengthConstrainedSampler()
    constraint_test.setup_method()
    constraint_test.test_length_mask_creation()
    constraint_test.test_length_constraint_enforcement()
    print("âœ… é•¿åº¦çº¦æŸæµ‹è¯•é€šè¿‡")
    
    # é›†æˆæµ‹è¯•
    print("ğŸ”¸ æµ‹è¯•CFG+é•¿åº¦é‡‡æ ·å™¨é›†æˆ...")
    integration_test = TestCFGLengthIntegration()
    integration_test.setup_method()
    integration_test.test_integrated_condition_processing()
    integration_test.test_condition_dropout_with_length_sampling()
    print("âœ… é›†æˆæµ‹è¯•é€šè¿‡")
    
    # æ€§èƒ½æµ‹è¯•
    print("ğŸ”¸ æµ‹è¯•æ€§èƒ½...")
    perf_test = TestPerformance()
    perf_test.setup_method()
    perf_test.test_cfg_performance()
    perf_test.test_length_sampler_performance()
    print("âœ… æ€§èƒ½æµ‹è¯•é€šè¿‡")
    
    print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼CFGå’Œé•¿åº¦é‡‡æ ·å™¨åŠŸèƒ½æ­£å¸¸")


if __name__ == "__main__":
    run_all_tests()