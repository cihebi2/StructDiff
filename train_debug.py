#!/usr/bin/env python3
"""
è°ƒè¯•ç‰ˆæœ¬çš„StructDiffè®­ç»ƒè„šæœ¬
æ·»åŠ è¯¦ç»†æ—¥å¿—è¾“å‡ºï¼Œå¸®åŠ©å®šä½è®­ç»ƒå¡ä½çš„é—®é¢˜
"""

import os
import sys
import time
import torch
import numpy as np
from pathlib import Path
from omegaconf import OmegaConf
from torch.utils.data import DataLoader
import argparse

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

def custom_collate_fn(batch):
    """è‡ªå®šä¹‰collateå‡½æ•°ï¼Œå¤„ç†ä¸åŒé•¿åº¦çš„åºåˆ—"""
    print(f"DEBUG: Processing batch of size {len(batch)}")
    
    # è·å–æœ€å¤§é•¿åº¦
    max_len = max(item['sequences'].shape[0] for item in batch)
    print(f"DEBUG: Max sequence length in batch: {max_len}")
    
    # å‡†å¤‡æ‰¹æ¬¡æ•°æ®
    sequences = []
    attention_masks = []
    labels = []
    
    for i, item in enumerate(batch):
        seq = item['sequences']
        # æˆªæ–­æˆ–å¡«å……åˆ°å›ºå®šé•¿åº¦
        if seq.shape[0] > max_len:
            seq = seq[:max_len]
        elif seq.shape[0] < max_len:
            # ä½¿ç”¨pad_token_idå¡«å……ï¼ˆé€šå¸¸æ˜¯0ï¼‰
            pad_length = max_len - seq.shape[0]
            seq = torch.cat([seq, torch.zeros(pad_length, dtype=seq.dtype)], dim=0)
        
        sequences.append(seq)
        
        # åˆ›å»ºattention mask
        attention_mask = torch.ones(max_len, dtype=torch.bool)
        if item['sequences'].shape[0] < max_len:
            attention_mask[item['sequences'].shape[0]:] = False
        attention_masks.append(attention_mask)
        
        labels.append(item['label'])
    
    print(f"DEBUG: Collated batch successfully")
    return {
        'sequences': torch.stack(sequences),
        'attention_mask': torch.stack(attention_masks),
        'peptide_type': torch.stack(labels)
    }

def main():
    parser = argparse.ArgumentParser(description='è°ƒè¯•StructDiffè®­ç»ƒ')
    parser.add_argument('--device', type=str, default='cuda:0', help='è®­ç»ƒè®¾å¤‡')
    
    args = parser.parse_args()
    
    print("=" * 50)
    print("ğŸ› å¼€å§‹è°ƒè¯•StructDiffè®­ç»ƒ")
    print("=" * 50)
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device(args.device if torch.cuda.is_available() else 'cpu')
    print(f"âœ“ ä½¿ç”¨è®¾å¤‡: {device}")
    
    # æ•°æ®é…ç½®
    data_config = OmegaConf.create({
        "data": {
            "max_length": 50,
            "use_predicted_structures": False
        },
        "model": {
            "sequence_encoder": {
                "pretrained_model": "facebook/esm2_t6_8M_UR50D"
            },
            "structure_encoder": {
                "use_esmfold": False
            }
        }
    })
    
    print("âœ“ é…ç½®åˆ›å»ºå®Œæˆ")
    
    # åˆ›å»ºæ•°æ®é›†
    print("ğŸ“Š åˆ›å»ºæ•°æ®é›†...")
    sys.stdout.flush()
    
    try:
        from structdiff.data.dataset import PeptideStructureDataset
        
        train_dataset = PeptideStructureDataset(
            data_path="data/processed/train.csv",
            config=data_config,
            is_training=True
        )
        print(f"âœ“ è®­ç»ƒæ•°æ®é›†åˆ›å»ºå®Œæˆ: {len(train_dataset)} æ ·æœ¬")
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        print("ğŸ“¥ åˆ›å»ºæ•°æ®åŠ è½½å™¨...")
        train_loader = DataLoader(
            train_dataset,
            batch_size=2,  # å¾ˆå°çš„æ‰¹æ¬¡å¤§å°
            shuffle=False,  # ç¦ç”¨éšæœºæ‰“ä¹±ä¾¿äºè°ƒè¯•
            num_workers=0,
            pin_memory=False,
            collate_fn=custom_collate_fn
        )
        print("âœ“ æ•°æ®åŠ è½½å™¨åˆ›å»ºå®Œæˆ")
        
        # æµ‹è¯•æ•°æ®åŠ è½½
        print("ğŸ”„ æµ‹è¯•æ•°æ®åŠ è½½...")
        sys.stdout.flush()
        
        for i, batch in enumerate(train_loader):
            print(f"âœ“ æˆåŠŸåŠ è½½ç¬¬ {i+1} ä¸ªæ‰¹æ¬¡")
            print(f"  åºåˆ—å½¢çŠ¶: {batch['sequences'].shape}")
            print(f"  æ ‡ç­¾: {batch['peptide_type']}")
            
            if i >= 2:  # åªæµ‹è¯•å‰å‡ ä¸ªæ‰¹æ¬¡
                break
        
        print("âœ“ æ•°æ®åŠ è½½æµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # åˆ›å»ºç®€åŒ–çš„æ¨¡å‹é…ç½®
    print("ğŸ§  åˆ›å»ºæ¨¡å‹...")
    sys.stdout.flush()
    
    model_config = OmegaConf.create({
        "sequence_encoder": {
            "pretrained_model": "facebook/esm2_t6_8M_UR50D",
            "freeze_encoder": True,  # å›ºå®šç¼–ç å™¨å‡å°‘è®­ç»ƒå¤æ‚åº¦
            "use_lora": False
        },
        "structure_encoder": {
            "use_esmfold": False,
            "hidden_dim": 256
        },
        "denoiser": {
            "hidden_dim": 320,
            "num_layers": 2,  # åªç”¨2å±‚ä¾¿äºè°ƒè¯•
            "num_heads": 4,
            "dropout": 0.1,
            "use_cross_attention": False
        }
    })
    
    try:
        from structdiff.models.structdiff import StructDiff
        
        print("  åˆå§‹åŒ–StructDiffæ¨¡å‹...")
        sys.stdout.flush()
        model = StructDiff(model_config)
        print(f"âœ“ æ¨¡å‹åˆ›å»ºæˆåŠŸï¼Œå‚æ•°æ•°é‡: {model.count_parameters():,}")
        
        print("  ç§»åŠ¨æ¨¡å‹åˆ°è®¾å¤‡...")
        sys.stdout.flush()
        model = model.to(device)
        print("âœ“ æ¨¡å‹ç§»åŠ¨åˆ°è®¾å¤‡å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # åˆ›å»ºæ‰©æ•£è¿‡ç¨‹
    print("ğŸŒ€ åˆ›å»ºæ‰©æ•£è¿‡ç¨‹...")
    sys.stdout.flush()
    
    try:
        from structdiff.diffusion.gaussian_diffusion import GaussianDiffusion
        
        diffusion = GaussianDiffusion(
            num_timesteps=100,  # å‡å°‘æ—¶é—´æ­¥ä¾¿äºè°ƒè¯•
            noise_schedule="linear",
            beta_start=0.0001,
            beta_end=0.02
        )
        print("âœ“ æ‰©æ•£è¿‡ç¨‹åˆ›å»ºå®Œæˆ")
        
    except Exception as e:
        print(f"âŒ æ‰©æ•£è¿‡ç¨‹åˆ›å»ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # æµ‹è¯•å•ä¸ªè®­ç»ƒæ­¥éª¤
    print("ğŸ‹ï¸ æµ‹è¯•å•ä¸ªè®­ç»ƒæ­¥éª¤...")
    sys.stdout.flush()
    
    try:
        optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)
        
        # è·å–ä¸€ä¸ªæ‰¹æ¬¡
        batch = next(iter(train_loader))
        print("âœ“ è·å–è®­ç»ƒæ‰¹æ¬¡æˆåŠŸ")
        
        # ç§»åŠ¨æ•°æ®åˆ°è®¾å¤‡
        print("  ç§»åŠ¨æ•°æ®åˆ°è®¾å¤‡...")
        sequences = batch['sequences'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        conditions = {'peptide_type': batch['peptide_type'].to(device)}
        print("âœ“ æ•°æ®ç§»åŠ¨å®Œæˆ")
        
        # è·å–åºåˆ—åµŒå…¥
        print("  è·å–åºåˆ—åµŒå…¥...")
        sys.stdout.flush()
        with torch.no_grad():
            embeddings = model.sequence_encoder(sequences, attention_mask)
            embeddings = embeddings.last_hidden_state[:, 1:-1, :]
        print(f"âœ“ åºåˆ—åµŒå…¥è·å–å®Œæˆï¼Œå½¢çŠ¶: {embeddings.shape}")
        
        # å‰å‘æ‰©æ•£
        print("  æ‰§è¡Œå‰å‘æ‰©æ•£...")
        batch_size, seq_len, hidden_dim = embeddings.shape
        timesteps = torch.randint(0, diffusion.num_timesteps, (batch_size,), device=device)
        noise = torch.randn_like(embeddings)
        noisy_embeddings = diffusion.q_sample(embeddings, timesteps, noise)
        print("âœ“ å‰å‘æ‰©æ•£å®Œæˆ")
        
        # é¢„æµ‹å™ªå£°
        print("  é¢„æµ‹å™ªå£°...")
        sys.stdout.flush()
        model.train()
        optimizer.zero_grad()
        
        predicted_noise = model.denoiser(
            noisy_embeddings=noisy_embeddings,
            timesteps=timesteps,
            attention_mask=attention_mask[:, 1:-1],
            structure_features=None,
            conditions=conditions
        )[0]
        print("âœ“ å™ªå£°é¢„æµ‹å®Œæˆ")
        
        # è®¡ç®—æŸå¤±å’Œåå‘ä¼ æ’­
        print("  è®¡ç®—æŸå¤±...")
        loss = torch.nn.functional.mse_loss(predicted_noise, noise)
        print(f"âœ“ æŸå¤±è®¡ç®—å®Œæˆ: {loss.item():.6f}")
        
        print("  åå‘ä¼ æ’­...")
        loss.backward()
        optimizer.step()
        print("âœ“ åå‘ä¼ æ’­å®Œæˆ")
        
        print("=" * 50)
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•æ­¥éª¤å®Œæˆï¼è®­ç»ƒæµç¨‹æ­£å¸¸ã€‚")
        print("=" * 50)
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒæ­¥éª¤å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return

if __name__ == "__main__":
    main() 