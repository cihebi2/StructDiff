#!/usr/bin/env python3
"""
GPUä¼˜åŒ–è®­ç»ƒè„šæœ¬ - ä½¿ç”¨é¢„è®¡ç®—çš„ç»“æ„ç‰¹å¾
ä¼˜åŒ–é…ç½®ï¼š
- æ‰¹æ¬¡å¤§å°ï¼š16 (ä»åŸæ¥çš„2å¤§å¹…æå‡)
- æ•°æ®åŠ è½½å·¥ä½œè¿›ç¨‹ï¼š4 (å¯ç”¨å¤šè¿›ç¨‹)
- æ··åˆç²¾åº¦è®­ç»ƒï¼šå¯ç”¨
- æ¢¯åº¦ç´¯ç§¯ï¼š2 (å‡å°‘ä»¥å¢åŠ æ›´æ–°é¢‘ç‡)
- é¢„è®¡ç®—ç»“æ„ç‰¹å¾ï¼šå¯ç”¨ç¼“å­˜ç³»ç»Ÿ
"""

import os
import sys
import time
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torch.cuda.amp import autocast, GradScaler
import logging
from pathlib import Path
from datetime import datetime
import gc
import psutil
import GPUtil
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True,max_split_size_mb:128'
os.environ['TOKENIZERS_PARALLELISM'] = 'false'

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
sys.path.append('/home/qlyu/sequence/StructDiff-7.0.0')
from precompute_structure_features import StructureFeatureCache
from transformers import EsmModel, EsmTokenizer
from sklearn.model_selection import train_test_split

# é…ç½®æ—¥å¿—
def setup_logging():
    log_dir = Path("logs")
    log_dir.mkdir(exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_file = log_dir / f"gpu_optimized_training_{timestamp}.log"
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file),
            logging.StreamHandler()
        ]
    )
    return logging.getLogger(__name__)

logger = setup_logging()

class OptimizedPeptideDataset(Dataset):
    """ä¼˜åŒ–çš„è‚½æ®µæ•°æ®é›†ï¼Œä½¿ç”¨é¢„è®¡ç®—çš„ç»“æ„ç‰¹å¾"""
    
    def __init__(self, sequences, labels, structure_cache, max_length=512, use_structure=True):
        self.sequences = sequences
        self.labels = labels
        self.structure_cache = structure_cache
        self.max_length = max_length
        self.use_structure = use_structure
        
        # ESM tokenizer
        self.tokenizer = EsmTokenizer.from_pretrained("facebook/esm2_t33_650M_UR50D")
        
        logger.info(f"æ•°æ®é›†åˆå§‹åŒ–å®Œæˆ: {len(sequences)} ä¸ªåºåˆ—")
        logger.info(f"ä½¿ç”¨ç»“æ„ç‰¹å¾: {use_structure}")
        
    def __len__(self):
        return len(self.sequences)
    
    def __getitem__(self, idx):
        sequence = str(self.sequences[idx])
        label = self.labels[idx]
        
        # ESMç¼–ç 
        inputs = self.tokenizer(
            sequence,
            return_tensors="pt",
            padding="max_length",
            truncation=True,
            max_length=self.max_length
        )
        
        input_ids = inputs["input_ids"].squeeze(0)
        attention_mask = inputs["attention_mask"].squeeze(0)
        
        # è·å–ç»“æ„ç‰¹å¾
        structure_features = None
        if self.use_structure and self.structure_cache is not None:
            try:
                structure_features = self.structure_cache.get_cached_structure(sequence)
                if structure_features is not None:
                    # è°ƒæ•´ç»´åº¦ä»¥åŒ¹é…åºåˆ—é•¿åº¦
                    seq_len = attention_mask.sum().item()
                    if structure_features.shape[0] > seq_len:
                        structure_features = structure_features[:seq_len]
                    elif structure_features.shape[0] < seq_len:
                        # å¡«å……åˆ°åŒ¹é…é•¿åº¦
                        padding = torch.zeros(seq_len - structure_features.shape[0], structure_features.shape[1])
                        structure_features = torch.cat([structure_features, padding], dim=0)
                else:
                    # å¦‚æœæ²¡æœ‰ç»“æ„ç‰¹å¾ï¼Œåˆ›å»ºé›¶å¡«å……
                    seq_len = attention_mask.sum().item()
                    structure_features = torch.zeros(seq_len, 1024)  # ESMFoldç‰¹å¾ç»´åº¦
            except Exception as e:
                logger.warning(f"è·å–ç»“æ„ç‰¹å¾å¤±è´¥ (åºåˆ— {idx}): {e}")
                seq_len = attention_mask.sum().item()
                structure_features = torch.zeros(seq_len, 1024)
        
        result = {
            'input_ids': input_ids,
            'attention_mask': attention_mask,
            'labels': torch.tensor(label, dtype=torch.float32)
        }
        
        if structure_features is not None:
            # å¡«å……ç»“æ„ç‰¹å¾åˆ°max_length
            padded_features = torch.zeros(self.max_length, structure_features.shape[1])
            actual_len = min(structure_features.shape[0], self.max_length)
            padded_features[:actual_len] = structure_features[:actual_len]
            result['structure_features'] = padded_features
        
        return result

class StructureFusionTransformer(nn.Module):
    """ç»“æ„èåˆTransformeræ¨¡å‹"""
    
    def __init__(self, esm_model_name="facebook/esm2_t33_650M_UR50D", num_labels=1, 
                 structure_dim=1024, fusion_dim=512, dropout=0.1):
        super().__init__()
        
        # ESM2æ¨¡å‹
        self.esm_model = EsmModel.from_pretrained(esm_model_name)
        self.esm_dim = self.esm_model.config.hidden_size
        
        # ç»“æ„ç‰¹å¾æŠ•å½±
        self.structure_projection = nn.Linear(structure_dim, fusion_dim)
        
        # åºåˆ—ç‰¹å¾æŠ•å½±
        self.sequence_projection = nn.Linear(self.esm_dim, fusion_dim)
        
        # èåˆå±‚
        self.fusion_attention = nn.MultiheadAttention(
            embed_dim=fusion_dim,
            num_heads=8,
            dropout=dropout,
            batch_first=True
        )
        
        # åˆ†ç±»å™¨
        self.classifier = nn.Sequential(
            nn.Linear(fusion_dim, fusion_dim // 2),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(fusion_dim // 2, fusion_dim // 4),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(fusion_dim // 4, num_labels)
        )
        
        self.dropout = nn.Dropout(dropout)
        
    def forward(self, input_ids, attention_mask, structure_features=None):
        # ESM2ç¼–ç 
        with autocast():
            esm_outputs = self.esm_model(
                input_ids=input_ids,
                attention_mask=attention_mask,
                output_hidden_states=True
            )
            sequence_features = esm_outputs.last_hidden_state
        
        # æŠ•å½±åˆ°èåˆç»´åº¦
        seq_projected = self.sequence_projection(sequence_features)
        
        if structure_features is not None:
            # ç»“æ„ç‰¹å¾æŠ•å½±
            struct_projected = self.structure_projection(structure_features)
            
            # èåˆæ³¨æ„åŠ›
            fused_features, _ = self.fusion_attention(
                query=seq_projected,
                key=struct_projected,
                value=struct_projected,
                key_padding_mask=~attention_mask.bool()
            )
            
            # æ®‹å·®è¿æ¥
            features = seq_projected + fused_features
        else:
            features = seq_projected
        
        # æ± åŒ–ï¼šä½¿ç”¨æ³¨æ„åŠ›æ©ç è¿›è¡Œå¹³å‡æ± åŒ–
        mask_expanded = attention_mask.unsqueeze(-1).expand(features.size()).float()
        sum_embeddings = torch.sum(features * mask_expanded, 1)
        sum_mask = torch.clamp(mask_expanded.sum(1), min=1e-9)
        pooled_features = sum_embeddings / sum_mask
        
        # åˆ†ç±»
        pooled_features = self.dropout(pooled_features)
        logits = self.classifier(pooled_features)
        
        return logits

def calculate_metrics(predictions, labels):
    """è®¡ç®—è¯„ä¼°æŒ‡æ ‡"""
    predictions = torch.sigmoid(predictions).cpu().numpy()
    labels = labels.cpu().numpy()
    
    # å¤„ç†å¤šç»´æ ‡ç­¾ï¼šå¦‚æœlabelsæ˜¯å¤šç»´çš„ï¼Œå±•å¹³ä¸º1ç»´
    if labels.ndim > 1:
        labels = labels.flatten()
    if predictions.ndim > 1:
        predictions = predictions.flatten()
    
    # ç¡®ä¿æ˜¯äºŒåˆ†ç±»é—®é¢˜
    unique_labels = np.unique(labels)
    logger.info(f"æ ‡ç­¾å”¯ä¸€å€¼: {unique_labels}")
    
    # äºŒåˆ†ç±»æŒ‡æ ‡
    pred_binary = (predictions > 0.5).astype(int)
    accuracy = (pred_binary == labels).mean()
    
    # è®¡ç®—å…¶ä»–æŒ‡æ ‡
    from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score
    
    try:
        # å¦‚æœæ˜¯å¤šç±»é—®é¢˜ï¼Œä½¿ç”¨macroå¹³å‡
        if len(unique_labels) > 2:
            precision = precision_score(labels, pred_binary, average='macro', zero_division=0)
            recall = recall_score(labels, pred_binary, average='macro', zero_division=0)
            f1 = f1_score(labels, pred_binary, average='macro', zero_division=0)
        else:
            precision = precision_score(labels, pred_binary, zero_division=0)
            recall = recall_score(labels, pred_binary, zero_division=0)
            f1 = f1_score(labels, pred_binary, zero_division=0)
        
        auc = roc_auc_score(labels, predictions) if len(unique_labels) == 2 else 0.0
    except Exception as e:
        logger.warning(f"æŒ‡æ ‡è®¡ç®—å¤±è´¥: {e}")
        precision = recall = f1 = auc = 0.0
    
    return {
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1': f1,
        'auc': auc
    }

def monitor_resources():
    """ç›‘æ§ç³»ç»Ÿèµ„æº"""
    # CPUå’Œå†…å­˜
    cpu_percent = psutil.cpu_percent()
    memory_info = psutil.virtual_memory()
    
    # GPU
    gpu_info = []
    try:
        gpus = GPUtil.getGPUs()
        for gpu in gpus:
            gpu_info.append({
                'id': gpu.id,
                'utilization': gpu.load * 100,
                'memory_used': gpu.memoryUsed,
                'memory_total': gpu.memoryTotal,
                'memory_percent': (gpu.memoryUsed / gpu.memoryTotal) * 100,
                'temperature': gpu.temperature
            })
    except:
        pass
    
    return {
        'cpu_percent': cpu_percent,
        'memory_percent': memory_info.percent,
        'memory_used_gb': memory_info.used / (1024**3),
        'gpus': gpu_info
    }

def main():
    # è®­ç»ƒé…ç½®ï¼ˆGPU 1 å¹³è¡¡ç‰ˆæœ¬ - ä¿®å¤å¤šè¿›ç¨‹CUDAå†²çªï¼‰
    config = {
        'batch_size': 4,  # é€‚ä¸­æ‰¹æ¬¡å¤§å°ï¼Œé€‚åº”å‰©ä½™å†…å­˜
        'num_workers': 0,  # ç¦ç”¨å¤šè¿›ç¨‹é¿å…CUDAå†²çª
        'learning_rate': 2e-5,
        'num_epochs': 200,
        'accumulation_steps': 8,  # å¢åŠ æ¢¯åº¦ç´¯ç§¯ä¿æŒç­‰æ•ˆæ‰¹æ¬¡å¤§å°32
        'max_length': 512,
        'device': 'cuda:1',  # ä½¿ç”¨GPU 1
        'use_amp': True,  # å¯ç”¨æ··åˆç²¾åº¦èŠ‚çœå†…å­˜
        'pin_memory': False,  # ç¦ç”¨å†…å­˜å›ºå®šï¼ˆå•è¿›ç¨‹æ—¶ä¸éœ€è¦ï¼‰
        'prefetch_factor': None,  # å•è¿›ç¨‹æ—¶ä¸ä½¿ç”¨é¢„å–
        'structure_cache_dir': './structure_cache'
    }
    
    logger.info("ğŸš€ å¼€å§‹GPUä¼˜åŒ–è®­ç»ƒ")
    logger.info(f"è®­ç»ƒé…ç½®: {config}")
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device(config['device'])
    logger.info(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆå§‹åŒ–ç»“æ„ç‰¹å¾ç¼“å­˜
    logger.info("ğŸ“ åˆå§‹åŒ–ç»“æ„ç‰¹å¾ç¼“å­˜...")
    structure_cache = StructureFeatureCache(cache_dir=config['structure_cache_dir'])
    
    # åŠ è½½æ•°æ®
    logger.info("ğŸ“Š åŠ è½½è®­ç»ƒæ•°æ®...")
    train_df = pd.read_csv('data/processed/train.csv')
    val_df = pd.read_csv('data/processed/val.csv')
    
    logger.info(f"è®­ç»ƒé›†å¤§å°: {len(train_df)}")
    logger.info(f"éªŒè¯é›†å¤§å°: {len(val_df)}")
    
    # åˆ›å»ºæ•°æ®é›†
    train_dataset = OptimizedPeptideDataset(
        sequences=train_df['sequence'].tolist(),
        labels=train_df['label'].tolist(),
        structure_cache=structure_cache,
        max_length=config['max_length'],
        use_structure=True
    )
    
    val_dataset = OptimizedPeptideDataset(
        sequences=val_df['sequence'].tolist(),
        labels=val_df['label'].tolist(),
        structure_cache=structure_cache,
        max_length=config['max_length'],
        use_structure=True
    )
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨ï¼ˆå•è¿›ç¨‹é…ç½®ï¼Œé¿å…CUDAå†²çªï¼‰
    train_loader_kwargs = {
        'batch_size': config['batch_size'],
        'shuffle': True,
        'num_workers': config['num_workers'],
        'pin_memory': config['pin_memory']
    }
    
    val_loader_kwargs = {
        'batch_size': config['batch_size'],
        'shuffle': False,
        'num_workers': config['num_workers'],
        'pin_memory': config['pin_memory']
    }
    
    # åªæœ‰åœ¨ä½¿ç”¨å¤šè¿›ç¨‹æ—¶æ‰æ·»åŠ prefetch_factorå’Œpersistent_workers
    if config['num_workers'] > 0 and config['prefetch_factor'] is not None:
        train_loader_kwargs.update({
            'prefetch_factor': config['prefetch_factor'],
            'persistent_workers': True
        })
        val_loader_kwargs.update({
            'prefetch_factor': config['prefetch_factor'],
            'persistent_workers': True
        })
    
    train_loader = DataLoader(train_dataset, **train_loader_kwargs)
    val_loader = DataLoader(val_dataset, **val_loader_kwargs)
    
    logger.info(f"è®­ç»ƒæ‰¹æ¬¡æ•°: {len(train_loader)}")
    logger.info(f"éªŒè¯æ‰¹æ¬¡æ•°: {len(val_loader)}")
    
    # åˆ›å»ºæ¨¡å‹
    logger.info("ğŸ§  åˆå§‹åŒ–æ¨¡å‹...")
    model = StructureFusionTransformer(
        num_labels=1,
        structure_dim=1024,
        fusion_dim=512,
        dropout=0.1
    ).to(device)
    
    # ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨
    optimizer = torch.optim.AdamW(
        model.parameters(),
        lr=config['learning_rate'],
        weight_decay=0.01
    )
    
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
        optimizer,
        T_max=config['num_epochs'],
        eta_min=1e-6
    )
    
    # æ··åˆç²¾åº¦è®­ç»ƒ
    scaler = GradScaler() if config['use_amp'] else None
    
    # æŸå¤±å‡½æ•°
    criterion = nn.BCEWithLogitsLoss()
    
    # è®­ç»ƒå¾ªç¯
    logger.info("ğŸƒ å¼€å§‹è®­ç»ƒ...")
    best_val_f1 = 0.0
    train_losses = []
    val_losses = []
    
    for epoch in range(config['num_epochs']):
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        train_loss = 0.0
        train_predictions = []
        train_labels = []
        
        epoch_start_time = time.time()
        
        for batch_idx, batch in enumerate(train_loader):
            # ç§»åŠ¨æ•°æ®åˆ°è®¾å¤‡
            input_ids = batch['input_ids'].to(device, non_blocking=True)
            attention_mask = batch['attention_mask'].to(device, non_blocking=True)
            labels = batch['labels'].to(device, non_blocking=True)
            structure_features = batch.get('structure_features')
            if structure_features is not None:
                structure_features = structure_features.to(device, non_blocking=True)
            
            # å‰å‘ä¼ æ’­
            if config['use_amp']:
                with autocast():
                    logits = model(input_ids, attention_mask, structure_features)
                    loss = criterion(logits.squeeze(), labels)
                    loss = loss / config['accumulation_steps']
                
                # åå‘ä¼ æ’­
                scaler.scale(loss).backward()
                
                if (batch_idx + 1) % config['accumulation_steps'] == 0:
                    scaler.step(optimizer)
                    scaler.update()
                    optimizer.zero_grad()
            else:
                logits = model(input_ids, attention_mask, structure_features)
                loss = criterion(logits.squeeze(), labels)
                loss = loss / config['accumulation_steps']
                
                loss.backward()
                
                if (batch_idx + 1) % config['accumulation_steps'] == 0:
                    optimizer.step()
                    optimizer.zero_grad()
            
            train_loss += loss.item() * config['accumulation_steps']
            train_predictions.append(logits.squeeze().detach())
            train_labels.append(labels.detach())
            
            # å®æ—¶ç›‘æ§
            if batch_idx % 10 == 0:
                resources = monitor_resources()
                gpu_util = resources['gpus'][1]['utilization'] if len(resources['gpus']) > 1 else 0
                gpu_memory = resources['gpus'][1]['memory_percent'] if len(resources['gpus']) > 1 else 0
                
                logger.info(f"Epoch {epoch+1}/{config['num_epochs']}, "
                          f"Batch {batch_idx}/{len(train_loader)}, "
                          f"Loss: {loss.item():.4f}, "
                          f"GPUåˆ©ç”¨ç‡: {gpu_util:.1f}%, "
                          f"GPUå†…å­˜: {gpu_memory:.1f}%")
        
        # è®¡ç®—è®­ç»ƒæŒ‡æ ‡
        train_predictions = torch.cat(train_predictions)
        train_labels = torch.cat(train_labels)
        train_metrics = calculate_metrics(train_predictions, train_labels)
        
        # éªŒè¯é˜¶æ®µ
        model.eval()
        val_loss = 0.0
        val_predictions = []
        val_labels = []
        
        with torch.no_grad():
            for batch in val_loader:
                input_ids = batch['input_ids'].to(device, non_blocking=True)
                attention_mask = batch['attention_mask'].to(device, non_blocking=True)
                labels = batch['labels'].to(device, non_blocking=True)
                structure_features = batch.get('structure_features')
                if structure_features is not None:
                    structure_features = structure_features.to(device, non_blocking=True)
                
                if config['use_amp']:
                    with autocast():
                        logits = model(input_ids, attention_mask, structure_features)
                        loss = criterion(logits.squeeze(), labels)
                else:
                    logits = model(input_ids, attention_mask, structure_features)
                    loss = criterion(logits.squeeze(), labels)
                
                val_loss += loss.item()
                val_predictions.append(logits.squeeze())
                val_labels.append(labels)
        
        # è®¡ç®—éªŒè¯æŒ‡æ ‡
        val_predictions = torch.cat(val_predictions)
        val_labels = torch.cat(val_labels)
        val_metrics = calculate_metrics(val_predictions, val_labels)
        
        # å­¦ä¹ ç‡è°ƒåº¦
        scheduler.step()
        
        # è®°å½•æŸå¤±
        avg_train_loss = train_loss / len(train_loader)
        avg_val_loss = val_loss / len(val_loader)
        train_losses.append(avg_train_loss)
        val_losses.append(avg_val_loss)
        
        # è®¡ç®—epochæ—¶é—´
        epoch_time = time.time() - epoch_start_time
        
        # èµ„æºç›‘æ§
        resources = monitor_resources()
        
        # æ—¥å¿—è®°å½•
        logger.info(f"\n=== Epoch {epoch+1}/{config['num_epochs']} å®Œæˆ ===")
        logger.info(f"æ—¶é—´: {epoch_time:.2f}s")
        logger.info(f"è®­ç»ƒæŸå¤±: {avg_train_loss:.4f}")
        logger.info(f"éªŒè¯æŸå¤±: {avg_val_loss:.4f}")
        logger.info(f"è®­ç»ƒæŒ‡æ ‡: {train_metrics}")
        logger.info(f"éªŒè¯æŒ‡æ ‡: {val_metrics}")
        logger.info(f"å­¦ä¹ ç‡: {scheduler.get_last_lr()[0]:.2e}")
        
        if len(resources['gpus']) > 1:
            gpu_info = resources['gpus'][1]
            logger.info(f"GPUåˆ©ç”¨ç‡: {gpu_info['utilization']:.1f}%")
            logger.info(f"GPUå†…å­˜: {gpu_info['memory_percent']:.1f}%")
            logger.info(f"GPUæ¸©åº¦: {gpu_info['temperature']}Â°C")
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_metrics['f1'] > best_val_f1:
            best_val_f1 = val_metrics['f1']
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'val_f1': val_metrics['f1'],
                'config': config
            }, 'best_model_optimized.pth')
            logger.info(f"ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹ (F1: {val_metrics['f1']:.4f})")
        
        # å†…å­˜æ¸…ç†
        if epoch % 10 == 0:
            gc.collect()
            torch.cuda.empty_cache()
    
    logger.info("âœ… è®­ç»ƒå®Œæˆ!")
    logger.info(f"æœ€ä½³éªŒè¯F1åˆ†æ•°: {best_val_f1:.4f}")

if __name__ == "__main__":
    main() 